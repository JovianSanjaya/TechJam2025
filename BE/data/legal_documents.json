{
  "metadata": {
    "export_date": "2025-08-28T01:34:59.988874",
    "total_documents": 5,
    "total_sections": 42,
    "total_words": 85353
  },
  "documents": [
    {
      "url": "https://en.wikipedia.org/wiki/Digital_Services_Act",
      "title": "Digital Services Act - Wikipedia",
      "description": "",
      "keywords": "",
      "author": "",
      "published_date": "",
      "scraped_at": "2025-08-28T01:34:41.101270",
      "sections": [
        {
          "title": "Introduction",
          "content": "Regulation (EU) 2022/2065European Union regulationText with EEA relevanceTitleRegulation on a Single Market For Digital ServicesMade byEuropean Parliament and Council of the European UnionJournal referenceOJ L 277, 27.10.2022, p. 1–102HistoryDate made19 October 2022Preparative textsCommission proposalCOM/2020/825 finalCurrent legislation The Digital Services Act[1] (DSA) is an EU regulation adopted in 2022 that addresses illegal content, transparent advertising and disinformation. It updates the Electronic Commerce Directive 2000 in EU law,[2][3] and was proposed alongside the Digital Markets Act (DMA). The DSA applies to online platforms and intermediaries such as social networks, marketplaces, pornographic platforms,[4] and app stores.[5] Key requirements include disclosing to regulators how their algorithms work, providing users with explanations for content moderation decisions, and implementing stricter controls on targeted advertising. It also imposes specific rules on \"very large\" online platforms and search engines (those having more than 45 million monthly active users in the EU).[6] "
        },
        {
          "title": "Objectives",
          "content": "Ursula von der Leyen proposed a \"new Digital Services Act\" in her 2019 bid for the European Commission's presidency.[7] The expressed purpose of the DSA was to update the European Union's legal framework for illegal content on intermediaries, in particular by modernising the e-Commerce Directive that had been adopted in 2000. In doing so, the DSA aimed to harmonise different national laws in the European Union that have emerged to address illegal content at national level.[2] Most prominent amongst these laws was the German NetzDG, and similar laws in Austria (\"Kommunikationsplattformen-Gesetz\") and France (\"Loi Avia\"). With the adoption of the Digital Services Act at European level, those national laws were planned to be overridden and would have to be amended.[8] In practice, this would lead to new legislation regarding illegal content, transparent advertising and disinformation.[3][needs update] "
        },
        {
          "title": "New obligations on platform companies",
          "content": "The DSA is meant to \"govern the content moderation practices of social media platforms\" and address illegal content.[9] It is organised in five chapters, with the most important chapters regulating the liability exemption of intermediaries (Chapter 2), the obligations on intermediaries (Chapter 3), and the cooperation and enforcement framework between the commission and national authorities (Chapter 4). The DSA proposal maintains the current rule according to which companies that host others' data become liable when informed that this data is illegal.[9] This so-called \"conditional liability exemption\" is fundamentally different[10][11] from the broad immunities given to intermediaries under the equivalent rule (\"Section 230 CDA\") in the United States. The DSA applies to intermediary service providers that offer their services to users based in the European Union, irrespective of whether the intermediary service provider is established in the European Union.[12] In addition to the liability exemptions, the DSA would introduce a wide-ranging set of new obligations on platforms, including some that aim to disclose to regulators how their algorithms work, while other obligations would create transparency on how decisions to remove content are taken and on the way advertisers target users. The European Centre for Algorithmic Transparency was created to aid the enforcement of this.[13] A December 2020 Time article said that while many of its provisions only apply to platforms which have more than 45 million users in the European Union, the Act could have repercussions beyond Europe. Platforms including Facebook, Twitter, TikTok, and Google's subsidiary YouTube would meet that threshold and be subjected to the new obligations.[14] A 16 November 2021 Internet Policy Review listed some of new obligations including mandatory \"notice-and-action\" requirements, for example, respect fundamental rights, mandatory redress for content removal decisions, and a comprehensive risk management and audit framework.[15] Companies that do not comply with the new obligations risk fines of up to 6% on their global annual turnover. In addition, the Commission can apply periodic penalties up to 5% of the average daily worldwide turnover for each day of delay in complying with remedies, interim measures, and commitments. As a last resort measure, if the infringement persists and causes serious harm to users and entails criminal offences involving threat to persons' life or safety, the Commission can request the temporary suspension of the service.[16] "
        },
        {
          "title": "Large online platforms",
          "content": "On 23 April 2023, the European Commission named a first list of 19 online platforms that will be required to comply starting 25 August 2023.[17] They include the following very large online platforms (VLOPs) with more than 45 million monthly active users in the EU as of 17 February 2023.[18] Alibaba AliExpress Amazon Store Apple AppStore Booking.com Facebook Google Play Google Maps Google Shopping Instagram LinkedIn Pinterest PornHub (added 20 December 2023) Shein (added 26 April 2024) Snapchat Stripchat (added 20 December 2023) Temu (added 31 May 2024) TikTok Wikipedia X (formerly Twitter) XNXX (added 10 July 2024) XVideos (added 20 December 2023) YouTube Zalando Very Large Online Search Engines (VLOSEs): Bing Google Search Amazon and Zalando both initiated proceedings in the General Court challenging the designations, claiming unequal treatment compared to other large retailers, and that their core business models are retail not distributing third party content/products. Zalando argued the criteria and methodology lack transparency, for instance in how it counts active users, while Amazon said VLOP rules are disproportionate for its business model and asked to be exempted from transparency around targeted ads.[19][20] As of December 2023, 13 VLOPs have received a request for information (RFI),[16] the procedure necessary to verify compliance with the DSA, and one is being subjected to a formal proceedings.[21] 3 further platforms, all of them providing adult content, were added on 20 December 2023.[22] "
        },
        {
          "title": "Legislative history",
          "content": "The European Commission submitted the DSA alongside the Digital Markets Act (DMA) to the European Parliament and the Council on 15 December 2020.[5][23] The DSA was prepared by von der Leyen Commission members Margrethe Vestager (Executive Vice President of the European Commission for A Europe Fit for the Digital Age) and Thierry Breton (European Commissioner for Internal Market).[24] The Digital Services Act builds in large parts on the non-binding Commission Recommendation 2018/314 of 1 March 2018[25] when it comes to illegal content on platforms. However, it goes further in addressing topics such as disinformation and other risks especially on very large online platforms. As part of the preparatory phase, the European Commission launched a public consultation on the package to gather evidence between July and September 2020.[26][27] An impact assessment was published alongside the proposal on 15 December 2020 with the relevant evidence base.[28] The European Parliament appointed Danish Social Democrat Christel Schaldemose as rapporteur for the Digital Services Act. On 20 January 2022 the Parliament voted to introduce amendments in the DSA for tracking-free advertising and a ban on using a minor's data for targeted ads, as well as a new right for users to seek compensation for damages.[29] In the wake of the Facebook Files revelations and a hearing by Facebook Whistleblower Frances Haugen in the European Parliament,[30] the European Parliament also strengthened the rules on fighting disinformation and harmful content, as well as tougher auditing requirements.[31] The Council of the European Union adopted its position on 25 November 2021.[32] The most significant changes introduced by the Member States are to entrust the European Commission with the enforcement of the new rules, in the wake of allegations and complaints that the Irish Data Protection Watchdog was not effectively policing the bloc's data protection rules against platform companies.[33] The Data Governance Act (DGA) was formally approved by the European Parliament on 6 April 2022.[34] This sets up a legal framework for common data spaces in Europe which will increase data sharing in sectors such as finance, health, and the environment.[34][35] With Russia using social media platforms to spread misinformation about the 2022 Russian invasion of Ukraine, European policymakers felt a greater sense of urgency to move the legislation forward to ensure that major tech platforms were transparent and properly regulated, according to The Washington Post.[36] On 22 April 2022, the Council of the European Union and the European Parliament reached a deal on the Digital Services Act in Brussels following sixteen hours of negotiations.[37][38][39] According to The Washington Post, the agreement reached in Brussels solidifies the two-bill plan— the Digital Services Act and the Digital Markets Act, a law regulating competition. The latter is aimed at preventing abuse of power against smaller competitors by larger \"gatekeepers\".[36] On 5 July 2022, the European Parliament approved both the DSA and the DMA.[40] Following this, on 4 October 2022, the European Council gave its final approval to the DSA.[41] The DSA was adopted on 19 October 2022 and was published in the Official Journal of the European Union on 27 October 2022.[1] It came into force on 16 November 2022.[42] Most services were given 15 months to comply with its provisions (until 17 February 2024[43]). However, \"very large\" online platforms and search engines, after their designation as such, had only four months to comply (until 23 August 2023).[40] "
        },
        {
          "title": "Influence of the European Court of Human Rights",
          "content": "The DSA was passed alongside the Digital Markets Act and the Democracy Action Plan.[44] The latter of these is focused on addressing the nuanced legal interpretation of free speech on digital platforms, a fundamental right that has been extensively guided by the European Court of Human Rights (ECtHR) and the European Convention on Human Rights.[45] Accordingly, the Democracy Action Plan, and subsequently the DSA, were strongly influenced by the Delfi AS v. Estonia and Magyar Tartalomszolgltatk Egyeslete and Index.hu Zrt v. Hungary ECtHR cases, which outlined a framework for assessing intermediary liability on digital platforms.[46] In Delfi AS v. Estonia, the ECtHR applied proportionality analysis when considering whether the Estonian courts' decision to hold the online platform Delfi liable for hate speech posted by its users was a proportionate restriction on Delfi's right to freedom of expression.[47] The court found that, given the serious nature of the hate speech, the Estonian courts' actions were justified to protect the rights of others.[48] In other words, the ECtHR upheld the liability of online platforms for hate speech posted by their users, underlining that platforms could be expected to take proactive steps to control content when there is a clear risk of harm from unlawful comments. This case highlighted the responsibilities of platforms to prevent the spread of harmful content.[47] On the other hand, the MTE and Index.hu v. Hungary case illustrated the nuanced limits of freedom of speech on digital platforms.[49] In its application of proportionality analysis, the ECtHR found that the Hungarian courts had failed to strike a fair balance between protecting reputation and ensuring freedom of expression.[50] The Hungarian courts imposed strict liability on the platforms for user comments that were offensive but did not constitute hate speech, constituting a disproportionate interference in the platforms' right to freedom of expression. The ECtHR ruled that imposing strict liability on platforms for user comments, without consideration of the nature of the comments or the context in which they were made, could infringe on freedom of expression. This judgment emphasized the need for a balance between protecting reputation and upholding free speech on digital platforms.[49] These decisions by the ECtHR provided critical legal precedents that shaped the EU's decision-making process on the framework of the DSA. In particular, the DSA drew from the ECtHR's distinction between different types of illegal content, as well as its proportionality analysis in both cases, by incorporating nuanced rules on intermediary liability and ensuring that measures taken by platforms do not unreasonably restrict users' freedom of expression and information.[51] "
        },
        {
          "title": "Reactions",
          "content": "Media reactions to the Digital Services Act have been mixed. In January 2022, the editorial board of The Washington Post stated that the U.S. could learn from these rules,[52] while whistleblower Frances Haugen stated that it could set a \"gold standard\" of regulation worldwide.[53] Tech journalist Casey Newton has argued that the DSA will shape US tech policy.[54] Mike Masnick of Techdirt praised the DSA for ensuring the right to pay for digital services anonymously, but criticised the act for not including provisions that would have required a court order for the removal of illegal content.[55] Scholars have begun critically examining the Digital Services Act.[56][57] Some academics have expressed concerns that the Digital Services Act might be too rigid and prescribed,[58] excessively focused on individual content decisions or vague risk assessments.[59] Civil Society organisations such as Electronic Frontier Foundation have called for stronger privacy protections.[60] Human Rights Watch has welcomed the transparency and user remedies but called for an end to abusive surveillance and profiling.[61] Amnesty International has welcomed many aspects of the proposal in terms of fundamental rights balance, but also asked for further restrictions on advertising.[62] Advocacy organisation Avaaz has compared the Digital Services Act to the Paris Agreement for climate change.[63] Following the 2023 Hamas-led attack on Israel, Thierry Breton wrote public letters to X, Meta Platforms, TikTok, and YouTube on how their platforms complied with the DSA regarding content related to the conflict and upcoming elections. The Atlantic Council's Digital Forensic Research Lab reported that Breton's letters did not follow DSA processes, and digital rights group Access Now criticised Breton's letters for drawing a \"false equivalence\" between illegal content and disinformation.[64] Tech companies have repeatedly criticised the heavy burden of the rules and the alleged lack of clarity of the Digital Services Act,[65] and have been accused of lobbying to undermine some of the more far-reaching demands by law-makers, notably on bans for targeted advertising,[66] and a high-profile apology from Sundar Pichai to Breton on leaked plans by Google to lobby against the Digital Services Act.[67] A bipartisan group of US senators have called the DSA and DMA discriminatory, claiming that the legislation would \"focus on regulations on a handful of American companies while failing to regulate similar companies based in Europe, China, Russia and elsewhere.\"[68][69] The DSA was mostly welcomed by the European media sector.[70] Due to the influence gatekeepers have in selecting and controlling the visibility of certain journalistic articles over others through their online platforms, the European Federation of Journalists encouraged EU legislators to further increase the transparency of platforms' recommendation systems via the DSA.[71] Nevertheless, the DSA's later stage inter-institutional negotiations, or trilogues, have been criticized as lacking transparency and equitable participation.[72] These criticisms mirror past experiences with the drafting of the EU Regulation on Preventing the Dissemination of Terrorist Content Online as well as the General Data Protection Regulation (GDPR).[73] Swedish member of the European Parliament Jessica Stegrud argued that the DSA's focus on preventing the spread of disinformation and \"harmful content\" would undermine freedom of speech.[74] After the first round of the 2024 Romanian presidential election was invalidated due to reports allegedly showing Russian involvement on TikTok in favor of Călin Georgescu, an investigation was conducted to determine whether TikTok had breached the DSA.[75] "
        },
        {
          "title": "Feature and content removal",
          "content": "In August 2024, TikTok agreed to withdraw its TikTok Lite rewards feature after it was investigated under the DSA due to concerns about its \"addictive effect\", especially for children.[76][77] A 2024 study of deleted Facebook and YouTube comments by the Future of Free Speech think tank at Vanderbilt University suggested that \"platforms, pages, or channels may be over-removing content to avoid regulatory penalties\" under the DSA.[78] "
        },
        {
          "title": "Outside the EU",
          "content": "The Washington Post wrote in 2023 that tech companies may apply features instituted to comply with the DSA to countries outside of the EU, and that researchers have argued that the DSA could provide a framework for the United States to impose stricter regulations on tech companies.[79] The Economist wrote in 2023 that the Brussels effect, whereby social media platforms implement EU regulations globally to save costs, \"is far from guaranteed\" with the DSA due to tech companies being unwilling to \"[lose] sovereignty over their digital territories everywhere\".[80] Among legal academics, Dawn Nunziato of the George Washington University argued in 2022 that the DSA \"will further instantiate the Brussels Effect, whereby EU regulators wield powerful influence on how social media platforms moderate content on the global scale\".[81] Suzanne Vergnolle of the Conservatoire national des arts et mtiers stated her belief in 2023 that the DSA would have a Brussels effect, similar to that of the General Data Protection Regulation, but that \"it's going to take years\".[82] Martin Husovec of the London School of Economics and Jennifer Urban of the University of California, Berkeley wrote in 2024 that \"the chances of spontaneous voluntary implementation beyond the EU's borders for four key parts of the DSA — content moderation procedures, transparency and governance obligations, and risk management rules — seem modest.\"[83] "
        },
        {
          "title": "Similar legislation",
          "content": "The 2023 Brazilian Fake News Bill, a proposed new social media regulation framework introduced in the National Congress, heavily referenced the DSA and contained similar provisions.[84][85] "
        },
        {
          "title": "See also",
          "content": "Digital Markets Act Trade and Technology Council Big Tech Platform economy Online Streaming Act WeChat Transparency and targeting of political advertising "
        },
        {
          "title": "References",
          "content": "^ a b \"Regulation - 2022/2065 - EN - DSA - EUR-Lex\". ^ a b Stolton, Samuel (18 August 2020). \"Digital agenda: Autumn/Winter Policy Briefing\". Euractiv. Archived from the original on 4 September 2020. Retrieved 2 September 2020. ^ a b Espinoza, Javier (28 October 2020). \"Internal Google document reveals campaign against EU lawmakers\". Financial Times. Archived from the original on 30 October 2021. Retrieved 29 October 2020. ^ Gosztonyi, Gergely; Ruszkai, Szonja; Lendvai, Gergely Ferenc (2025). \"The European regulation of porn platforms before and after the Digital Services Act\". Porn Studies: 1–16. doi:10.1080/23268743.2025.2476962. ^ a b \"The Digital Services Act package\". Directorate-General CONNECT of the European Commission. Archived from the original on 17 April 2021. Retrieved 29 December 2020. ^ Roth, Emma (25 August 2023). \"The EU's Digital Services Act goes into effect today: here's what that means\". The Verge. Retrieved 1 August 2024. ^ Candidate for President of the European Commission Ursula von der Leyen, 'A Union that strives for more: My agenda for Europe' (2019) Archived 17 July 2019 at the Wayback Machine (PDF). ^ \"Primacy of EU law\". EUR-Lex. Archived from the original on 10 April 2022. Retrieved 10 April 2022. ^ a b \"The EU's attempt to regulate Big Tech: What it brings and what is missing\". European Digital Rights (EDRi). 18 December 2020. Archived from the original on 16 April 2021. Retrieved 29 December 2020. ^ Wilman, Folkert (19 November 2020). The Responsibility of Online Intermediaries for Illegal User Content in the EU and the US. Edward Elgar. ISBN 978-1-83910-483-1. ^ Johnson, Ashley; Castro, Daniel (22 February 2021). \"How Other Countries Have Dealt With Intermediary Liability\". Information Technology and Innovation Foundation. Archived from the original on 10 April 2022. Retrieved 10 April 2022. ^ \"Questions and answers on the Digital Services Act*\". European Commission. Retrieved 5 September 2024. ^ Bertuzzi, Luca (19 April 2023). \"EU launches research centre on algorithmic transparency\". www.euractiv.com. Archived from the original on 20 April 2023. Retrieved 20 April 2023. ^ Perrigo, Billy (15 December 2020). \"How the E.U's Sweeping New Regulations Against Big Tech Could Have an Impact Beyond Europe\". Time. Archived from the original on 30 October 2021. Retrieved 29 December 2020. ^ \"The Digital Services Act: risk-based regulation of online platforms\". Internet Policy Review. 16 November 2021. Archived from the original on 23 March 2022. Retrieved 10 April 2022. ^ a b \"The enforcement framework under the Digital Services Act | Shaping Europe's digital future\". digital-strategy.ec.europa.eu. Retrieved 19 December 2023. ^ Brodkin, Jon (25 April 2023). \"EU names 19 large tech platforms that must follow Europe's new Internet rules\". Ars Technica. Archived from the original on 25 April 2023. Retrieved 25 April 2023. ^ \"DSA: Very Large Online Platforms and Search Engines\". European Commission - European Commission. Archived from the original on 25 April 2023. Retrieved 26 April 2023. ^ Tar, Julia (11 July 2023). \"Amazon joins Zalando in challenging very large online platform designation\". Euractiv. Retrieved 26 August 2023. ^ Rauer, Nils (13 July 2023). \"Unpacking Amazon's legal challenge to its Digital Services Act designation\". Pinsent Masons. Retrieved 26 August 2023. ^ \"Press corner\". European Commission - European Commission. Retrieved 19 December 2023. ^ \"Commission designates second set of Very Large Online Platforms under the Digital Services Act\". digital-strategy.ec.europa.eu. Retrieved 29 December 2023. ^ Espinoza, Javier; Hindley, Scott (16 December 2019). \"Brussels' plans to tackle digital 'gatekeepers' spark fevered debate\". Financial Times. Archived from the original on 30 October 2021. Retrieved 29 December 2020. ^ \"EU Digital Services Act set to bring in new rules for tech giants\". BBC News. 15 December 2020. Archived from the original on 30 October 2021. Retrieved 24 January 2021. ^ \"Commission Recommendation (EU) 2018/334 of 1 March 2018 on measures to effectively tackle illegal content online\". EUR-Lex. 6 March 2018. ^ \"Press corner\". European Commission - European Commission. Archived from the original on 27 December 2020. Retrieved 2 September 2020. ^ \"Europe asks for views on platform governance and competition tools\". TechCrunch. 2 June 2020. Retrieved 2 September 2020. ^ \"Impact assessment of the Digital Services Act | Shaping Europe's digital future\". digital-strategy.ec.europa.eu. 15 December 2020. Archived from the original on 2 April 2022. Retrieved 10 April 2022. ^ \"Digital Services Act: regulating platforms for a safer online space for users | News | European Parliament\". www.europarl.europa.eu. 20 January 2022. Archived from the original on 8 April 2022. Retrieved 10 April 2022. ^ \"Frances Haugen to MEPs: EU digital rules can be a game changer for the world | News | European Parliament\". www.europarl.europa.eu. 11 August 2021. Archived from the original on 29 March 2022. Retrieved 10 April 2022. ^ \"Facebook whistleblower Frances Haugen speaks to EU parliament\". TechCrunch. 9 November 2021. Retrieved 10 April 2022. ^ \"What is illegal offline should be illegal online: Council agrees position on the Digital Services Act\". www.consilium.europa.eu. Archived from the original on 10 April 2022. Retrieved 10 April 2022. ^ \"Ireland's privacy watchdog sued over Google adtech inaction\". TechCrunch. 15 March 2022. Retrieved 10 April 2022. ^ a b \"Data governance: Parliament approves new rules boosting intra-EU data sharing | News | European Parliament\". 6 April 2022. Archived from the original on 29 April 2022. Retrieved 29 April 2022. ^ Daly, Sidley Austin LLP-Ken; Zdzieborska, Monika; Shajko, Fiona (27 April 2022). \"EU Data Governance Act - Edging Closer to a European Single Market for Data\". Lexology. Archived from the original on 8 June 2022. Retrieved 29 April 2022. ^ a b Zakrzewski, Cat (22 April 2022). \"Europe to slap new regulations on Big Tech, beating U.S. to the punch\". The Washington Post. ISSN 0190-8286. Archived from the original on 23 April 2022. Retrieved 29 April 2022. ^ Satariano, Adam (22 April 2022). \"E.U. Takes Aim at Social Media's Harms With Landmark New Law\". The New York Times. ISSN 0362-4331. Archived from the original on 23 October 2022. Retrieved 29 April 2022. ^ \"Digital Services Act: Commission welcomes political agreement on rules ensuring a safe and accountable online environment\" (Press release). Brussels: European Commission. 23 April 2022. Archived from the original on 23 April 2022. Retrieved 23 April 2022. ^ Foo Yun Chee (22 April 2022). \"EU sets new online rules for Google, Meta to curb illegal content\". Reuters. Archived from the original on 23 April 2022. Retrieved 23 April 2022. ^ a b \"Digital Services: landmark rules adopted for a safer, open online environment\". 5 July 2022. Archived from the original on 16 October 2022. Retrieved 5 July 2022. ^ \"The EU Digital Services Act - Europe's New Regime for Content Moderation\". 4 October 2022. Archived from the original on 10 October 2022. Retrieved 10 October 2022. ^ O'Donnell, Meghan (5 February 2024). \"When Does the Digital Services Act (DSA) Come Into Effect?\". Trolley. Retrieved 1 August 2024. ^ \"Digital Services Act starts applying to all online platforms in the EU\". European Commission. 16 February 2024. Retrieved 1 August 2024. ^ Heldt, Amlie P. (2022), \"EU Digital Services Act: The White Hope of Intermediary Regulation\", Digital Platform Regulation, Palgrave Global Media Policy and Business, Cham: Springer International Publishing, pp. 69–84, doi:10.1007/978-3-030-95220-4_4, ISBN 978-3-030-95219-8, retrieved 16 May 2024 ^ \"Freedom of Expression\", Law, Democracy and the European Court of Human Rights, Cambridge University Press, pp. 84–119, 2 November 2020, doi:10.1017/9781139547246.007, ISBN 978-1-139-54724-6, retrieved 16 May 2024 ^ Ombelet, Pieter-Jan; Kuczerawy, Aleksandra (20 February 2016). \"Delfi revisited: the MTE & Index.hu v. Hungary case\". CiTiP blog. Retrieved 16 May 2024. ^ a b \"Delfi AS v. Estonia\". Global Freedom of Expression. Retrieved 16 May 2024. ^ Susi, Mart (April 2014). \"Delfi AS v. Estonia\". American Journal of International Law. 108 (2): 295–302. doi:10.5305/amerjintelaw.108.2.0295. ISSN 0002-9300. ^ a b \"Magyar Tartalomszolgltatk Egyeslete and Index.hu Zrt v. Hungary\". Global Freedom of Expression. Retrieved 16 May 2024. ^ \"Magyar Tartalomszolgltatk Egyeslete and Index.hu Zrt v. Hungary (2016)\". hudoc.echr.coe.int. Retrieved 16 May 2024. ^ \"The Digital Services Act and the EU as the Global Regulator of the Internet | Chicago Journal of International Law\". cjil.uchicago.edu. Retrieved 16 May 2024. ^ \"The U.S. could learn from Europe's online speech rules\". The Washington Post. ISSN 0190-8286. Archived from the original on 31 January 2022. Retrieved 10 April 2022. ^ \"EU could set 'gold standard' on big tech - Haugen\". RT.ie. 8 November 2021. Archived from the original on 10 April 2022. Retrieved 10 April 2022. ^ \"European values are starting to define U.S. tech privacy, says journalist\". NPR.org. Archived from the original on 10 April 2022. Retrieved 10 April 2022. ^ Masnick, Mike (28 January 2022). \"EU Parliament's 'More Thoughtful' Approach To Regulating The Internet Still A Complete Disaster\". Techdirt. Retrieved 12 October 2023. ^ \"DSA Observatory – a hub of expertise on the DSA package\". Archived from the original on 3 April 2022. Retrieved 10 April 2022. ^ \"DSA in Perspective Seminar Series\". Brussels Privacy Hub. Archived from the original on 16 May 2022. Retrieved 10 April 2022. ^ Keller, Daphne (2022). \"The DSA's Industrial Model for Content Moderation\". Verfassungsblog: On Matters Constitutional (in German). doi:10.17176/20220224-121133-0. Archived from the original on 9 March 2022. Retrieved 10 April 2022. ^ Douek, Evelyn (10 January 2022). \"Content Moderation as Systems Thinking\". Harvard Law Review. 136 (4). doi:10.2139/ssrn.4005326. SSRN 4005326. ^ Schmon, Christoph (20 January 2022). \"DSA: EU Parliament Vote Ensures a Free Internet, But a Final Regulation Must Add Stronger Privacy Protections\". Electronic Frontier Foundation. Archived from the original on 8 April 2022. Retrieved 10 April 2022. ^ \"EU: Put Fundamental Rights at Top of Digital Regulation\". Human Rights Watch. 7 January 2022. Archived from the original on 10 April 2022. Retrieved 10 April 2022. ^ \"Amnesty International Position on the Proposals for a Digital Services Act and a Digital Markets Act\". European Institutions Office. 30 March 2021. Archived from the original on 4 February 2022. Retrieved 10 April 2022. ^ Nicotra, Luca (24 February 2022). \"Could the EU be on the cusp of a Paris Agreement For The Internet?\". www.euractiv.com. Archived from the original on 10 April 2022. Retrieved 10 April 2022. ^ Smalley, Suzanne (27 October 2023). \"European Commission misfires in initial DSA enforcement, experts say\". The Record. Recorded Future. Retrieved 24 March 2024. ^ \"Documents\". Archived from the original on 19 May 2022. Retrieved 10 April 2022. ^ \"How corporate lobbying undermined the EU's push to ban surveillance ads | Corporate Europe Observatory\". corporateeurope.org. Archived from the original on 4 March 2022. Retrieved 10 April 2022. ^ Espinoza, Javier (13 November 2020). \"Google apologises to Thierry Breton over plan to target EU commissioner\". Financial Times. Archived from the original on 10 April 2022. Retrieved 10 April 2022. ^ \"Finance Committee Leaders Wyden and Crapo: Biden Administration Must Fight Back Against Discriminatory Digital Trade Policies | The United States Senate Committee on Finance\". www.finance.senate.gov. Archived from the original on 23 April 2022. Retrieved 10 April 2022. ^ \"Lawmakers Argue Pending European Tech Laws Disadvantage American Firms\". Nextgov.com. 2 February 2022. Archived from the original on 7 March 2022. Retrieved 10 April 2022. ^ Bertuzzi, Luca (25 June 2021). \"Digital Brief: Calls for biometrical ban, online marketplaces' threat, Germany's antitrust crusade\". www.euractiv.com. Archived from the original on 27 June 2021. Retrieved 29 June 2021. ^ Killeen, Molly (25 June 2021). \"Media sector eyes opportunity to rebalance relations with online platforms\". Euractiv. Archived from the original on 26 June 2021. Retrieved 29 June 2021. ^ Allen, Asha (29 April 2022). \"The EU's Opaque Policy-Making Has Never Been Clearer\". WIRED. Archived from the original on 30 April 2022. Retrieved 3 May 2022. ^ Skiera, Bernd; Miller, Klaus; Jin, Yuxi; Kraft, Lennart; Laub, Ren; Schmitt, Julia (2022). Skiera, Bernd (ed.). The impact of the GDPR on the online advertising market. Frankfurt am Main: Skiera, Bernd. ISBN 978-3-9824173-0-1. OCLC 1303894344. ^ Stegrud, Jessica (25 April 2022). \"The EU's Digital Services Act is undermining free speech, Brussels Report\". Brussels Report. Archived from the original on 11 October 2022. Retrieved 11 October 2022. ^ \"TikTok made changes ahead of Romanian election re-run, says Virkkunen\". euronews. 8 April 2025. Retrieved 31 May 2025. ^ The Associated Press (5 August 2024). \"TikTok agrees to withdraw rewards feature after EU raised concerns about potential online addiction\". AP News. Retrieved 30 March 2025. ^ Kroet, Cynthia (5 August 2024). \"TikTok commits to withdraw TikTok Lite from EU\". euronews. Retrieved 30 March 2025. ^ \"Preventing \"Torrents of Hate\" or Stifling Free Expression Online?\". The Future of Free Speech. 28 May 2024. Retrieved 12 March 2025. ^ Velazco, Chris (30 August 2023). \"What the E.U.'s sweeping rules for Big Tech mean for your life online\". The Washington Post. Retrieved 30 March 2025. ^ \"How Europe's new digital law will change the internet\". The Economist. 24 August 2023. Retrieved 30 March 2025. ^ Nunziato, Dawn Carla (22 August 2022). \"The Digital Services Act and the Brussels Effect on Platform Content Moderation\". Chicago Journal of International Law. Retrieved 30 March 2025. ^ Freedman, Robert (23 August 2023). \"Sweeping EU digital misinformation law takes effect\". Legal Dive. Retrieved 30 March 2025. ^ Husovec, Martin; Urban, Jennifer (21 February 2024), Will the DSA have the Brussels Effect?, Verfassungsblog, doi:10.59704/79d561104269780d ^ Boadle, Anthony (2 May 2023). \"Brazil pushes back on big tech firms' campaign against 'fake news law'\". Reuters. Retrieved 30 March 2025. The Brazilian proposal is shaping up to be one of the world's strongest legislations on social media, comparable to the European Union's Digital Services Act enacted last year. ^ Bueno, Thales Martini; Canaan, Renan Gadoni (2024). \"The Brussels Effect in Brazil: Analysing the impact of the EU digital services act on the discussion surrounding the fake news bill\". Telecommunications Policy. 48 (5): 102757. doi:10.1016/j.telpol.2024.102757. "
        },
        {
          "title": "External links",
          "content": "\"The Digital Services Act\". European Commission. 27 October 2022. \"Infographics — Digital Services Act\". 30 September 2022. Retrieved 12 January 2025. Regulation (EU) 2022/2065 of the European Parliament and of the Council of 19 October 2022 on a Single Market For Digital Services and amending Directive 2000/31/EC (Digital Services Act) COM (2020) 825: Proposal for a REGULATION OF THE EUROPEAN PARLIAMENT AND OF THE COUNCIL on a Single Market For Digital Services (Digital Services Act) and amending Directive 2000/31/EC \"Procedure 2020/0361(COD)\". ŒIL. Authority control databases InternationalVIAFNationalGermany VIAF Germany vte Judiciary and law of the European UnionJudiciary Court of Justice of the European Union European Court of Justice members Advocates General General Court Civil Service Tribunal European lawyer Relationship with ECHR Public Prosecutor European civil code Treaties Rome Treaty Merger Treaty Single European Act Maastricht Treaty Amsterdam Treaty Nice Treaty Lisbon Treaty Charter of Fundamental Rights Opt-outs Acts Acquis: Regulation Directive Framework Directive Decision Recommendation Digital Services Act Procedures Ordinary legislative procedure Consultation procedure Consent procedure Commission and Council acting alone Commission acting alone Principlesand terms Acquis communautaire EUR-Lex Direct applicability Direct effect European labour law European Enforcement Order Gold-plating Four freedoms Home state regulation Indirect effect Incidental effect Minimum harmonisation Maximum harmonisation Preliminary ruling Precautionary principle Principle of legal certainty Recasting Principle of conferral Proportionality Staatenverbund State liability Subsidiarity Supremacy Regulations Council Regulation (EC) No. 1206/2001 Council Regulation (EC) No. 1348/2000 Customs Regulation 1383/2003 Regulation (EC) No 261/2004 EU-Eco-regulation Commission Regulation (EC) No. 2257/94 Commission Regulation (EU) No. 1170/2011 Customs Regulation 3295/94 Regulation on roaming charges Brussels Regime CLP Regulation Regulation on Community designs Societas Europaea European Union System for the Evaluation of Substances Commission Regulation (EC) No 474/2006 REACH Rome II Regulation Rule of Law Conditionality Regulation Directives Good Clinical Practice Directive Data Protection Directive ATEX directive Battery Directive Best available technology Biocidal Products Directive Birds Directive Capital Requirements Directives Clinical Trials Directive Computer Programs Directive Conditional Access Directive Copyright Duration Directive (93/98/EEC) Copyright Term Directive (2006/116/EC) Cosmetics Directive Dangerous Substances Directive (67/548/EEC) Dangerous Preparations Directive Data Retention Directive Database Directive Database right Directive 2000/43/EC on Anti-discrimination Directive establishing a general framework for equal treatment in employment and occupation Information Society Directive (first Copyright directive) Directive on Privacy and Electronic Communications Directive on the Promotion of the use of biofuels and other renewable fuels for transport Directive on the re-use of public sector information Directive on Electricity Production from Renewable Energy Sources End of Life Vehicles Directive CHP Directive Directive on the energy performance of buildings Directive on the enforcement of intellectual property rights Directive 2004/38/EC on the right to move and reside freely Environmental liability directive European SEA Directive 2001/42/EC European units of measurement directives Habitats Directive Integrated Pollution Prevention and Control Internal Market in Electricity Directive Landfill Directive Directive on the legal protection of biotechnological inventions Directive on the legal protection of designs Markets in Financial Instruments Directive Measuring Instruments Directive Medical Devices Directive Posted Workers Directive Pressure Equipment Directive Rental Directive Resale Rights Directive Restriction of Hazardous Substances Directive Satellite and Cable Directive Directive on services in the internal market Temporary and Agency Work Directive Trade Marks Directive European Directive on Traditional Herbal Medicinal Products Unfair Commercial Practices Directive Universal Service Directive Urban Waste Water Treatment Directive Waste Electrical and Electronic Equipment Directive Waste Incineration Directive Waste framework directive Water Framework Directive Working Time Directive Cases ECJ Rulings (Caselex): Allonby v Accrington and Rossendale College Apostolides v Orams Bosman Cassis de Dijon Chacn Navas v Eurest Colectividades SA Chen Ciarn Tobin Coleman v Attridge Law Costa v ENEL Factortame Francovich Kamer van Koophandel en Fabrieken voor Amsterdam v Inspire Art Ltd Kolpak Microsoft Corp. v. Commission Marleasing SA v La Comercial Internacional de Alimentacion SA Metock Nordsee Palacios de la Villa v Cortefiel Servicios SA Peter Paul and Others v Bundesrepublik Deutschland Procureur du Roi v Dassonville Ralf Sieckmann v Deutsches Patent und Markenamt Tanja Kreil Van Duyn v Home Office Van Gend en Loos Fraud Court of Auditors European Anti-Fraud Office Accountability in the European Union European Union portal Law portal vte Court of Justice of the European Union European Court of Justice members Advocates General General Court Civil Service Tribunal European lawyer Relationship with ECHR Public Prosecutor European civil code members Advocates General Rome Treaty Merger Treaty Single European Act Maastricht Treaty Amsterdam Treaty Nice Treaty Lisbon Treaty Charter of Fundamental Rights Opt-outs Acquis: Regulation Directive Framework Directive Decision Recommendation Digital Services Act Framework Directive Ordinary legislative procedure Consultation procedure Consent procedure Commission and Council acting alone Commission acting alone Acquis communautaire EUR-Lex Direct applicability Direct effect European labour law European Enforcement Order Gold-plating Four freedoms Home state regulation Indirect effect Incidental effect Minimum harmonisation Maximum harmonisation Preliminary ruling Precautionary principle Principle of legal certainty Recasting Principle of conferral Proportionality Staatenverbund State liability Subsidiarity Supremacy EUR-Lex Council Regulation (EC) No. 1206/2001 Council Regulation (EC) No. 1348/2000 Customs Regulation 1383/2003 Regulation (EC) No 261/2004 EU-Eco-regulation Commission Regulation (EC) No. 2257/94 Commission Regulation (EU) No. 1170/2011 Customs Regulation 3295/94 Regulation on roaming charges Brussels Regime CLP Regulation Regulation on Community designs Societas Europaea European Union System for the Evaluation of Substances Commission Regulation (EC) No 474/2006 REACH Rome II Regulation Rule of Law Conditionality Regulation Good Clinical Practice Directive Data Protection Directive ATEX directive Battery Directive Best available technology Biocidal Products Directive Birds Directive Capital Requirements Directives Clinical Trials Directive Computer Programs Directive Conditional Access Directive Copyright Duration Directive (93/98/EEC) Copyright Term Directive (2006/116/EC) Cosmetics Directive Dangerous Substances Directive (67/548/EEC) Dangerous Preparations Directive Data Retention Directive Database Directive Database right Directive 2000/43/EC on Anti-discrimination Directive establishing a general framework for equal treatment in employment and occupation Information Society Directive (first Copyright directive) Directive on Privacy and Electronic Communications Directive on the Promotion of the use of biofuels and other renewable fuels for transport Directive on the re-use of public sector information Directive on Electricity Production from Renewable Energy Sources End of Life Vehicles Directive CHP Directive Directive on the energy performance of buildings Directive on the enforcement of intellectual property rights Directive 2004/38/EC on the right to move and reside freely Environmental liability directive European SEA Directive 2001/42/EC European units of measurement directives Habitats Directive Integrated Pollution Prevention and Control Internal Market in Electricity Directive Landfill Directive Directive on the legal protection of biotechnological inventions Directive on the legal protection of designs Markets in Financial Instruments Directive Measuring Instruments Directive Medical Devices Directive Posted Workers Directive Pressure Equipment Directive Rental Directive Resale Rights Directive Restriction of Hazardous Substances Directive Satellite and Cable Directive Directive on services in the internal market Temporary and Agency Work Directive Trade Marks Directive European Directive on Traditional Herbal Medicinal Products Unfair Commercial Practices Directive Universal Service Directive Urban Waste Water Treatment Directive Waste Electrical and Electronic Equipment Directive Waste Incineration Directive Waste framework directive Water Framework Directive Working Time Directive ECJ Rulings (Caselex): Allonby v Accrington and Rossendale College Apostolides v Orams Bosman Cassis de Dijon Chacn Navas v Eurest Colectividades SA Chen Ciarn Tobin Coleman v Attridge Law Costa v ENEL Factortame Francovich Kamer van Koophandel en Fabrieken voor Amsterdam v Inspire Art Ltd Kolpak Microsoft Corp. v. Commission Marleasing SA v La Comercial Internacional de Alimentacion SA Metock Nordsee Palacios de la Villa v Cortefiel Servicios SA Peter Paul and Others v Bundesrepublik Deutschland Procureur du Roi v Dassonville Ralf Sieckmann v Deutsches Patent und Markenamt Tanja Kreil Van Duyn v Home Office Van Gend en Loos Court of Auditors European Anti-Fraud Office Accountability in the European Union European Union portal Law portal "
        }
      ],
      "references": [
        "^ a b \"Regulation - 2022/2065 - EN - DSA - EUR-Lex\".",
        "^ a b Stolton, Samuel (18 August 2020). \"Digital agenda: Autumn/Winter Policy Briefing\". Euractiv. Archived from the original on 4 September 2020. Retrieved 2 September 2020.",
        "^ a b Espinoza, Javier (28 October 2020). \"Internal Google document reveals campaign against EU lawmakers\". Financial Times. Archived from the original on 30 October 2021. Retrieved 29 October 2020.",
        "^ Gosztonyi, Gergely; Ruszkai, Szonja; Lendvai, Gergely Ferenc (2025). \"The European regulation of porn platforms before and after the Digital Services Act\". Porn Studies: 1–16. doi:10.1080/23268743.2025.2476962.",
        "^ a b \"The Digital Services Act package\". Directorate-General CONNECT of the European Commission. Archived from the original on 17 April 2021. Retrieved 29 December 2020.",
        "^ Roth, Emma (25 August 2023). \"The EU's Digital Services Act goes into effect today: here's what that means\". The Verge. Retrieved 1 August 2024.",
        "^ Candidate for President of the European Commission Ursula von der Leyen, 'A Union that strives for more: My agenda for Europe' (2019) Archived 17 July 2019 at the Wayback Machine (PDF).",
        "^ \"Primacy of EU law\". EUR-Lex. Archived from the original on 10 April 2022. Retrieved 10 April 2022.",
        "^ a b \"The EU's attempt to regulate Big Tech: What it brings and what is missing\". European Digital Rights (EDRi). 18 December 2020. Archived from the original on 16 April 2021. Retrieved 29 December 2020.",
        "^ Wilman, Folkert (19 November 2020). The Responsibility of Online Intermediaries for Illegal User Content in the EU and the US. Edward Elgar. ISBN 978-1-83910-483-1.",
        "^ Johnson, Ashley; Castro, Daniel (22 February 2021). \"How Other Countries Have Dealt With Intermediary Liability\". Information Technology and Innovation Foundation. Archived from the original on 10 April 2022. Retrieved 10 April 2022.",
        "^ \"Questions and answers on the Digital Services Act*\". European Commission. Retrieved 5 September 2024.",
        "^ Bertuzzi, Luca (19 April 2023). \"EU launches research centre on algorithmic transparency\". www.euractiv.com. Archived from the original on 20 April 2023. Retrieved 20 April 2023.",
        "^ Perrigo, Billy (15 December 2020). \"How the E.U's Sweeping New Regulations Against Big Tech Could Have an Impact Beyond Europe\". Time. Archived from the original on 30 October 2021. Retrieved 29 December 2020.",
        "^ \"The Digital Services Act: risk-based regulation of online platforms\". Internet Policy Review. 16 November 2021. Archived from the original on 23 March 2022. Retrieved 10 April 2022.",
        "^ a b \"The enforcement framework under the Digital Services Act | Shaping Europe's digital future\". digital-strategy.ec.europa.eu. Retrieved 19 December 2023.",
        "^ Brodkin, Jon (25 April 2023). \"EU names 19 large tech platforms that must follow Europe's new Internet rules\". Ars Technica. Archived from the original on 25 April 2023. Retrieved 25 April 2023.",
        "^ \"DSA: Very Large Online Platforms and Search Engines\". European Commission - European Commission. Archived from the original on 25 April 2023. Retrieved 26 April 2023.",
        "^ Tar, Julia (11 July 2023). \"Amazon joins Zalando in challenging very large online platform designation\". Euractiv. Retrieved 26 August 2023.",
        "^ Rauer, Nils (13 July 2023). \"Unpacking Amazon's legal challenge to its Digital Services Act designation\". Pinsent Masons. Retrieved 26 August 2023.",
        "^ \"Press corner\". European Commission - European Commission. Retrieved 19 December 2023.",
        "^ \"Commission designates second set of Very Large Online Platforms under the Digital Services Act\". digital-strategy.ec.europa.eu. Retrieved 29 December 2023.",
        "^ Espinoza, Javier; Hindley, Scott (16 December 2019). \"Brussels' plans to tackle digital 'gatekeepers' spark fevered debate\". Financial Times. Archived from the original on 30 October 2021. Retrieved 29 December 2020.",
        "^ \"EU Digital Services Act set to bring in new rules for tech giants\". BBC News. 15 December 2020. Archived from the original on 30 October 2021. Retrieved 24 January 2021.",
        "^ \"Commission Recommendation (EU) 2018/334 of 1 March 2018 on measures to effectively tackle illegal content online\". EUR-Lex. 6 March 2018.",
        "^ \"Press corner\". European Commission - European Commission. Archived from the original on 27 December 2020. Retrieved 2 September 2020.",
        "^ \"Europe asks for views on platform governance and competition tools\". TechCrunch. 2 June 2020. Retrieved 2 September 2020.",
        "^ \"Impact assessment of the Digital Services Act | Shaping Europe's digital future\". digital-strategy.ec.europa.eu. 15 December 2020. Archived from the original on 2 April 2022. Retrieved 10 April 2022.",
        "^ \"Digital Services Act: regulating platforms for a safer online space for users | News | European Parliament\". www.europarl.europa.eu. 20 January 2022. Archived from the original on 8 April 2022. Retrieved 10 April 2022.",
        "^ \"Frances Haugen to MEPs: EU digital rules can be a game changer for the world | News | European Parliament\". www.europarl.europa.eu. 11 August 2021. Archived from the original on 29 March 2022. Retrieved 10 April 2022.",
        "^ \"Facebook whistleblower Frances Haugen speaks to EU parliament\". TechCrunch. 9 November 2021. Retrieved 10 April 2022.",
        "^ \"What is illegal offline should be illegal online: Council agrees position on the Digital Services Act\". www.consilium.europa.eu. Archived from the original on 10 April 2022. Retrieved 10 April 2022.",
        "^ \"Ireland's privacy watchdog sued over Google adtech inaction\". TechCrunch. 15 March 2022. Retrieved 10 April 2022.",
        "^ a b \"Data governance: Parliament approves new rules boosting intra-EU data sharing | News | European Parliament\". 6 April 2022. Archived from the original on 29 April 2022. Retrieved 29 April 2022.",
        "^ Daly, Sidley Austin LLP-Ken; Zdzieborska, Monika; Shajko, Fiona (27 April 2022). \"EU Data Governance Act - Edging Closer to a European Single Market for Data\". Lexology. Archived from the original on 8 June 2022. Retrieved 29 April 2022.",
        "^ a b Zakrzewski, Cat (22 April 2022). \"Europe to slap new regulations on Big Tech, beating U.S. to the punch\". The Washington Post. ISSN 0190-8286. Archived from the original on 23 April 2022. Retrieved 29 April 2022.",
        "^ Satariano, Adam (22 April 2022). \"E.U. Takes Aim at Social Media's Harms With Landmark New Law\". The New York Times. ISSN 0362-4331. Archived from the original on 23 October 2022. Retrieved 29 April 2022.",
        "^ \"Digital Services Act: Commission welcomes political agreement on rules ensuring a safe and accountable online environment\" (Press release). Brussels: European Commission. 23 April 2022. Archived from the original on 23 April 2022. Retrieved 23 April 2022.",
        "^ Foo Yun Chee (22 April 2022). \"EU sets new online rules for Google, Meta to curb illegal content\". Reuters. Archived from the original on 23 April 2022. Retrieved 23 April 2022.",
        "^ a b \"Digital Services: landmark rules adopted for a safer, open online environment\". 5 July 2022. Archived from the original on 16 October 2022. Retrieved 5 July 2022.",
        "^ \"The EU Digital Services Act - Europe's New Regime for Content Moderation\". 4 October 2022. Archived from the original on 10 October 2022. Retrieved 10 October 2022.",
        "^ O'Donnell, Meghan (5 February 2024). \"When Does the Digital Services Act (DSA) Come Into Effect?\". Trolley. Retrieved 1 August 2024.",
        "^ \"Digital Services Act starts applying to all online platforms in the EU\". European Commission. 16 February 2024. Retrieved 1 August 2024.",
        "^ Heldt, Amlie P. (2022), \"EU Digital Services Act: The White Hope of Intermediary Regulation\", Digital Platform Regulation, Palgrave Global Media Policy and Business, Cham: Springer International Publishing, pp. 69–84, doi:10.1007/978-3-030-95220-4_4, ISBN 978-3-030-95219-8, retrieved 16 May 2024",
        "^ \"Freedom of Expression\", Law, Democracy and the European Court of Human Rights, Cambridge University Press, pp. 84–119, 2 November 2020, doi:10.1017/9781139547246.007, ISBN 978-1-139-54724-6, retrieved 16 May 2024",
        "^ Ombelet, Pieter-Jan; Kuczerawy, Aleksandra (20 February 2016). \"Delfi revisited: the MTE & Index.hu v. Hungary case\". CiTiP blog. Retrieved 16 May 2024.",
        "^ a b \"Delfi AS v. Estonia\". Global Freedom of Expression. Retrieved 16 May 2024.",
        "^ Susi, Mart (April 2014). \"Delfi AS v. Estonia\". American Journal of International Law. 108 (2): 295–302. doi:10.5305/amerjintelaw.108.2.0295. ISSN 0002-9300.",
        "^ a b \"Magyar Tartalomszolgltatk Egyeslete and Index.hu Zrt v. Hungary\". Global Freedom of Expression. Retrieved 16 May 2024.",
        "^ \"Magyar Tartalomszolgltatk Egyeslete and Index.hu Zrt v. Hungary (2016)\". hudoc.echr.coe.int. Retrieved 16 May 2024.",
        "^ \"The Digital Services Act and the EU as the Global Regulator of the Internet | Chicago Journal of International Law\". cjil.uchicago.edu. Retrieved 16 May 2024.",
        "^ \"The U.S. could learn from Europe's online speech rules\". The Washington Post. ISSN 0190-8286. Archived from the original on 31 January 2022. Retrieved 10 April 2022.",
        "^ \"EU could set 'gold standard' on big tech - Haugen\". RT.ie. 8 November 2021. Archived from the original on 10 April 2022. Retrieved 10 April 2022.",
        "^ \"European values are starting to define U.S. tech privacy, says journalist\". NPR.org. Archived from the original on 10 April 2022. Retrieved 10 April 2022.",
        "^ Masnick, Mike (28 January 2022). \"EU Parliament's 'More Thoughtful' Approach To Regulating The Internet Still A Complete Disaster\". Techdirt. Retrieved 12 October 2023.",
        "^ \"DSA Observatory – a hub of expertise on the DSA package\". Archived from the original on 3 April 2022. Retrieved 10 April 2022.",
        "^ \"DSA in Perspective Seminar Series\". Brussels Privacy Hub. Archived from the original on 16 May 2022. Retrieved 10 April 2022.",
        "^ Keller, Daphne (2022). \"The DSA's Industrial Model for Content Moderation\". Verfassungsblog: On Matters Constitutional (in German). doi:10.17176/20220224-121133-0. Archived from the original on 9 March 2022. Retrieved 10 April 2022.",
        "^ Douek, Evelyn (10 January 2022). \"Content Moderation as Systems Thinking\". Harvard Law Review. 136 (4). doi:10.2139/ssrn.4005326. SSRN 4005326.",
        "^ Schmon, Christoph (20 January 2022). \"DSA: EU Parliament Vote Ensures a Free Internet, But a Final Regulation Must Add Stronger Privacy Protections\". Electronic Frontier Foundation. Archived from the original on 8 April 2022. Retrieved 10 April 2022.",
        "^ \"EU: Put Fundamental Rights at Top of Digital Regulation\". Human Rights Watch. 7 January 2022. Archived from the original on 10 April 2022. Retrieved 10 April 2022.",
        "^ \"Amnesty International Position on the Proposals for a Digital Services Act and a Digital Markets Act\". European Institutions Office. 30 March 2021. Archived from the original on 4 February 2022. Retrieved 10 April 2022.",
        "^ Nicotra, Luca (24 February 2022). \"Could the EU be on the cusp of a Paris Agreement For The Internet?\". www.euractiv.com. Archived from the original on 10 April 2022. Retrieved 10 April 2022.",
        "^ Smalley, Suzanne (27 October 2023). \"European Commission misfires in initial DSA enforcement, experts say\". The Record. Recorded Future. Retrieved 24 March 2024.",
        "^ \"Documents\". Archived from the original on 19 May 2022. Retrieved 10 April 2022.",
        "^ \"How corporate lobbying undermined the EU's push to ban surveillance ads | Corporate Europe Observatory\". corporateeurope.org. Archived from the original on 4 March 2022. Retrieved 10 April 2022.",
        "^ Espinoza, Javier (13 November 2020). \"Google apologises to Thierry Breton over plan to target EU commissioner\". Financial Times. Archived from the original on 10 April 2022. Retrieved 10 April 2022.",
        "^ \"Finance Committee Leaders Wyden and Crapo: Biden Administration Must Fight Back Against Discriminatory Digital Trade Policies | The United States Senate Committee on Finance\". www.finance.senate.gov. Archived from the original on 23 April 2022. Retrieved 10 April 2022.",
        "^ \"Lawmakers Argue Pending European Tech Laws Disadvantage American Firms\". Nextgov.com. 2 February 2022. Archived from the original on 7 March 2022. Retrieved 10 April 2022.",
        "^ Bertuzzi, Luca (25 June 2021). \"Digital Brief: Calls for biometrical ban, online marketplaces' threat, Germany's antitrust crusade\". www.euractiv.com. Archived from the original on 27 June 2021. Retrieved 29 June 2021.",
        "^ Killeen, Molly (25 June 2021). \"Media sector eyes opportunity to rebalance relations with online platforms\". Euractiv. Archived from the original on 26 June 2021. Retrieved 29 June 2021.",
        "^ Allen, Asha (29 April 2022). \"The EU's Opaque Policy-Making Has Never Been Clearer\". WIRED. Archived from the original on 30 April 2022. Retrieved 3 May 2022.",
        "^ Skiera, Bernd; Miller, Klaus; Jin, Yuxi; Kraft, Lennart; Laub, Ren; Schmitt, Julia (2022). Skiera, Bernd (ed.). The impact of the GDPR on the online advertising market. Frankfurt am Main: Skiera, Bernd. ISBN 978-3-9824173-0-1. OCLC 1303894344.",
        "^ Stegrud, Jessica (25 April 2022). \"The EU's Digital Services Act is undermining free speech, Brussels Report\". Brussels Report. Archived from the original on 11 October 2022. Retrieved 11 October 2022.",
        "^ \"TikTok made changes ahead of Romanian election re-run, says Virkkunen\". euronews. 8 April 2025. Retrieved 31 May 2025.",
        "^ The Associated Press (5 August 2024). \"TikTok agrees to withdraw rewards feature after EU raised concerns about potential online addiction\". AP News. Retrieved 30 March 2025.",
        "^ Kroet, Cynthia (5 August 2024). \"TikTok commits to withdraw TikTok Lite from EU\". euronews. Retrieved 30 March 2025.",
        "^ \"Preventing \"Torrents of Hate\" or Stifling Free Expression Online?\". The Future of Free Speech. 28 May 2024. Retrieved 12 March 2025.",
        "^ Velazco, Chris (30 August 2023). \"What the E.U.'s sweeping rules for Big Tech mean for your life online\". The Washington Post. Retrieved 30 March 2025.",
        "^ \"How Europe's new digital law will change the internet\". The Economist. 24 August 2023. Retrieved 30 March 2025.",
        "^ Nunziato, Dawn Carla (22 August 2022). \"The Digital Services Act and the Brussels Effect on Platform Content Moderation\". Chicago Journal of International Law. Retrieved 30 March 2025.",
        "^ Freedman, Robert (23 August 2023). \"Sweeping EU digital misinformation law takes effect\". Legal Dive. Retrieved 30 March 2025.",
        "^ Husovec, Martin; Urban, Jennifer (21 February 2024), Will the DSA have the Brussels Effect?, Verfassungsblog, doi:10.59704/79d561104269780d",
        "^ Boadle, Anthony (2 May 2023). \"Brazil pushes back on big tech firms' campaign against 'fake news law'\". Reuters. Retrieved 30 March 2025. The Brazilian proposal is shaping up to be one of the world's strongest legislations on social media, comparable to the European Union's Digital Services Act enacted last year.",
        "^ Bueno, Thales Martini; Canaan, Renan Gadoni (2024). \"The Brussels Effect in Brazil: Analysing the impact of the EU digital services act on the discussion surrounding the fake news bill\". Telecommunications Policy. 48 (5): 102757. doi:10.1016/j.telpol.2024.102757."
      ],
      "content_type": "wikipedia",
      "word_count": 6254,
      "char_count": 43149
    },
    {
      "url": "https://leginfo.legislature.ca.gov/faces/billTextClient.xhtml?bill_id=202320240SB976",
      "title": "Bill Text - SB-976 Protecting Our Kids from Social Media Addiction Act.",
      "description": "SB 976 Protecting Our Kids from Social Media Addiction Act.",
      "keywords": "California Bill SB 976, CA SB 976, SB 976, 20232024 SB 976, 2023 2024 SB 976, 2023 SB 976",
      "author": "",
      "published_date": "",
      "scraped_at": "2025-08-28T01:34:45.814429",
      "sections": [
        {
          "title": "Main Content",
          "content": "skip to content home accessibility FAQ feedback sitemap login x Quick Search: Bill Number Bill Keyword skip to content home accessibility FAQ feedback sitemap login x Quick Search: Bill Number Bill Keyword Quick Search: Bill Number Bill Keyword Quick Search: Bill Number Bill Keyword Home Bill Information California Law Publications Other Resources My Subscriptions My Favorites Bill Information >> Bill Search >> Text Bill Text PDF2 Bill PDF |Add To My Favorites | Version: 09/20/24 - Chaptered 09/05/24 - Enrolled 08/22/24 - Amended Assembly 08/19/24 - Amended Assembly 07/03/24 - Amended Assembly 06/18/24 - Amended Assembly 04/25/24 - Amended Senate 03/19/24 - Amended Senate 01/29/24 - Introduced SB-976 Protecting Our Kids from Social Media Addiction Act.(2023-2024) Text >> Votes >> History >> Bill Analysis >> Today's Law As Amended >> Compare Versions >> Status >> Comments To Author >> Add To My Favorites >> SHARE THIS: Date Published: 09/23/2024 09:00 PM SB976:v91#DOCUMENTBill Start Senate Bill No. 976 CHAPTER 321An act to add Chapter 24 (commencing with Section 27000) to Division 20 of the Health and Safety Code, relating to youth addiction. [ Approved by Governor September 20, 2024. Filed with Secretary of State September 20, 2024. ] LEGISLATIVE COUNSEL'S DIGESTSB 976, Skinner. Protecting Our Kids from Social Media Addiction Act.Existing law, the California Age-Appropriate Design Code Act, requires, beginning July 1, 2024, a business that provides an online service, product, or feature likely to be accessed by children to comply with certain requirements. The act requires the business to complete a data protection impact assessment addressing, among other things, whether the design could harm children and whether and how the online product, service, or feature uses system design features to increase, sustain, or extend use of the online product, service, or feature by children, including the automatic playing of media, rewards for time spent, and notifications. Existing law prohibits the business from using the personal information of any child in a way that the business knows, or has reason to know, is materially detrimental to the physical health, mental health, or well-being of a child.Existing law, the Privacy Rights for California Minors in the Digital World, prohibits an operator of an internet website, online service, online application, or mobile application from specified conduct when minors are involved, including the marketing or advertising of alcoholic beverages, firearms, or certain other products or services. Existing law sets forth other related protections for minors, including under the California Consumer Privacy Act of 2018 and the California Privacy Rights Act of 2020.This bill, the Protecting Our Kids from Social Media Addiction Act, would make it unlawful for the operator of an addictive internet-based service or application, as defined, to provide an addictive feed to a user, unless the operator does not have actual knowledge that the user is a minor; commencing January 1, 2027, has reasonably determined that the user is not a minor; or has obtained verifiable parental consent to provide an addictive feed to the user who is a minor.The bill would define “addictive feed” as an internet website, online service, online application, or mobile application, in which multiple pieces of media generated or shared by users are recommended, selected, or prioritized for display to a user based on information provided by the user, or otherwise associated with the user or the user’s device, as specified, unless any of certain conditions are met.The bill would make it unlawful for the operator of an addictive internet-based service or application, between the hours of 12 a.m. and 6 a.m., in the user’s local time zone, and between the hours of 8 a.m. and 3 p.m., Monday through Friday from September through May in the user’s local time zone, to send notifications to a user if the operator has actual knowledge that the user is a minor or, commencing January 1, 2027, has not reasonably determined that the user is not a minor, unless the operator has obtained verifiable parental consent to send those notifications, as specified. The bill would set forth related provisions for certain access controls determined by the verified parent through a mechanism provided by the operator.Under the bill, a parent’s provision of consent or use of a mechanism, as described above, would not waive, release, otherwise limit, or serve as a defense to, any claim that the parent, or that the user who is a minor or was a minor at the time of using the internet-based service or application, might have against the operator regarding any harm to the mental health or well-being of the user.The bill would require an operator to annually disclose the number of minor users of its addictive internet-based service or application, and of that total the number for whom the operator has received verifiable parental consent to provide an addictive feed, and the number of minor users as to whom the access controls are or are not enabled.Under the bill, these provisions would only be enforced in a civil action brought in the name of the people of the State of California by the Attorney General. The bill would require the Attorney General to adopt regulations to further the purposes of these provisions, including regulations regarding age assurance and parental consent by January 1, 2027. The bill would authorize the Attorney General to adopt regulations that provide for exceptions to these provisions, but only if those exceptions further the purpose of protecting minors. The bill would require the Attorney General, in promulgating regulations, to solicit public comment regarding the impact that any regulation might have based on certain nondiscrimination characteristics set forth in existing law.The bill would make these provisions severable.Digest Key Vote: MAJORITY Appropriation: NO Fiscal Committee: YES Local Program: NO Bill TextThe people of the State of California do enact as follows:SECTION 1. The Legislature finds and declares the following:(a) Social media provides an important tool for communication and information sharing. Approximately 95 percent of 13- to 17-year-olds, inclusive, say that they use at least one social media platform, and more than one-third report using social media almost constantly.(b) However, some social media platforms have evolved to include addictive features, including the algorithmic delivery of content and other design features, that pose a significant risk of harm to the mental health and well-being of children and adolescents.(c) As the United States Surgeon General has reported, recent evidence has identified “reasons for concern” about social media usage by children and adolescents. This evidence includes a study concluding that the risk of poor mental health outcomes doubles for children and adolescents who use social media at least three hours a day and research finding that social media usage is linked to a variety of negative health outcomes, including low self-esteem and disordered eating, for adolescent girls. (d) Heavier usage of social media also leads to less healthy sleep patterns and sleep quality, which can in turn exacerbate both physical and mental health problems.(e) Further, social media usage is more strongly associated with negative mental health outcomes, including depressive symptoms and self-harm behaviors, than is consumption of other forms of media such as television or electronic games. (f) Both California and the country as a whole are facing an ongoing youth mental health crisis, with rates of adolescent suicides, depressive episodes, and feelings of sadness and hopelessness on the rise in recent years. (g) For these reasons, it is essential that California act to ensure that social media platforms obtain parental consent before exposing children and adolescents to harmful and addictive social media features.SEC. 2. Chapter 24 (commencing with Section 27000) is added to Division 20 of the Health and Safety Code, to read: CHAPTER 24. Protecting Our Kids from Social Media Addiction Act27000. This chapter shall be known, and may be cited, as the Protecting Our Kids from Social Media Addiction Act.27000.5. For purposes of this chapter, the following terms have the following meanings:(a) “Addictive feed” means an internet website, online service, online application, or mobile application, or a portion thereof, in which multiple pieces of media generated or shared by users are, either concurrently or sequentially, recommended, selected, or prioritized for display to a user based, in whole or in part, on information provided by the user, or otherwise associated with the user or the user’s device, unless any of the following conditions are met, alone or in combination with one another:(1) The information is not persistently associated with the user or user’s device, and does not concern the user’s previous interactions with media generated or shared by others.(2) The information consists of search terms that are not persistently associated with the user or user’s device.(3) The information consists of user-selected privacy or accessibility settings, technical information concerning the user’s device, or device communications or signals concerning whether the user is a minor.(4) The user expressly and unambiguously requested the specific media or media by the author, creator, or poster of the media, or the blocking, prioritization, or deprioritization of such media, provided that the media is not recommended, selected, or prioritized for display based, in whole or in part, on other information associated with the user or the user’s device, except as otherwise permitted by this chapter and, in the case of audio or video content, is not automatically played.(5) The media consists of direct, private communications between users.(6) The media recommended, selected, or prioritized for display is exclusively the next media in a preexisting sequence from the same author, creator, poster, or source and, in the case of audio or video content, is not automatically played.(7) The recommendation, selection, or prioritization of the media is necessary to comply with this chapter or any regulations promulgated pursuant to this chapter.(b) (1) “Addictive internet-based service or application” means an internet website, online service, online application, or mobile application, including, but not limited to, a “social media platform” as defined in Section 22675 of the Business and Professions Code, that offers users or provides users with an addictive feed as a significant part of the service provided by that internet website, online service, online application, or mobile application.(2) “Addictive internet-based service or application” does not apply to either of the following:(A) An internet website, online service, online application, or mobile application for which interactions between users are limited to commercial transactions or to consumer reviews of products, sellers, services, events, or places, or any combination thereof.(B) An internet website, online service, online application, or mobile application that operates a feed for the primary purpose of cloud storage.(c) “Media” means text, audio, an image, or a video.(d) “Minor” means an individual under 18 years of age who is located in the State of California.(e) “Operator” means a person who operates or provides an internet website, an online service, an online application, or a mobile application.(f) “Parent” means a parent or guardian, including as defined in regulations promulgated pursuant to this chapter.(g) “User” means a person who uses an internet website, online service, online application, or mobile application. “User” does not include the operator or a person acting as an agent of the operator.27001. (a) It shall be unlawful for the operator of an addictive internet-based service or application to provide an addictive feed to a user unless either of the following is met:(1) (A) Except as provided in subparagraph (B), the operator does not have actual knowledge that the user is a minor.(B) Commencing January 1, 2027, the operator has reasonably determined that the user is not a minor, including pursuant to regulations promulgated by the Attorney General.(2) The operator has obtained verifiable parental consent to provide an addictive feed to the user who is a minor.(b) Information collected for the purpose of determining a user’s age or verifying parental consent pursuant to this chapter shall not be used for any purpose other than compliance with this chapter or with another applicable law. The information collected shall be deleted immediately after it is used to determine a user’s age or to verify parental consent, except as necessary to comply with state or federal law.27002. (a) (1) Except as provided in paragraph (2), it shall be unlawful for the operator of an addictive internet-based service or application, between the hours of 12 a.m. and 6 a.m., in the user’s local time zone, and between the hours of 8 a.m. and 3 p.m., from Monday through Friday from September through May in the user’s local time zone, to send notifications to a user if the operator has actual knowledge that the user is a minor unless the operator has obtained verifiable parental consent to send those notifications.(2) Commencing January 1, 2027, it shall be unlawful for the operator of an addictive internet-based service or application, between the hours of 12 a.m. and 6 a.m., in the user’s local time zone, and between the hours of 8 a.m. and 3 p.m., from Monday through Friday from September through May in the user’s local time zone, to send notifications to a user whom the operator has not reasonably determined is not a minor, including pursuant to regulations promulgated by the Attorney General, unless the operator has obtained verifiable parental consent to send those notifications.(b) The operator of an addictive internet-based service or application shall provide a mechanism through which the verified parent of a user who is a minor may do any of the following:(1) Prevent their child from accessing or receiving notifications from the addictive internet-based service or application between specific hours chosen by the parent. This setting shall be set by the operator as on by default, in a manner in which the child’s access is limited between the hours of 12 a.m. and 6 a.m., in the user’s local time zone.(2) Limit their child’s access to any addictive feed from the addictive internet-based service or application to a length of time per day specified by the verified parent. This setting shall be set by the operator as on by default, in a manner in which the child’s access is limited to one hour per day unless modified by the verified parent.(3) Limit their child’s ability to view the number of likes or other forms of feedback to pieces of media within an addictive feed. This setting shall be set by the operator as on by default.(4) Require that the default feed provided to the child when entering the internet-based service or application be one in which pieces of media are not recommended, selected, or prioritized for display based on information provided by the user, or otherwise associated with the user or the user’s device, other than the user’s age or status as a minor.(5) Set their child’s account to private mode, in a manner in which only users to whom the child is connected on the addictive internet-based service or application may view or respond to content posted by the child. This setting shall be set by the operator as on by default.27003. (a) This chapter shall not be construed as requiring the operator of an addictive internet-based service or application to give a parent any additional or special access to, or control over, the data or accounts of their child.(b) This chapter shall not be construed as preventing any action taken in good faith to restrict access to, or availability of, media.27004. (a) An operator may choose not to provide services to minors. However, the operator of an addictive internet-based service or application shall not withhold, degrade, lower the quality of, or increase the price of, any product, service, or feature, other than as required by this chapter, due to a user or parent availing themselves of the rights provided by this chapter, or due to the protections required by this chapter.(b) A parent’s provision of consent as described in Section 27001 or 27002, or the use by a parent of a mechanism as described in Section 27002, does not waive, release, otherwise limit, or serve as a defense to, any claim that the parent, or that the user who is a minor or was a minor at the time of using the internet-based service or application, might have against the operator of an addictive internet-based service or application regarding any harm to the mental health or well-being of the user.(c) The protections provided by this chapter are in addition to those provided by any other applicable law, including, but not limited to, the California Age-Appropriate Design Code Act (Title 1.81.47 (commencing with Section 1798.99.28) of Part 4 of Division 3 of the Civil Code).27005. An operator of an addictive internet-based service or application shall publicly disclose, on an annual basis, the number of minor users of its addictive internet-based service or application, and of that total the number for whom the operator has received verifiable parental consent to provide an addictive feed, and the number of minor users as to whom the controls set forth in Section 27002 are or are not enabled. 27006. (a) This chapter may only be enforced in a civil action brought in the name of the people of the State of California by the Attorney General.(b) The Attorney General shall adopt regulations to further the purposes of this chapter, including regulations regarding age assurance and parental consent by January 1, 2027. The Attorney General may adopt regulations that provide for exceptions to this chapter, but only if those exceptions further the purpose of protecting minors.(c) In promulgating the regulations described in subdivision (b), the Attorney General shall solicit public comment regarding the impact that any regulation might have based on the nondiscrimination characteristics set forth in Section 51 of the Civil Code or in any other applicable law.27007. If any provision of this chapter, or application thereof, to any person or circumstance is held invalid, that invalidity shall not affect other provisions or applications of this chapter that can be given effect without the invalid provision or application, and to this end the provisions of this chapter are declared to be severable. Bill Information >> Bill Search >> Text Bill Text PDF2 Bill PDF |Add To My Favorites | Version: 09/20/24 - Chaptered 09/05/24 - Enrolled 08/22/24 - Amended Assembly 08/19/24 - Amended Assembly 07/03/24 - Amended Assembly 06/18/24 - Amended Assembly 04/25/24 - Amended Senate 03/19/24 - Amended Senate 01/29/24 - Introduced SB-976 Protecting Our Kids from Social Media Addiction Act.(2023-2024) Text >> Votes >> History >> Bill Analysis >> Today's Law As Amended >> Compare Versions >> Status >> Comments To Author >> Add To My Favorites >> SHARE THIS: Date Published: 09/23/2024 09:00 PM SB976:v91#DOCUMENTBill Start Senate Bill No. 976 CHAPTER 321An act to add Chapter 24 (commencing with Section 27000) to Division 20 of the Health and Safety Code, relating to youth addiction. [ Approved by Governor September 20, 2024. Filed with Secretary of State September 20, 2024. ] LEGISLATIVE COUNSEL'S DIGESTSB 976, Skinner. Protecting Our Kids from Social Media Addiction Act.Existing law, the California Age-Appropriate Design Code Act, requires, beginning July 1, 2024, a business that provides an online service, product, or feature likely to be accessed by children to comply with certain requirements. The act requires the business to complete a data protection impact assessment addressing, among other things, whether the design could harm children and whether and how the online product, service, or feature uses system design features to increase, sustain, or extend use of the online product, service, or feature by children, including the automatic playing of media, rewards for time spent, and notifications. Existing law prohibits the business from using the personal information of any child in a way that the business knows, or has reason to know, is materially detrimental to the physical health, mental health, or well-being of a child.Existing law, the Privacy Rights for California Minors in the Digital World, prohibits an operator of an internet website, online service, online application, or mobile application from specified conduct when minors are involved, including the marketing or advertising of alcoholic beverages, firearms, or certain other products or services. Existing law sets forth other related protections for minors, including under the California Consumer Privacy Act of 2018 and the California Privacy Rights Act of 2020.This bill, the Protecting Our Kids from Social Media Addiction Act, would make it unlawful for the operator of an addictive internet-based service or application, as defined, to provide an addictive feed to a user, unless the operator does not have actual knowledge that the user is a minor; commencing January 1, 2027, has reasonably determined that the user is not a minor; or has obtained verifiable parental consent to provide an addictive feed to the user who is a minor.The bill would define “addictive feed” as an internet website, online service, online application, or mobile application, in which multiple pieces of media generated or shared by users are recommended, selected, or prioritized for display to a user based on information provided by the user, or otherwise associated with the user or the user’s device, as specified, unless any of certain conditions are met.The bill would make it unlawful for the operator of an addictive internet-based service or application, between the hours of 12 a.m. and 6 a.m., in the user’s local time zone, and between the hours of 8 a.m. and 3 p.m., Monday through Friday from September through May in the user’s local time zone, to send notifications to a user if the operator has actual knowledge that the user is a minor or, commencing January 1, 2027, has not reasonably determined that the user is not a minor, unless the operator has obtained verifiable parental consent to send those notifications, as specified. The bill would set forth related provisions for certain access controls determined by the verified parent through a mechanism provided by the operator.Under the bill, a parent’s provision of consent or use of a mechanism, as described above, would not waive, release, otherwise limit, or serve as a defense to, any claim that the parent, or that the user who is a minor or was a minor at the time of using the internet-based service or application, might have against the operator regarding any harm to the mental health or well-being of the user.The bill would require an operator to annually disclose the number of minor users of its addictive internet-based service or application, and of that total the number for whom the operator has received verifiable parental consent to provide an addictive feed, and the number of minor users as to whom the access controls are or are not enabled.Under the bill, these provisions would only be enforced in a civil action brought in the name of the people of the State of California by the Attorney General. The bill would require the Attorney General to adopt regulations to further the purposes of these provisions, including regulations regarding age assurance and parental consent by January 1, 2027. The bill would authorize the Attorney General to adopt regulations that provide for exceptions to these provisions, but only if those exceptions further the purpose of protecting minors. The bill would require the Attorney General, in promulgating regulations, to solicit public comment regarding the impact that any regulation might have based on certain nondiscrimination characteristics set forth in existing law.The bill would make these provisions severable.Digest Key Vote: MAJORITY Appropriation: NO Fiscal Committee: YES Local Program: NO Bill TextThe people of the State of California do enact as follows:SECTION 1. The Legislature finds and declares the following:(a) Social media provides an important tool for communication and information sharing. Approximately 95 percent of 13- to 17-year-olds, inclusive, say that they use at least one social media platform, and more than one-third report using social media almost constantly.(b) However, some social media platforms have evolved to include addictive features, including the algorithmic delivery of content and other design features, that pose a significant risk of harm to the mental health and well-being of children and adolescents.(c) As the United States Surgeon General has reported, recent evidence has identified “reasons for concern” about social media usage by children and adolescents. This evidence includes a study concluding that the risk of poor mental health outcomes doubles for children and adolescents who use social media at least three hours a day and research finding that social media usage is linked to a variety of negative health outcomes, including low self-esteem and disordered eating, for adolescent girls. (d) Heavier usage of social media also leads to less healthy sleep patterns and sleep quality, which can in turn exacerbate both physical and mental health problems.(e) Further, social media usage is more strongly associated with negative mental health outcomes, including depressive symptoms and self-harm behaviors, than is consumption of other forms of media such as television or electronic games. (f) Both California and the country as a whole are facing an ongoing youth mental health crisis, with rates of adolescent suicides, depressive episodes, and feelings of sadness and hopelessness on the rise in recent years. (g) For these reasons, it is essential that California act to ensure that social media platforms obtain parental consent before exposing children and adolescents to harmful and addictive social media features.SEC. 2. Chapter 24 (commencing with Section 27000) is added to Division 20 of the Health and Safety Code, to read: CHAPTER 24. Protecting Our Kids from Social Media Addiction Act27000. This chapter shall be known, and may be cited, as the Protecting Our Kids from Social Media Addiction Act.27000.5. For purposes of this chapter, the following terms have the following meanings:(a) “Addictive feed” means an internet website, online service, online application, or mobile application, or a portion thereof, in which multiple pieces of media generated or shared by users are, either concurrently or sequentially, recommended, selected, or prioritized for display to a user based, in whole or in part, on information provided by the user, or otherwise associated with the user or the user’s device, unless any of the following conditions are met, alone or in combination with one another:(1) The information is not persistently associated with the user or user’s device, and does not concern the user’s previous interactions with media generated or shared by others.(2) The information consists of search terms that are not persistently associated with the user or user’s device.(3) The information consists of user-selected privacy or accessibility settings, technical information concerning the user’s device, or device communications or signals concerning whether the user is a minor.(4) The user expressly and unambiguously requested the specific media or media by the author, creator, or poster of the media, or the blocking, prioritization, or deprioritization of such media, provided that the media is not recommended, selected, or prioritized for display based, in whole or in part, on other information associated with the user or the user’s device, except as otherwise permitted by this chapter and, in the case of audio or video content, is not automatically played.(5) The media consists of direct, private communications between users.(6) The media recommended, selected, or prioritized for display is exclusively the next media in a preexisting sequence from the same author, creator, poster, or source and, in the case of audio or video content, is not automatically played.(7) The recommendation, selection, or prioritization of the media is necessary to comply with this chapter or any regulations promulgated pursuant to this chapter.(b) (1) “Addictive internet-based service or application” means an internet website, online service, online application, or mobile application, including, but not limited to, a “social media platform” as defined in Section 22675 of the Business and Professions Code, that offers users or provides users with an addictive feed as a significant part of the service provided by that internet website, online service, online application, or mobile application.(2) “Addictive internet-based service or application” does not apply to either of the following:(A) An internet website, online service, online application, or mobile application for which interactions between users are limited to commercial transactions or to consumer reviews of products, sellers, services, events, or places, or any combination thereof.(B) An internet website, online service, online application, or mobile application that operates a feed for the primary purpose of cloud storage.(c) “Media” means text, audio, an image, or a video.(d) “Minor” means an individual under 18 years of age who is located in the State of California.(e) “Operator” means a person who operates or provides an internet website, an online service, an online application, or a mobile application.(f) “Parent” means a parent or guardian, including as defined in regulations promulgated pursuant to this chapter.(g) “User” means a person who uses an internet website, online service, online application, or mobile application. “User” does not include the operator or a person acting as an agent of the operator.27001. (a) It shall be unlawful for the operator of an addictive internet-based service or application to provide an addictive feed to a user unless either of the following is met:(1) (A) Except as provided in subparagraph (B), the operator does not have actual knowledge that the user is a minor.(B) Commencing January 1, 2027, the operator has reasonably determined that the user is not a minor, including pursuant to regulations promulgated by the Attorney General.(2) The operator has obtained verifiable parental consent to provide an addictive feed to the user who is a minor.(b) Information collected for the purpose of determining a user’s age or verifying parental consent pursuant to this chapter shall not be used for any purpose other than compliance with this chapter or with another applicable law. The information collected shall be deleted immediately after it is used to determine a user’s age or to verify parental consent, except as necessary to comply with state or federal law.27002. (a) (1) Except as provided in paragraph (2), it shall be unlawful for the operator of an addictive internet-based service or application, between the hours of 12 a.m. and 6 a.m., in the user’s local time zone, and between the hours of 8 a.m. and 3 p.m., from Monday through Friday from September through May in the user’s local time zone, to send notifications to a user if the operator has actual knowledge that the user is a minor unless the operator has obtained verifiable parental consent to send those notifications.(2) Commencing January 1, 2027, it shall be unlawful for the operator of an addictive internet-based service or application, between the hours of 12 a.m. and 6 a.m., in the user’s local time zone, and between the hours of 8 a.m. and 3 p.m., from Monday through Friday from September through May in the user’s local time zone, to send notifications to a user whom the operator has not reasonably determined is not a minor, including pursuant to regulations promulgated by the Attorney General, unless the operator has obtained verifiable parental consent to send those notifications.(b) The operator of an addictive internet-based service or application shall provide a mechanism through which the verified parent of a user who is a minor may do any of the following:(1) Prevent their child from accessing or receiving notifications from the addictive internet-based service or application between specific hours chosen by the parent. This setting shall be set by the operator as on by default, in a manner in which the child’s access is limited between the hours of 12 a.m. and 6 a.m., in the user’s local time zone.(2) Limit their child’s access to any addictive feed from the addictive internet-based service or application to a length of time per day specified by the verified parent. This setting shall be set by the operator as on by default, in a manner in which the child’s access is limited to one hour per day unless modified by the verified parent.(3) Limit their child’s ability to view the number of likes or other forms of feedback to pieces of media within an addictive feed. This setting shall be set by the operator as on by default.(4) Require that the default feed provided to the child when entering the internet-based service or application be one in which pieces of media are not recommended, selected, or prioritized for display based on information provided by the user, or otherwise associated with the user or the user’s device, other than the user’s age or status as a minor.(5) Set their child’s account to private mode, in a manner in which only users to whom the child is connected on the addictive internet-based service or application may view or respond to content posted by the child. This setting shall be set by the operator as on by default.27003. (a) This chapter shall not be construed as requiring the operator of an addictive internet-based service or application to give a parent any additional or special access to, or control over, the data or accounts of their child.(b) This chapter shall not be construed as preventing any action taken in good faith to restrict access to, or availability of, media.27004. (a) An operator may choose not to provide services to minors. However, the operator of an addictive internet-based service or application shall not withhold, degrade, lower the quality of, or increase the price of, any product, service, or feature, other than as required by this chapter, due to a user or parent availing themselves of the rights provided by this chapter, or due to the protections required by this chapter.(b) A parent’s provision of consent as described in Section 27001 or 27002, or the use by a parent of a mechanism as described in Section 27002, does not waive, release, otherwise limit, or serve as a defense to, any claim that the parent, or that the user who is a minor or was a minor at the time of using the internet-based service or application, might have against the operator of an addictive internet-based service or application regarding any harm to the mental health or well-being of the user.(c) The protections provided by this chapter are in addition to those provided by any other applicable law, including, but not limited to, the California Age-Appropriate Design Code Act (Title 1.81.47 (commencing with Section 1798.99.28) of Part 4 of Division 3 of the Civil Code).27005. An operator of an addictive internet-based service or application shall publicly disclose, on an annual basis, the number of minor users of its addictive internet-based service or application, and of that total the number for whom the operator has received verifiable parental consent to provide an addictive feed, and the number of minor users as to whom the controls set forth in Section 27002 are or are not enabled. 27006. (a) This chapter may only be enforced in a civil action brought in the name of the people of the State of California by the Attorney General.(b) The Attorney General shall adopt regulations to further the purposes of this chapter, including regulations regarding age assurance and parental consent by January 1, 2027. The Attorney General may adopt regulations that provide for exceptions to this chapter, but only if those exceptions further the purpose of protecting minors.(c) In promulgating the regulations described in subdivision (b), the Attorney General shall solicit public comment regarding the impact that any regulation might have based on the nondiscrimination characteristics set forth in Section 51 of the Civil Code or in any other applicable law.27007. If any provision of this chapter, or application thereof, to any person or circumstance is held invalid, that invalidity shall not affect other provisions or applications of this chapter that can be given effect without the invalid provision or application, and to this end the provisions of this chapter are declared to be severable. Bill Information >> Bill Search >> Text "
        },
        {
          "title": "Bill Text",
          "content": "PDF2 Bill PDF |Add To My Favorites | Version: 09/20/24 - Chaptered 09/05/24 - Enrolled 08/22/24 - Amended Assembly 08/19/24 - Amended Assembly 07/03/24 - Amended Assembly 06/18/24 - Amended Assembly 04/25/24 - Amended Senate 03/19/24 - Amended Senate 01/29/24 - Introduced SB-976 Protecting Our Kids from Social Media Addiction Act.(2023-2024) Text >> Votes >> History >> Bill Analysis >> Today's Law As Amended >> Compare Versions >> Status >> Comments To Author >> Add To My Favorites >> PDF2 Bill PDF |Add To My Favorites | Version: 09/20/24 - Chaptered 09/05/24 - Enrolled 08/22/24 - Amended Assembly 08/19/24 - Amended Assembly 07/03/24 - Amended Assembly 06/18/24 - Amended Assembly 04/25/24 - Amended Senate 03/19/24 - Amended Senate 01/29/24 - Introduced SB-976 Protecting Our Kids from Social Media Addiction Act.(2023-2024) PDF2 Bill PDF |Add To My Favorites | Version: 09/20/24 - Chaptered 09/05/24 - Enrolled 08/22/24 - Amended Assembly 08/19/24 - Amended Assembly 07/03/24 - Amended Assembly 06/18/24 - Amended Assembly 04/25/24 - Amended Senate 03/19/24 - Amended Senate 01/29/24 - Introduced SB-976 Protecting Our Kids from Social Media Addiction Act.(2023-2024) "
        },
        {
          "title": "SB-976 Protecting Our Kids from Social Media Addiction Act.(2023-2024)",
          "content": "Text >> Votes >> History >> Bill Analysis >> Today's Law As Amended >> Compare Versions >> Status >> Comments To Author >> Add To My Favorites >> SHARE THIS: Date Published: 09/23/2024 09:00 PM SB976:v91#DOCUMENTBill Start Senate Bill No. 976 CHAPTER 321An act to add Chapter 24 (commencing with Section 27000) to Division 20 of the Health and Safety Code, relating to youth addiction. [ Approved by Governor September 20, 2024. Filed with Secretary of State September 20, 2024. ] LEGISLATIVE COUNSEL'S DIGESTSB 976, Skinner. Protecting Our Kids from Social Media Addiction Act.Existing law, the California Age-Appropriate Design Code Act, requires, beginning July 1, 2024, a business that provides an online service, product, or feature likely to be accessed by children to comply with certain requirements. The act requires the business to complete a data protection impact assessment addressing, among other things, whether the design could harm children and whether and how the online product, service, or feature uses system design features to increase, sustain, or extend use of the online product, service, or feature by children, including the automatic playing of media, rewards for time spent, and notifications. Existing law prohibits the business from using the personal information of any child in a way that the business knows, or has reason to know, is materially detrimental to the physical health, mental health, or well-being of a child.Existing law, the Privacy Rights for California Minors in the Digital World, prohibits an operator of an internet website, online service, online application, or mobile application from specified conduct when minors are involved, including the marketing or advertising of alcoholic beverages, firearms, or certain other products or services. Existing law sets forth other related protections for minors, including under the California Consumer Privacy Act of 2018 and the California Privacy Rights Act of 2020.This bill, the Protecting Our Kids from Social Media Addiction Act, would make it unlawful for the operator of an addictive internet-based service or application, as defined, to provide an addictive feed to a user, unless the operator does not have actual knowledge that the user is a minor; commencing January 1, 2027, has reasonably determined that the user is not a minor; or has obtained verifiable parental consent to provide an addictive feed to the user who is a minor.The bill would define “addictive feed” as an internet website, online service, online application, or mobile application, in which multiple pieces of media generated or shared by users are recommended, selected, or prioritized for display to a user based on information provided by the user, or otherwise associated with the user or the user’s device, as specified, unless any of certain conditions are met.The bill would make it unlawful for the operator of an addictive internet-based service or application, between the hours of 12 a.m. and 6 a.m., in the user’s local time zone, and between the hours of 8 a.m. and 3 p.m., Monday through Friday from September through May in the user’s local time zone, to send notifications to a user if the operator has actual knowledge that the user is a minor or, commencing January 1, 2027, has not reasonably determined that the user is not a minor, unless the operator has obtained verifiable parental consent to send those notifications, as specified. The bill would set forth related provisions for certain access controls determined by the verified parent through a mechanism provided by the operator.Under the bill, a parent’s provision of consent or use of a mechanism, as described above, would not waive, release, otherwise limit, or serve as a defense to, any claim that the parent, or that the user who is a minor or was a minor at the time of using the internet-based service or application, might have against the operator regarding any harm to the mental health or well-being of the user.The bill would require an operator to annually disclose the number of minor users of its addictive internet-based service or application, and of that total the number for whom the operator has received verifiable parental consent to provide an addictive feed, and the number of minor users as to whom the access controls are or are not enabled.Under the bill, these provisions would only be enforced in a civil action brought in the name of the people of the State of California by the Attorney General. The bill would require the Attorney General to adopt regulations to further the purposes of these provisions, including regulations regarding age assurance and parental consent by January 1, 2027. The bill would authorize the Attorney General to adopt regulations that provide for exceptions to these provisions, but only if those exceptions further the purpose of protecting minors. The bill would require the Attorney General, in promulgating regulations, to solicit public comment regarding the impact that any regulation might have based on certain nondiscrimination characteristics set forth in existing law.The bill would make these provisions severable.Digest Key Vote: MAJORITY Appropriation: NO Fiscal Committee: YES Local Program: NO Bill TextThe people of the State of California do enact as follows:SECTION 1. The Legislature finds and declares the following:(a) Social media provides an important tool for communication and information sharing. Approximately 95 percent of 13- to 17-year-olds, inclusive, say that they use at least one social media platform, and more than one-third report using social media almost constantly.(b) However, some social media platforms have evolved to include addictive features, including the algorithmic delivery of content and other design features, that pose a significant risk of harm to the mental health and well-being of children and adolescents.(c) As the United States Surgeon General has reported, recent evidence has identified “reasons for concern” about social media usage by children and adolescents. This evidence includes a study concluding that the risk of poor mental health outcomes doubles for children and adolescents who use social media at least three hours a day and research finding that social media usage is linked to a variety of negative health outcomes, including low self-esteem and disordered eating, for adolescent girls. (d) Heavier usage of social media also leads to less healthy sleep patterns and sleep quality, which can in turn exacerbate both physical and mental health problems.(e) Further, social media usage is more strongly associated with negative mental health outcomes, including depressive symptoms and self-harm behaviors, than is consumption of other forms of media such as television or electronic games. (f) Both California and the country as a whole are facing an ongoing youth mental health crisis, with rates of adolescent suicides, depressive episodes, and feelings of sadness and hopelessness on the rise in recent years. (g) For these reasons, it is essential that California act to ensure that social media platforms obtain parental consent before exposing children and adolescents to harmful and addictive social media features.SEC. 2. Chapter 24 (commencing with Section 27000) is added to Division 20 of the Health and Safety Code, to read: CHAPTER 24. Protecting Our Kids from Social Media Addiction Act27000. This chapter shall be known, and may be cited, as the Protecting Our Kids from Social Media Addiction Act.27000.5. For purposes of this chapter, the following terms have the following meanings:(a) “Addictive feed” means an internet website, online service, online application, or mobile application, or a portion thereof, in which multiple pieces of media generated or shared by users are, either concurrently or sequentially, recommended, selected, or prioritized for display to a user based, in whole or in part, on information provided by the user, or otherwise associated with the user or the user’s device, unless any of the following conditions are met, alone or in combination with one another:(1) The information is not persistently associated with the user or user’s device, and does not concern the user’s previous interactions with media generated or shared by others.(2) The information consists of search terms that are not persistently associated with the user or user’s device.(3) The information consists of user-selected privacy or accessibility settings, technical information concerning the user’s device, or device communications or signals concerning whether the user is a minor.(4) The user expressly and unambiguously requested the specific media or media by the author, creator, or poster of the media, or the blocking, prioritization, or deprioritization of such media, provided that the media is not recommended, selected, or prioritized for display based, in whole or in part, on other information associated with the user or the user’s device, except as otherwise permitted by this chapter and, in the case of audio or video content, is not automatically played.(5) The media consists of direct, private communications between users.(6) The media recommended, selected, or prioritized for display is exclusively the next media in a preexisting sequence from the same author, creator, poster, or source and, in the case of audio or video content, is not automatically played.(7) The recommendation, selection, or prioritization of the media is necessary to comply with this chapter or any regulations promulgated pursuant to this chapter.(b) (1) “Addictive internet-based service or application” means an internet website, online service, online application, or mobile application, including, but not limited to, a “social media platform” as defined in Section 22675 of the Business and Professions Code, that offers users or provides users with an addictive feed as a significant part of the service provided by that internet website, online service, online application, or mobile application.(2) “Addictive internet-based service or application” does not apply to either of the following:(A) An internet website, online service, online application, or mobile application for which interactions between users are limited to commercial transactions or to consumer reviews of products, sellers, services, events, or places, or any combination thereof.(B) An internet website, online service, online application, or mobile application that operates a feed for the primary purpose of cloud storage.(c) “Media” means text, audio, an image, or a video.(d) “Minor” means an individual under 18 years of age who is located in the State of California.(e) “Operator” means a person who operates or provides an internet website, an online service, an online application, or a mobile application.(f) “Parent” means a parent or guardian, including as defined in regulations promulgated pursuant to this chapter.(g) “User” means a person who uses an internet website, online service, online application, or mobile application. “User” does not include the operator or a person acting as an agent of the operator.27001. (a) It shall be unlawful for the operator of an addictive internet-based service or application to provide an addictive feed to a user unless either of the following is met:(1) (A) Except as provided in subparagraph (B), the operator does not have actual knowledge that the user is a minor.(B) Commencing January 1, 2027, the operator has reasonably determined that the user is not a minor, including pursuant to regulations promulgated by the Attorney General.(2) The operator has obtained verifiable parental consent to provide an addictive feed to the user who is a minor.(b) Information collected for the purpose of determining a user’s age or verifying parental consent pursuant to this chapter shall not be used for any purpose other than compliance with this chapter or with another applicable law. The information collected shall be deleted immediately after it is used to determine a user’s age or to verify parental consent, except as necessary to comply with state or federal law.27002. (a) (1) Except as provided in paragraph (2), it shall be unlawful for the operator of an addictive internet-based service or application, between the hours of 12 a.m. and 6 a.m., in the user’s local time zone, and between the hours of 8 a.m. and 3 p.m., from Monday through Friday from September through May in the user’s local time zone, to send notifications to a user if the operator has actual knowledge that the user is a minor unless the operator has obtained verifiable parental consent to send those notifications.(2) Commencing January 1, 2027, it shall be unlawful for the operator of an addictive internet-based service or application, between the hours of 12 a.m. and 6 a.m., in the user’s local time zone, and between the hours of 8 a.m. and 3 p.m., from Monday through Friday from September through May in the user’s local time zone, to send notifications to a user whom the operator has not reasonably determined is not a minor, including pursuant to regulations promulgated by the Attorney General, unless the operator has obtained verifiable parental consent to send those notifications.(b) The operator of an addictive internet-based service or application shall provide a mechanism through which the verified parent of a user who is a minor may do any of the following:(1) Prevent their child from accessing or receiving notifications from the addictive internet-based service or application between specific hours chosen by the parent. This setting shall be set by the operator as on by default, in a manner in which the child’s access is limited between the hours of 12 a.m. and 6 a.m., in the user’s local time zone.(2) Limit their child’s access to any addictive feed from the addictive internet-based service or application to a length of time per day specified by the verified parent. This setting shall be set by the operator as on by default, in a manner in which the child’s access is limited to one hour per day unless modified by the verified parent.(3) Limit their child’s ability to view the number of likes or other forms of feedback to pieces of media within an addictive feed. This setting shall be set by the operator as on by default.(4) Require that the default feed provided to the child when entering the internet-based service or application be one in which pieces of media are not recommended, selected, or prioritized for display based on information provided by the user, or otherwise associated with the user or the user’s device, other than the user’s age or status as a minor.(5) Set their child’s account to private mode, in a manner in which only users to whom the child is connected on the addictive internet-based service or application may view or respond to content posted by the child. This setting shall be set by the operator as on by default.27003. (a) This chapter shall not be construed as requiring the operator of an addictive internet-based service or application to give a parent any additional or special access to, or control over, the data or accounts of their child.(b) This chapter shall not be construed as preventing any action taken in good faith to restrict access to, or availability of, media.27004. (a) An operator may choose not to provide services to minors. However, the operator of an addictive internet-based service or application shall not withhold, degrade, lower the quality of, or increase the price of, any product, service, or feature, other than as required by this chapter, due to a user or parent availing themselves of the rights provided by this chapter, or due to the protections required by this chapter.(b) A parent’s provision of consent as described in Section 27001 or 27002, or the use by a parent of a mechanism as described in Section 27002, does not waive, release, otherwise limit, or serve as a defense to, any claim that the parent, or that the user who is a minor or was a minor at the time of using the internet-based service or application, might have against the operator of an addictive internet-based service or application regarding any harm to the mental health or well-being of the user.(c) The protections provided by this chapter are in addition to those provided by any other applicable law, including, but not limited to, the California Age-Appropriate Design Code Act (Title 1.81.47 (commencing with Section 1798.99.28) of Part 4 of Division 3 of the Civil Code).27005. An operator of an addictive internet-based service or application shall publicly disclose, on an annual basis, the number of minor users of its addictive internet-based service or application, and of that total the number for whom the operator has received verifiable parental consent to provide an addictive feed, and the number of minor users as to whom the controls set forth in Section 27002 are or are not enabled. 27006. (a) This chapter may only be enforced in a civil action brought in the name of the people of the State of California by the Attorney General.(b) The Attorney General shall adopt regulations to further the purposes of this chapter, including regulations regarding age assurance and parental consent by January 1, 2027. The Attorney General may adopt regulations that provide for exceptions to this chapter, but only if those exceptions further the purpose of protecting minors.(c) In promulgating the regulations described in subdivision (b), the Attorney General shall solicit public comment regarding the impact that any regulation might have based on the nondiscrimination characteristics set forth in Section 51 of the Civil Code or in any other applicable law.27007. If any provision of this chapter, or application thereof, to any person or circumstance is held invalid, that invalidity shall not affect other provisions or applications of this chapter that can be given effect without the invalid provision or application, and to this end the provisions of this chapter are declared to be severable. SHARE THIS: Date Published: 09/23/2024 09:00 PM "
        },
        {
          "title": "Bill Start",
          "content": "Senate Bill No. 976 CHAPTER 321An act to add Chapter 24 (commencing with Section 27000) to Division 20 of the Health and Safety Code, relating to youth addiction. [ Approved by Governor September 20, 2024. Filed with Secretary of State September 20, 2024. ] LEGISLATIVE COUNSEL'S DIGESTSB 976, Skinner. Protecting Our Kids from Social Media Addiction Act.Existing law, the California Age-Appropriate Design Code Act, requires, beginning July 1, 2024, a business that provides an online service, product, or feature likely to be accessed by children to comply with certain requirements. The act requires the business to complete a data protection impact assessment addressing, among other things, whether the design could harm children and whether and how the online product, service, or feature uses system design features to increase, sustain, or extend use of the online product, service, or feature by children, including the automatic playing of media, rewards for time spent, and notifications. Existing law prohibits the business from using the personal information of any child in a way that the business knows, or has reason to know, is materially detrimental to the physical health, mental health, or well-being of a child.Existing law, the Privacy Rights for California Minors in the Digital World, prohibits an operator of an internet website, online service, online application, or mobile application from specified conduct when minors are involved, including the marketing or advertising of alcoholic beverages, firearms, or certain other products or services. Existing law sets forth other related protections for minors, including under the California Consumer Privacy Act of 2018 and the California Privacy Rights Act of 2020.This bill, the Protecting Our Kids from Social Media Addiction Act, would make it unlawful for the operator of an addictive internet-based service or application, as defined, to provide an addictive feed to a user, unless the operator does not have actual knowledge that the user is a minor; commencing January 1, 2027, has reasonably determined that the user is not a minor; or has obtained verifiable parental consent to provide an addictive feed to the user who is a minor.The bill would define “addictive feed” as an internet website, online service, online application, or mobile application, in which multiple pieces of media generated or shared by users are recommended, selected, or prioritized for display to a user based on information provided by the user, or otherwise associated with the user or the user’s device, as specified, unless any of certain conditions are met.The bill would make it unlawful for the operator of an addictive internet-based service or application, between the hours of 12 a.m. and 6 a.m., in the user’s local time zone, and between the hours of 8 a.m. and 3 p.m., Monday through Friday from September through May in the user’s local time zone, to send notifications to a user if the operator has actual knowledge that the user is a minor or, commencing January 1, 2027, has not reasonably determined that the user is not a minor, unless the operator has obtained verifiable parental consent to send those notifications, as specified. The bill would set forth related provisions for certain access controls determined by the verified parent through a mechanism provided by the operator.Under the bill, a parent’s provision of consent or use of a mechanism, as described above, would not waive, release, otherwise limit, or serve as a defense to, any claim that the parent, or that the user who is a minor or was a minor at the time of using the internet-based service or application, might have against the operator regarding any harm to the mental health or well-being of the user.The bill would require an operator to annually disclose the number of minor users of its addictive internet-based service or application, and of that total the number for whom the operator has received verifiable parental consent to provide an addictive feed, and the number of minor users as to whom the access controls are or are not enabled.Under the bill, these provisions would only be enforced in a civil action brought in the name of the people of the State of California by the Attorney General. The bill would require the Attorney General to adopt regulations to further the purposes of these provisions, including regulations regarding age assurance and parental consent by January 1, 2027. The bill would authorize the Attorney General to adopt regulations that provide for exceptions to these provisions, but only if those exceptions further the purpose of protecting minors. The bill would require the Attorney General, in promulgating regulations, to solicit public comment regarding the impact that any regulation might have based on certain nondiscrimination characteristics set forth in existing law.The bill would make these provisions severable.Digest Key Vote: MAJORITY Appropriation: NO Fiscal Committee: YES Local Program: NO Bill TextThe people of the State of California do enact as follows:SECTION 1. The Legislature finds and declares the following:(a) Social media provides an important tool for communication and information sharing. Approximately 95 percent of 13- to 17-year-olds, inclusive, say that they use at least one social media platform, and more than one-third report using social media almost constantly.(b) However, some social media platforms have evolved to include addictive features, including the algorithmic delivery of content and other design features, that pose a significant risk of harm to the mental health and well-being of children and adolescents.(c) As the United States Surgeon General has reported, recent evidence has identified “reasons for concern” about social media usage by children and adolescents. This evidence includes a study concluding that the risk of poor mental health outcomes doubles for children and adolescents who use social media at least three hours a day and research finding that social media usage is linked to a variety of negative health outcomes, including low self-esteem and disordered eating, for adolescent girls. (d) Heavier usage of social media also leads to less healthy sleep patterns and sleep quality, which can in turn exacerbate both physical and mental health problems.(e) Further, social media usage is more strongly associated with negative mental health outcomes, including depressive symptoms and self-harm behaviors, than is consumption of other forms of media such as television or electronic games. (f) Both California and the country as a whole are facing an ongoing youth mental health crisis, with rates of adolescent suicides, depressive episodes, and feelings of sadness and hopelessness on the rise in recent years. (g) For these reasons, it is essential that California act to ensure that social media platforms obtain parental consent before exposing children and adolescents to harmful and addictive social media features.SEC. 2. Chapter 24 (commencing with Section 27000) is added to Division 20 of the Health and Safety Code, to read: CHAPTER 24. Protecting Our Kids from Social Media Addiction Act27000. This chapter shall be known, and may be cited, as the Protecting Our Kids from Social Media Addiction Act.27000.5. For purposes of this chapter, the following terms have the following meanings:(a) “Addictive feed” means an internet website, online service, online application, or mobile application, or a portion thereof, in which multiple pieces of media generated or shared by users are, either concurrently or sequentially, recommended, selected, or prioritized for display to a user based, in whole or in part, on information provided by the user, or otherwise associated with the user or the user’s device, unless any of the following conditions are met, alone or in combination with one another:(1) The information is not persistently associated with the user or user’s device, and does not concern the user’s previous interactions with media generated or shared by others.(2) The information consists of search terms that are not persistently associated with the user or user’s device.(3) The information consists of user-selected privacy or accessibility settings, technical information concerning the user’s device, or device communications or signals concerning whether the user is a minor.(4) The user expressly and unambiguously requested the specific media or media by the author, creator, or poster of the media, or the blocking, prioritization, or deprioritization of such media, provided that the media is not recommended, selected, or prioritized for display based, in whole or in part, on other information associated with the user or the user’s device, except as otherwise permitted by this chapter and, in the case of audio or video content, is not automatically played.(5) The media consists of direct, private communications between users.(6) The media recommended, selected, or prioritized for display is exclusively the next media in a preexisting sequence from the same author, creator, poster, or source and, in the case of audio or video content, is not automatically played.(7) The recommendation, selection, or prioritization of the media is necessary to comply with this chapter or any regulations promulgated pursuant to this chapter.(b) (1) “Addictive internet-based service or application” means an internet website, online service, online application, or mobile application, including, but not limited to, a “social media platform” as defined in Section 22675 of the Business and Professions Code, that offers users or provides users with an addictive feed as a significant part of the service provided by that internet website, online service, online application, or mobile application.(2) “Addictive internet-based service or application” does not apply to either of the following:(A) An internet website, online service, online application, or mobile application for which interactions between users are limited to commercial transactions or to consumer reviews of products, sellers, services, events, or places, or any combination thereof.(B) An internet website, online service, online application, or mobile application that operates a feed for the primary purpose of cloud storage.(c) “Media” means text, audio, an image, or a video.(d) “Minor” means an individual under 18 years of age who is located in the State of California.(e) “Operator” means a person who operates or provides an internet website, an online service, an online application, or a mobile application.(f) “Parent” means a parent or guardian, including as defined in regulations promulgated pursuant to this chapter.(g) “User” means a person who uses an internet website, online service, online application, or mobile application. “User” does not include the operator or a person acting as an agent of the operator.27001. (a) It shall be unlawful for the operator of an addictive internet-based service or application to provide an addictive feed to a user unless either of the following is met:(1) (A) Except as provided in subparagraph (B), the operator does not have actual knowledge that the user is a minor.(B) Commencing January 1, 2027, the operator has reasonably determined that the user is not a minor, including pursuant to regulations promulgated by the Attorney General.(2) The operator has obtained verifiable parental consent to provide an addictive feed to the user who is a minor.(b) Information collected for the purpose of determining a user’s age or verifying parental consent pursuant to this chapter shall not be used for any purpose other than compliance with this chapter or with another applicable law. The information collected shall be deleted immediately after it is used to determine a user’s age or to verify parental consent, except as necessary to comply with state or federal law.27002. (a) (1) Except as provided in paragraph (2), it shall be unlawful for the operator of an addictive internet-based service or application, between the hours of 12 a.m. and 6 a.m., in the user’s local time zone, and between the hours of 8 a.m. and 3 p.m., from Monday through Friday from September through May in the user’s local time zone, to send notifications to a user if the operator has actual knowledge that the user is a minor unless the operator has obtained verifiable parental consent to send those notifications.(2) Commencing January 1, 2027, it shall be unlawful for the operator of an addictive internet-based service or application, between the hours of 12 a.m. and 6 a.m., in the user’s local time zone, and between the hours of 8 a.m. and 3 p.m., from Monday through Friday from September through May in the user’s local time zone, to send notifications to a user whom the operator has not reasonably determined is not a minor, including pursuant to regulations promulgated by the Attorney General, unless the operator has obtained verifiable parental consent to send those notifications.(b) The operator of an addictive internet-based service or application shall provide a mechanism through which the verified parent of a user who is a minor may do any of the following:(1) Prevent their child from accessing or receiving notifications from the addictive internet-based service or application between specific hours chosen by the parent. This setting shall be set by the operator as on by default, in a manner in which the child’s access is limited between the hours of 12 a.m. and 6 a.m., in the user’s local time zone.(2) Limit their child’s access to any addictive feed from the addictive internet-based service or application to a length of time per day specified by the verified parent. This setting shall be set by the operator as on by default, in a manner in which the child’s access is limited to one hour per day unless modified by the verified parent.(3) Limit their child’s ability to view the number of likes or other forms of feedback to pieces of media within an addictive feed. This setting shall be set by the operator as on by default.(4) Require that the default feed provided to the child when entering the internet-based service or application be one in which pieces of media are not recommended, selected, or prioritized for display based on information provided by the user, or otherwise associated with the user or the user’s device, other than the user’s age or status as a minor.(5) Set their child’s account to private mode, in a manner in which only users to whom the child is connected on the addictive internet-based service or application may view or respond to content posted by the child. This setting shall be set by the operator as on by default.27003. (a) This chapter shall not be construed as requiring the operator of an addictive internet-based service or application to give a parent any additional or special access to, or control over, the data or accounts of their child.(b) This chapter shall not be construed as preventing any action taken in good faith to restrict access to, or availability of, media.27004. (a) An operator may choose not to provide services to minors. However, the operator of an addictive internet-based service or application shall not withhold, degrade, lower the quality of, or increase the price of, any product, service, or feature, other than as required by this chapter, due to a user or parent availing themselves of the rights provided by this chapter, or due to the protections required by this chapter.(b) A parent’s provision of consent as described in Section 27001 or 27002, or the use by a parent of a mechanism as described in Section 27002, does not waive, release, otherwise limit, or serve as a defense to, any claim that the parent, or that the user who is a minor or was a minor at the time of using the internet-based service or application, might have against the operator of an addictive internet-based service or application regarding any harm to the mental health or well-being of the user.(c) The protections provided by this chapter are in addition to those provided by any other applicable law, including, but not limited to, the California Age-Appropriate Design Code Act (Title 1.81.47 (commencing with Section 1798.99.28) of Part 4 of Division 3 of the Civil Code).27005. An operator of an addictive internet-based service or application shall publicly disclose, on an annual basis, the number of minor users of its addictive internet-based service or application, and of that total the number for whom the operator has received verifiable parental consent to provide an addictive feed, and the number of minor users as to whom the controls set forth in Section 27002 are or are not enabled. 27006. (a) This chapter may only be enforced in a civil action brought in the name of the people of the State of California by the Attorney General.(b) The Attorney General shall adopt regulations to further the purposes of this chapter, including regulations regarding age assurance and parental consent by January 1, 2027. The Attorney General may adopt regulations that provide for exceptions to this chapter, but only if those exceptions further the purpose of protecting minors.(c) In promulgating the regulations described in subdivision (b), the Attorney General shall solicit public comment regarding the impact that any regulation might have based on the nondiscrimination characteristics set forth in Section 51 of the Civil Code or in any other applicable law.27007. If any provision of this chapter, or application thereof, to any person or circumstance is held invalid, that invalidity shall not affect other provisions or applications of this chapter that can be given effect without the invalid provision or application, and to this end the provisions of this chapter are declared to be severable. Senate Bill No. 976 CHAPTER 321An act to add Chapter 24 (commencing with Section 27000) to Division 20 of the Health and Safety Code, relating to youth addiction. [ Approved by Governor September 20, 2024. Filed with Secretary of State September 20, 2024. ] LEGISLATIVE COUNSEL'S DIGESTSB 976, Skinner. Protecting Our Kids from Social Media Addiction Act.Existing law, the California Age-Appropriate Design Code Act, requires, beginning July 1, 2024, a business that provides an online service, product, or feature likely to be accessed by children to comply with certain requirements. The act requires the business to complete a data protection impact assessment addressing, among other things, whether the design could harm children and whether and how the online product, service, or feature uses system design features to increase, sustain, or extend use of the online product, service, or feature by children, including the automatic playing of media, rewards for time spent, and notifications. Existing law prohibits the business from using the personal information of any child in a way that the business knows, or has reason to know, is materially detrimental to the physical health, mental health, or well-being of a child.Existing law, the Privacy Rights for California Minors in the Digital World, prohibits an operator of an internet website, online service, online application, or mobile application from specified conduct when minors are involved, including the marketing or advertising of alcoholic beverages, firearms, or certain other products or services. Existing law sets forth other related protections for minors, including under the California Consumer Privacy Act of 2018 and the California Privacy Rights Act of 2020.This bill, the Protecting Our Kids from Social Media Addiction Act, would make it unlawful for the operator of an addictive internet-based service or application, as defined, to provide an addictive feed to a user, unless the operator does not have actual knowledge that the user is a minor; commencing January 1, 2027, has reasonably determined that the user is not a minor; or has obtained verifiable parental consent to provide an addictive feed to the user who is a minor.The bill would define “addictive feed” as an internet website, online service, online application, or mobile application, in which multiple pieces of media generated or shared by users are recommended, selected, or prioritized for display to a user based on information provided by the user, or otherwise associated with the user or the user’s device, as specified, unless any of certain conditions are met.The bill would make it unlawful for the operator of an addictive internet-based service or application, between the hours of 12 a.m. and 6 a.m., in the user’s local time zone, and between the hours of 8 a.m. and 3 p.m., Monday through Friday from September through May in the user’s local time zone, to send notifications to a user if the operator has actual knowledge that the user is a minor or, commencing January 1, 2027, has not reasonably determined that the user is not a minor, unless the operator has obtained verifiable parental consent to send those notifications, as specified. The bill would set forth related provisions for certain access controls determined by the verified parent through a mechanism provided by the operator.Under the bill, a parent’s provision of consent or use of a mechanism, as described above, would not waive, release, otherwise limit, or serve as a defense to, any claim that the parent, or that the user who is a minor or was a minor at the time of using the internet-based service or application, might have against the operator regarding any harm to the mental health or well-being of the user.The bill would require an operator to annually disclose the number of minor users of its addictive internet-based service or application, and of that total the number for whom the operator has received verifiable parental consent to provide an addictive feed, and the number of minor users as to whom the access controls are or are not enabled.Under the bill, these provisions would only be enforced in a civil action brought in the name of the people of the State of California by the Attorney General. The bill would require the Attorney General to adopt regulations to further the purposes of these provisions, including regulations regarding age assurance and parental consent by January 1, 2027. The bill would authorize the Attorney General to adopt regulations that provide for exceptions to these provisions, but only if those exceptions further the purpose of protecting minors. The bill would require the Attorney General, in promulgating regulations, to solicit public comment regarding the impact that any regulation might have based on certain nondiscrimination characteristics set forth in existing law.The bill would make these provisions severable.Digest Key Vote: MAJORITY Appropriation: NO Fiscal Committee: YES Local Program: NO Senate Bill No. 976 CHAPTER 321 Senate Bill No. 976 CHAPTER 321 An act to add Chapter 24 (commencing with Section 27000) to Division 20 of the Health and Safety Code, relating to youth addiction. [ Approved by Governor September 20, 2024. Filed with Secretary of State September 20, 2024. ] LEGISLATIVE COUNSEL'S DIGEST "
        },
        {
          "title": "LEGISLATIVE COUNSEL'S DIGEST",
          "content": "SB 976, Skinner. Protecting Our Kids from Social Media Addiction Act. Existing law, the California Age-Appropriate Design Code Act, requires, beginning July 1, 2024, a business that provides an online service, product, or feature likely to be accessed by children to comply with certain requirements. The act requires the business to complete a data protection impact assessment addressing, among other things, whether the design could harm children and whether and how the online product, service, or feature uses system design features to increase, sustain, or extend use of the online product, service, or feature by children, including the automatic playing of media, rewards for time spent, and notifications. Existing law prohibits the business from using the personal information of any child in a way that the business knows, or has reason to know, is materially detrimental to the physical health, mental health, or well-being of a child.Existing law, the Privacy Rights for California Minors in the Digital World, prohibits an operator of an internet website, online service, online application, or mobile application from specified conduct when minors are involved, including the marketing or advertising of alcoholic beverages, firearms, or certain other products or services. Existing law sets forth other related protections for minors, including under the California Consumer Privacy Act of 2018 and the California Privacy Rights Act of 2020.This bill, the Protecting Our Kids from Social Media Addiction Act, would make it unlawful for the operator of an addictive internet-based service or application, as defined, to provide an addictive feed to a user, unless the operator does not have actual knowledge that the user is a minor; commencing January 1, 2027, has reasonably determined that the user is not a minor; or has obtained verifiable parental consent to provide an addictive feed to the user who is a minor.The bill would define “addictive feed” as an internet website, online service, online application, or mobile application, in which multiple pieces of media generated or shared by users are recommended, selected, or prioritized for display to a user based on information provided by the user, or otherwise associated with the user or the user’s device, as specified, unless any of certain conditions are met.The bill would make it unlawful for the operator of an addictive internet-based service or application, between the hours of 12 a.m. and 6 a.m., in the user’s local time zone, and between the hours of 8 a.m. and 3 p.m., Monday through Friday from September through May in the user’s local time zone, to send notifications to a user if the operator has actual knowledge that the user is a minor or, commencing January 1, 2027, has not reasonably determined that the user is not a minor, unless the operator has obtained verifiable parental consent to send those notifications, as specified. The bill would set forth related provisions for certain access controls determined by the verified parent through a mechanism provided by the operator.Under the bill, a parent’s provision of consent or use of a mechanism, as described above, would not waive, release, otherwise limit, or serve as a defense to, any claim that the parent, or that the user who is a minor or was a minor at the time of using the internet-based service or application, might have against the operator regarding any harm to the mental health or well-being of the user.The bill would require an operator to annually disclose the number of minor users of its addictive internet-based service or application, and of that total the number for whom the operator has received verifiable parental consent to provide an addictive feed, and the number of minor users as to whom the access controls are or are not enabled.Under the bill, these provisions would only be enforced in a civil action brought in the name of the people of the State of California by the Attorney General. The bill would require the Attorney General to adopt regulations to further the purposes of these provisions, including regulations regarding age assurance and parental consent by January 1, 2027. The bill would authorize the Attorney General to adopt regulations that provide for exceptions to these provisions, but only if those exceptions further the purpose of protecting minors. The bill would require the Attorney General, in promulgating regulations, to solicit public comment regarding the impact that any regulation might have based on certain nondiscrimination characteristics set forth in existing law.The bill would make these provisions severable. Existing law, the California Age-Appropriate Design Code Act, requires, beginning July 1, 2024, a business that provides an online service, product, or feature likely to be accessed by children to comply with certain requirements. The act requires the business to complete a data protection impact assessment addressing, among other things, whether the design could harm children and whether and how the online product, service, or feature uses system design features to increase, sustain, or extend use of the online product, service, or feature by children, including the automatic playing of media, rewards for time spent, and notifications. Existing law prohibits the business from using the personal information of any child in a way that the business knows, or has reason to know, is materially detrimental to the physical health, mental health, or well-being of a child. Existing law, the Privacy Rights for California Minors in the Digital World, prohibits an operator of an internet website, online service, online application, or mobile application from specified conduct when minors are involved, including the marketing or advertising of alcoholic beverages, firearms, or certain other products or services. Existing law sets forth other related protections for minors, including under the California Consumer Privacy Act of 2018 and the California Privacy Rights Act of 2020. This bill, the Protecting Our Kids from Social Media Addiction Act, would make it unlawful for the operator of an addictive internet-based service or application, as defined, to provide an addictive feed to a user, unless the operator does not have actual knowledge that the user is a minor; commencing January 1, 2027, has reasonably determined that the user is not a minor; or has obtained verifiable parental consent to provide an addictive feed to the user who is a minor. The bill would define “addictive feed” as an internet website, online service, online application, or mobile application, in which multiple pieces of media generated or shared by users are recommended, selected, or prioritized for display to a user based on information provided by the user, or otherwise associated with the user or the user’s device, as specified, unless any of certain conditions are met. The bill would make it unlawful for the operator of an addictive internet-based service or application, between the hours of 12 a.m. and 6 a.m., in the user’s local time zone, and between the hours of 8 a.m. and 3 p.m., Monday through Friday from September through May in the user’s local time zone, to send notifications to a user if the operator has actual knowledge that the user is a minor or, commencing January 1, 2027, has not reasonably determined that the user is not a minor, unless the operator has obtained verifiable parental consent to send those notifications, as specified. The bill would set forth related provisions for certain access controls determined by the verified parent through a mechanism provided by the operator. Under the bill, a parent’s provision of consent or use of a mechanism, as described above, would not waive, release, otherwise limit, or serve as a defense to, any claim that the parent, or that the user who is a minor or was a minor at the time of using the internet-based service or application, might have against the operator regarding any harm to the mental health or well-being of the user. The bill would require an operator to annually disclose the number of minor users of its addictive internet-based service or application, and of that total the number for whom the operator has received verifiable parental consent to provide an addictive feed, and the number of minor users as to whom the access controls are or are not enabled. Under the bill, these provisions would only be enforced in a civil action brought in the name of the people of the State of California by the Attorney General. The bill would require the Attorney General to adopt regulations to further the purposes of these provisions, including regulations regarding age assurance and parental consent by January 1, 2027. The bill would authorize the Attorney General to adopt regulations that provide for exceptions to these provisions, but only if those exceptions further the purpose of protecting minors. The bill would require the Attorney General, in promulgating regulations, to solicit public comment regarding the impact that any regulation might have based on certain nondiscrimination characteristics set forth in existing law. The bill would make these provisions severable. "
        },
        {
          "title": "Bill Text",
          "content": "The people of the State of California do enact as follows:SECTION 1. The Legislature finds and declares the following:(a) Social media provides an important tool for communication and information sharing. Approximately 95 percent of 13- to 17-year-olds, inclusive, say that they use at least one social media platform, and more than one-third report using social media almost constantly.(b) However, some social media platforms have evolved to include addictive features, including the algorithmic delivery of content and other design features, that pose a significant risk of harm to the mental health and well-being of children and adolescents.(c) As the United States Surgeon General has reported, recent evidence has identified “reasons for concern” about social media usage by children and adolescents. This evidence includes a study concluding that the risk of poor mental health outcomes doubles for children and adolescents who use social media at least three hours a day and research finding that social media usage is linked to a variety of negative health outcomes, including low self-esteem and disordered eating, for adolescent girls. (d) Heavier usage of social media also leads to less healthy sleep patterns and sleep quality, which can in turn exacerbate both physical and mental health problems.(e) Further, social media usage is more strongly associated with negative mental health outcomes, including depressive symptoms and self-harm behaviors, than is consumption of other forms of media such as television or electronic games. (f) Both California and the country as a whole are facing an ongoing youth mental health crisis, with rates of adolescent suicides, depressive episodes, and feelings of sadness and hopelessness on the rise in recent years. (g) For these reasons, it is essential that California act to ensure that social media platforms obtain parental consent before exposing children and adolescents to harmful and addictive social media features.SEC. 2. Chapter 24 (commencing with Section 27000) is added to Division 20 of the Health and Safety Code, to read: CHAPTER 24. Protecting Our Kids from Social Media Addiction Act27000. This chapter shall be known, and may be cited, as the Protecting Our Kids from Social Media Addiction Act.27000.5. For purposes of this chapter, the following terms have the following meanings:(a) “Addictive feed” means an internet website, online service, online application, or mobile application, or a portion thereof, in which multiple pieces of media generated or shared by users are, either concurrently or sequentially, recommended, selected, or prioritized for display to a user based, in whole or in part, on information provided by the user, or otherwise associated with the user or the user’s device, unless any of the following conditions are met, alone or in combination with one another:(1) The information is not persistently associated with the user or user’s device, and does not concern the user’s previous interactions with media generated or shared by others.(2) The information consists of search terms that are not persistently associated with the user or user’s device.(3) The information consists of user-selected privacy or accessibility settings, technical information concerning the user’s device, or device communications or signals concerning whether the user is a minor.(4) The user expressly and unambiguously requested the specific media or media by the author, creator, or poster of the media, or the blocking, prioritization, or deprioritization of such media, provided that the media is not recommended, selected, or prioritized for display based, in whole or in part, on other information associated with the user or the user’s device, except as otherwise permitted by this chapter and, in the case of audio or video content, is not automatically played.(5) The media consists of direct, private communications between users.(6) The media recommended, selected, or prioritized for display is exclusively the next media in a preexisting sequence from the same author, creator, poster, or source and, in the case of audio or video content, is not automatically played.(7) The recommendation, selection, or prioritization of the media is necessary to comply with this chapter or any regulations promulgated pursuant to this chapter.(b) (1) “Addictive internet-based service or application” means an internet website, online service, online application, or mobile application, including, but not limited to, a “social media platform” as defined in Section 22675 of the Business and Professions Code, that offers users or provides users with an addictive feed as a significant part of the service provided by that internet website, online service, online application, or mobile application.(2) “Addictive internet-based service or application” does not apply to either of the following:(A) An internet website, online service, online application, or mobile application for which interactions between users are limited to commercial transactions or to consumer reviews of products, sellers, services, events, or places, or any combination thereof.(B) An internet website, online service, online application, or mobile application that operates a feed for the primary purpose of cloud storage.(c) “Media” means text, audio, an image, or a video.(d) “Minor” means an individual under 18 years of age who is located in the State of California.(e) “Operator” means a person who operates or provides an internet website, an online service, an online application, or a mobile application.(f) “Parent” means a parent or guardian, including as defined in regulations promulgated pursuant to this chapter.(g) “User” means a person who uses an internet website, online service, online application, or mobile application. “User” does not include the operator or a person acting as an agent of the operator.27001. (a) It shall be unlawful for the operator of an addictive internet-based service or application to provide an addictive feed to a user unless either of the following is met:(1) (A) Except as provided in subparagraph (B), the operator does not have actual knowledge that the user is a minor.(B) Commencing January 1, 2027, the operator has reasonably determined that the user is not a minor, including pursuant to regulations promulgated by the Attorney General.(2) The operator has obtained verifiable parental consent to provide an addictive feed to the user who is a minor.(b) Information collected for the purpose of determining a user’s age or verifying parental consent pursuant to this chapter shall not be used for any purpose other than compliance with this chapter or with another applicable law. The information collected shall be deleted immediately after it is used to determine a user’s age or to verify parental consent, except as necessary to comply with state or federal law.27002. (a) (1) Except as provided in paragraph (2), it shall be unlawful for the operator of an addictive internet-based service or application, between the hours of 12 a.m. and 6 a.m., in the user’s local time zone, and between the hours of 8 a.m. and 3 p.m., from Monday through Friday from September through May in the user’s local time zone, to send notifications to a user if the operator has actual knowledge that the user is a minor unless the operator has obtained verifiable parental consent to send those notifications.(2) Commencing January 1, 2027, it shall be unlawful for the operator of an addictive internet-based service or application, between the hours of 12 a.m. and 6 a.m., in the user’s local time zone, and between the hours of 8 a.m. and 3 p.m., from Monday through Friday from September through May in the user’s local time zone, to send notifications to a user whom the operator has not reasonably determined is not a minor, including pursuant to regulations promulgated by the Attorney General, unless the operator has obtained verifiable parental consent to send those notifications.(b) The operator of an addictive internet-based service or application shall provide a mechanism through which the verified parent of a user who is a minor may do any of the following:(1) Prevent their child from accessing or receiving notifications from the addictive internet-based service or application between specific hours chosen by the parent. This setting shall be set by the operator as on by default, in a manner in which the child’s access is limited between the hours of 12 a.m. and 6 a.m., in the user’s local time zone.(2) Limit their child’s access to any addictive feed from the addictive internet-based service or application to a length of time per day specified by the verified parent. This setting shall be set by the operator as on by default, in a manner in which the child’s access is limited to one hour per day unless modified by the verified parent.(3) Limit their child’s ability to view the number of likes or other forms of feedback to pieces of media within an addictive feed. This setting shall be set by the operator as on by default.(4) Require that the default feed provided to the child when entering the internet-based service or application be one in which pieces of media are not recommended, selected, or prioritized for display based on information provided by the user, or otherwise associated with the user or the user’s device, other than the user’s age or status as a minor.(5) Set their child’s account to private mode, in a manner in which only users to whom the child is connected on the addictive internet-based service or application may view or respond to content posted by the child. This setting shall be set by the operator as on by default.27003. (a) This chapter shall not be construed as requiring the operator of an addictive internet-based service or application to give a parent any additional or special access to, or control over, the data or accounts of their child.(b) This chapter shall not be construed as preventing any action taken in good faith to restrict access to, or availability of, media.27004. (a) An operator may choose not to provide services to minors. However, the operator of an addictive internet-based service or application shall not withhold, degrade, lower the quality of, or increase the price of, any product, service, or feature, other than as required by this chapter, due to a user or parent availing themselves of the rights provided by this chapter, or due to the protections required by this chapter.(b) A parent’s provision of consent as described in Section 27001 or 27002, or the use by a parent of a mechanism as described in Section 27002, does not waive, release, otherwise limit, or serve as a defense to, any claim that the parent, or that the user who is a minor or was a minor at the time of using the internet-based service or application, might have against the operator of an addictive internet-based service or application regarding any harm to the mental health or well-being of the user.(c) The protections provided by this chapter are in addition to those provided by any other applicable law, including, but not limited to, the California Age-Appropriate Design Code Act (Title 1.81.47 (commencing with Section 1798.99.28) of Part 4 of Division 3 of the Civil Code).27005. An operator of an addictive internet-based service or application shall publicly disclose, on an annual basis, the number of minor users of its addictive internet-based service or application, and of that total the number for whom the operator has received verifiable parental consent to provide an addictive feed, and the number of minor users as to whom the controls set forth in Section 27002 are or are not enabled. 27006. (a) This chapter may only be enforced in a civil action brought in the name of the people of the State of California by the Attorney General.(b) The Attorney General shall adopt regulations to further the purposes of this chapter, including regulations regarding age assurance and parental consent by January 1, 2027. The Attorney General may adopt regulations that provide for exceptions to this chapter, but only if those exceptions further the purpose of protecting minors.(c) In promulgating the regulations described in subdivision (b), the Attorney General shall solicit public comment regarding the impact that any regulation might have based on the nondiscrimination characteristics set forth in Section 51 of the Civil Code or in any other applicable law.27007. If any provision of this chapter, or application thereof, to any person or circumstance is held invalid, that invalidity shall not affect other provisions or applications of this chapter that can be given effect without the invalid provision or application, and to this end the provisions of this chapter are declared to be severable. The people of the State of California do enact as follows: "
        },
        {
          "title": "The people of the State of California do enact as follows:",
          "content": "SECTION 1. The Legislature finds and declares the following:(a) Social media provides an important tool for communication and information sharing. Approximately 95 percent of 13- to 17-year-olds, inclusive, say that they use at least one social media platform, and more than one-third report using social media almost constantly.(b) However, some social media platforms have evolved to include addictive features, including the algorithmic delivery of content and other design features, that pose a significant risk of harm to the mental health and well-being of children and adolescents.(c) As the United States Surgeon General has reported, recent evidence has identified “reasons for concern” about social media usage by children and adolescents. This evidence includes a study concluding that the risk of poor mental health outcomes doubles for children and adolescents who use social media at least three hours a day and research finding that social media usage is linked to a variety of negative health outcomes, including low self-esteem and disordered eating, for adolescent girls. (d) Heavier usage of social media also leads to less healthy sleep patterns and sleep quality, which can in turn exacerbate both physical and mental health problems.(e) Further, social media usage is more strongly associated with negative mental health outcomes, including depressive symptoms and self-harm behaviors, than is consumption of other forms of media such as television or electronic games. (f) Both California and the country as a whole are facing an ongoing youth mental health crisis, with rates of adolescent suicides, depressive episodes, and feelings of sadness and hopelessness on the rise in recent years. (g) For these reasons, it is essential that California act to ensure that social media platforms obtain parental consent before exposing children and adolescents to harmful and addictive social media features. SECTION 1. The Legislature finds and declares the following:(a) Social media provides an important tool for communication and information sharing. Approximately 95 percent of 13- to 17-year-olds, inclusive, say that they use at least one social media platform, and more than one-third report using social media almost constantly.(b) However, some social media platforms have evolved to include addictive features, including the algorithmic delivery of content and other design features, that pose a significant risk of harm to the mental health and well-being of children and adolescents.(c) As the United States Surgeon General has reported, recent evidence has identified “reasons for concern” about social media usage by children and adolescents. This evidence includes a study concluding that the risk of poor mental health outcomes doubles for children and adolescents who use social media at least three hours a day and research finding that social media usage is linked to a variety of negative health outcomes, including low self-esteem and disordered eating, for adolescent girls. (d) Heavier usage of social media also leads to less healthy sleep patterns and sleep quality, which can in turn exacerbate both physical and mental health problems.(e) Further, social media usage is more strongly associated with negative mental health outcomes, including depressive symptoms and self-harm behaviors, than is consumption of other forms of media such as television or electronic games. (f) Both California and the country as a whole are facing an ongoing youth mental health crisis, with rates of adolescent suicides, depressive episodes, and feelings of sadness and hopelessness on the rise in recent years. (g) For these reasons, it is essential that California act to ensure that social media platforms obtain parental consent before exposing children and adolescents to harmful and addictive social media features. SECTION 1. The Legislature finds and declares the following: "
        },
        {
          "title": "SECTION 1.",
          "content": "(a) Social media provides an important tool for communication and information sharing. Approximately 95 percent of 13- to 17-year-olds, inclusive, say that they use at least one social media platform, and more than one-third report using social media almost constantly. (b) However, some social media platforms have evolved to include addictive features, including the algorithmic delivery of content and other design features, that pose a significant risk of harm to the mental health and well-being of children and adolescents. (c) As the United States Surgeon General has reported, recent evidence has identified “reasons for concern” about social media usage by children and adolescents. This evidence includes a study concluding that the risk of poor mental health outcomes doubles for children and adolescents who use social media at least three hours a day and research finding that social media usage is linked to a variety of negative health outcomes, including low self-esteem and disordered eating, for adolescent girls. (d) Heavier usage of social media also leads to less healthy sleep patterns and sleep quality, which can in turn exacerbate both physical and mental health problems. (e) Further, social media usage is more strongly associated with negative mental health outcomes, including depressive symptoms and self-harm behaviors, than is consumption of other forms of media such as television or electronic games. (f) Both California and the country as a whole are facing an ongoing youth mental health crisis, with rates of adolescent suicides, depressive episodes, and feelings of sadness and hopelessness on the rise in recent years. (g) For these reasons, it is essential that California act to ensure that social media platforms obtain parental consent before exposing children and adolescents to harmful and addictive social media features. SEC. 2. Chapter 24 (commencing with Section 27000) is added to Division 20 of the Health and Safety Code, to read: CHAPTER 24. Protecting Our Kids from Social Media Addiction Act27000. This chapter shall be known, and may be cited, as the Protecting Our Kids from Social Media Addiction Act.27000.5. For purposes of this chapter, the following terms have the following meanings:(a) “Addictive feed” means an internet website, online service, online application, or mobile application, or a portion thereof, in which multiple pieces of media generated or shared by users are, either concurrently or sequentially, recommended, selected, or prioritized for display to a user based, in whole or in part, on information provided by the user, or otherwise associated with the user or the user’s device, unless any of the following conditions are met, alone or in combination with one another:(1) The information is not persistently associated with the user or user’s device, and does not concern the user’s previous interactions with media generated or shared by others.(2) The information consists of search terms that are not persistently associated with the user or user’s device.(3) The information consists of user-selected privacy or accessibility settings, technical information concerning the user’s device, or device communications or signals concerning whether the user is a minor.(4) The user expressly and unambiguously requested the specific media or media by the author, creator, or poster of the media, or the blocking, prioritization, or deprioritization of such media, provided that the media is not recommended, selected, or prioritized for display based, in whole or in part, on other information associated with the user or the user’s device, except as otherwise permitted by this chapter and, in the case of audio or video content, is not automatically played.(5) The media consists of direct, private communications between users.(6) The media recommended, selected, or prioritized for display is exclusively the next media in a preexisting sequence from the same author, creator, poster, or source and, in the case of audio or video content, is not automatically played.(7) The recommendation, selection, or prioritization of the media is necessary to comply with this chapter or any regulations promulgated pursuant to this chapter.(b) (1) “Addictive internet-based service or application” means an internet website, online service, online application, or mobile application, including, but not limited to, a “social media platform” as defined in Section 22675 of the Business and Professions Code, that offers users or provides users with an addictive feed as a significant part of the service provided by that internet website, online service, online application, or mobile application.(2) “Addictive internet-based service or application” does not apply to either of the following:(A) An internet website, online service, online application, or mobile application for which interactions between users are limited to commercial transactions or to consumer reviews of products, sellers, services, events, or places, or any combination thereof.(B) An internet website, online service, online application, or mobile application that operates a feed for the primary purpose of cloud storage.(c) “Media” means text, audio, an image, or a video.(d) “Minor” means an individual under 18 years of age who is located in the State of California.(e) “Operator” means a person who operates or provides an internet website, an online service, an online application, or a mobile application.(f) “Parent” means a parent or guardian, including as defined in regulations promulgated pursuant to this chapter.(g) “User” means a person who uses an internet website, online service, online application, or mobile application. “User” does not include the operator or a person acting as an agent of the operator.27001. (a) It shall be unlawful for the operator of an addictive internet-based service or application to provide an addictive feed to a user unless either of the following is met:(1) (A) Except as provided in subparagraph (B), the operator does not have actual knowledge that the user is a minor.(B) Commencing January 1, 2027, the operator has reasonably determined that the user is not a minor, including pursuant to regulations promulgated by the Attorney General.(2) The operator has obtained verifiable parental consent to provide an addictive feed to the user who is a minor.(b) Information collected for the purpose of determining a user’s age or verifying parental consent pursuant to this chapter shall not be used for any purpose other than compliance with this chapter or with another applicable law. The information collected shall be deleted immediately after it is used to determine a user’s age or to verify parental consent, except as necessary to comply with state or federal law.27002. (a) (1) Except as provided in paragraph (2), it shall be unlawful for the operator of an addictive internet-based service or application, between the hours of 12 a.m. and 6 a.m., in the user’s local time zone, and between the hours of 8 a.m. and 3 p.m., from Monday through Friday from September through May in the user’s local time zone, to send notifications to a user if the operator has actual knowledge that the user is a minor unless the operator has obtained verifiable parental consent to send those notifications.(2) Commencing January 1, 2027, it shall be unlawful for the operator of an addictive internet-based service or application, between the hours of 12 a.m. and 6 a.m., in the user’s local time zone, and between the hours of 8 a.m. and 3 p.m., from Monday through Friday from September through May in the user’s local time zone, to send notifications to a user whom the operator has not reasonably determined is not a minor, including pursuant to regulations promulgated by the Attorney General, unless the operator has obtained verifiable parental consent to send those notifications.(b) The operator of an addictive internet-based service or application shall provide a mechanism through which the verified parent of a user who is a minor may do any of the following:(1) Prevent their child from accessing or receiving notifications from the addictive internet-based service or application between specific hours chosen by the parent. This setting shall be set by the operator as on by default, in a manner in which the child’s access is limited between the hours of 12 a.m. and 6 a.m., in the user’s local time zone.(2) Limit their child’s access to any addictive feed from the addictive internet-based service or application to a length of time per day specified by the verified parent. This setting shall be set by the operator as on by default, in a manner in which the child’s access is limited to one hour per day unless modified by the verified parent.(3) Limit their child’s ability to view the number of likes or other forms of feedback to pieces of media within an addictive feed. This setting shall be set by the operator as on by default.(4) Require that the default feed provided to the child when entering the internet-based service or application be one in which pieces of media are not recommended, selected, or prioritized for display based on information provided by the user, or otherwise associated with the user or the user’s device, other than the user’s age or status as a minor.(5) Set their child’s account to private mode, in a manner in which only users to whom the child is connected on the addictive internet-based service or application may view or respond to content posted by the child. This setting shall be set by the operator as on by default.27003. (a) This chapter shall not be construed as requiring the operator of an addictive internet-based service or application to give a parent any additional or special access to, or control over, the data or accounts of their child.(b) This chapter shall not be construed as preventing any action taken in good faith to restrict access to, or availability of, media.27004. (a) An operator may choose not to provide services to minors. However, the operator of an addictive internet-based service or application shall not withhold, degrade, lower the quality of, or increase the price of, any product, service, or feature, other than as required by this chapter, due to a user or parent availing themselves of the rights provided by this chapter, or due to the protections required by this chapter.(b) A parent’s provision of consent as described in Section 27001 or 27002, or the use by a parent of a mechanism as described in Section 27002, does not waive, release, otherwise limit, or serve as a defense to, any claim that the parent, or that the user who is a minor or was a minor at the time of using the internet-based service or application, might have against the operator of an addictive internet-based service or application regarding any harm to the mental health or well-being of the user.(c) The protections provided by this chapter are in addition to those provided by any other applicable law, including, but not limited to, the California Age-Appropriate Design Code Act (Title 1.81.47 (commencing with Section 1798.99.28) of Part 4 of Division 3 of the Civil Code).27005. An operator of an addictive internet-based service or application shall publicly disclose, on an annual basis, the number of minor users of its addictive internet-based service or application, and of that total the number for whom the operator has received verifiable parental consent to provide an addictive feed, and the number of minor users as to whom the controls set forth in Section 27002 are or are not enabled. 27006. (a) This chapter may only be enforced in a civil action brought in the name of the people of the State of California by the Attorney General.(b) The Attorney General shall adopt regulations to further the purposes of this chapter, including regulations regarding age assurance and parental consent by January 1, 2027. The Attorney General may adopt regulations that provide for exceptions to this chapter, but only if those exceptions further the purpose of protecting minors.(c) In promulgating the regulations described in subdivision (b), the Attorney General shall solicit public comment regarding the impact that any regulation might have based on the nondiscrimination characteristics set forth in Section 51 of the Civil Code or in any other applicable law.27007. If any provision of this chapter, or application thereof, to any person or circumstance is held invalid, that invalidity shall not affect other provisions or applications of this chapter that can be given effect without the invalid provision or application, and to this end the provisions of this chapter are declared to be severable. SEC. 2. Chapter 24 (commencing with Section 27000) is added to Division 20 of the Health and Safety Code, to read: "
        },
        {
          "title": "SEC. 2.",
          "content": "CHAPTER 24. Protecting Our Kids from Social Media Addiction Act27000. This chapter shall be known, and may be cited, as the Protecting Our Kids from Social Media Addiction Act.27000.5. For purposes of this chapter, the following terms have the following meanings:(a) “Addictive feed” means an internet website, online service, online application, or mobile application, or a portion thereof, in which multiple pieces of media generated or shared by users are, either concurrently or sequentially, recommended, selected, or prioritized for display to a user based, in whole or in part, on information provided by the user, or otherwise associated with the user or the user’s device, unless any of the following conditions are met, alone or in combination with one another:(1) The information is not persistently associated with the user or user’s device, and does not concern the user’s previous interactions with media generated or shared by others.(2) The information consists of search terms that are not persistently associated with the user or user’s device.(3) The information consists of user-selected privacy or accessibility settings, technical information concerning the user’s device, or device communications or signals concerning whether the user is a minor.(4) The user expressly and unambiguously requested the specific media or media by the author, creator, or poster of the media, or the blocking, prioritization, or deprioritization of such media, provided that the media is not recommended, selected, or prioritized for display based, in whole or in part, on other information associated with the user or the user’s device, except as otherwise permitted by this chapter and, in the case of audio or video content, is not automatically played.(5) The media consists of direct, private communications between users.(6) The media recommended, selected, or prioritized for display is exclusively the next media in a preexisting sequence from the same author, creator, poster, or source and, in the case of audio or video content, is not automatically played.(7) The recommendation, selection, or prioritization of the media is necessary to comply with this chapter or any regulations promulgated pursuant to this chapter.(b) (1) “Addictive internet-based service or application” means an internet website, online service, online application, or mobile application, including, but not limited to, a “social media platform” as defined in Section 22675 of the Business and Professions Code, that offers users or provides users with an addictive feed as a significant part of the service provided by that internet website, online service, online application, or mobile application.(2) “Addictive internet-based service or application” does not apply to either of the following:(A) An internet website, online service, online application, or mobile application for which interactions between users are limited to commercial transactions or to consumer reviews of products, sellers, services, events, or places, or any combination thereof.(B) An internet website, online service, online application, or mobile application that operates a feed for the primary purpose of cloud storage.(c) “Media” means text, audio, an image, or a video.(d) “Minor” means an individual under 18 years of age who is located in the State of California.(e) “Operator” means a person who operates or provides an internet website, an online service, an online application, or a mobile application.(f) “Parent” means a parent or guardian, including as defined in regulations promulgated pursuant to this chapter.(g) “User” means a person who uses an internet website, online service, online application, or mobile application. “User” does not include the operator or a person acting as an agent of the operator.27001. (a) It shall be unlawful for the operator of an addictive internet-based service or application to provide an addictive feed to a user unless either of the following is met:(1) (A) Except as provided in subparagraph (B), the operator does not have actual knowledge that the user is a minor.(B) Commencing January 1, 2027, the operator has reasonably determined that the user is not a minor, including pursuant to regulations promulgated by the Attorney General.(2) The operator has obtained verifiable parental consent to provide an addictive feed to the user who is a minor.(b) Information collected for the purpose of determining a user’s age or verifying parental consent pursuant to this chapter shall not be used for any purpose other than compliance with this chapter or with another applicable law. The information collected shall be deleted immediately after it is used to determine a user’s age or to verify parental consent, except as necessary to comply with state or federal law.27002. (a) (1) Except as provided in paragraph (2), it shall be unlawful for the operator of an addictive internet-based service or application, between the hours of 12 a.m. and 6 a.m., in the user’s local time zone, and between the hours of 8 a.m. and 3 p.m., from Monday through Friday from September through May in the user’s local time zone, to send notifications to a user if the operator has actual knowledge that the user is a minor unless the operator has obtained verifiable parental consent to send those notifications.(2) Commencing January 1, 2027, it shall be unlawful for the operator of an addictive internet-based service or application, between the hours of 12 a.m. and 6 a.m., in the user’s local time zone, and between the hours of 8 a.m. and 3 p.m., from Monday through Friday from September through May in the user’s local time zone, to send notifications to a user whom the operator has not reasonably determined is not a minor, including pursuant to regulations promulgated by the Attorney General, unless the operator has obtained verifiable parental consent to send those notifications.(b) The operator of an addictive internet-based service or application shall provide a mechanism through which the verified parent of a user who is a minor may do any of the following:(1) Prevent their child from accessing or receiving notifications from the addictive internet-based service or application between specific hours chosen by the parent. This setting shall be set by the operator as on by default, in a manner in which the child’s access is limited between the hours of 12 a.m. and 6 a.m., in the user’s local time zone.(2) Limit their child’s access to any addictive feed from the addictive internet-based service or application to a length of time per day specified by the verified parent. This setting shall be set by the operator as on by default, in a manner in which the child’s access is limited to one hour per day unless modified by the verified parent.(3) Limit their child’s ability to view the number of likes or other forms of feedback to pieces of media within an addictive feed. This setting shall be set by the operator as on by default.(4) Require that the default feed provided to the child when entering the internet-based service or application be one in which pieces of media are not recommended, selected, or prioritized for display based on information provided by the user, or otherwise associated with the user or the user’s device, other than the user’s age or status as a minor.(5) Set their child’s account to private mode, in a manner in which only users to whom the child is connected on the addictive internet-based service or application may view or respond to content posted by the child. This setting shall be set by the operator as on by default.27003. (a) This chapter shall not be construed as requiring the operator of an addictive internet-based service or application to give a parent any additional or special access to, or control over, the data or accounts of their child.(b) This chapter shall not be construed as preventing any action taken in good faith to restrict access to, or availability of, media.27004. (a) An operator may choose not to provide services to minors. However, the operator of an addictive internet-based service or application shall not withhold, degrade, lower the quality of, or increase the price of, any product, service, or feature, other than as required by this chapter, due to a user or parent availing themselves of the rights provided by this chapter, or due to the protections required by this chapter.(b) A parent’s provision of consent as described in Section 27001 or 27002, or the use by a parent of a mechanism as described in Section 27002, does not waive, release, otherwise limit, or serve as a defense to, any claim that the parent, or that the user who is a minor or was a minor at the time of using the internet-based service or application, might have against the operator of an addictive internet-based service or application regarding any harm to the mental health or well-being of the user.(c) The protections provided by this chapter are in addition to those provided by any other applicable law, including, but not limited to, the California Age-Appropriate Design Code Act (Title 1.81.47 (commencing with Section 1798.99.28) of Part 4 of Division 3 of the Civil Code).27005. An operator of an addictive internet-based service or application shall publicly disclose, on an annual basis, the number of minor users of its addictive internet-based service or application, and of that total the number for whom the operator has received verifiable parental consent to provide an addictive feed, and the number of minor users as to whom the controls set forth in Section 27002 are or are not enabled. 27006. (a) This chapter may only be enforced in a civil action brought in the name of the people of the State of California by the Attorney General.(b) The Attorney General shall adopt regulations to further the purposes of this chapter, including regulations regarding age assurance and parental consent by January 1, 2027. The Attorney General may adopt regulations that provide for exceptions to this chapter, but only if those exceptions further the purpose of protecting minors.(c) In promulgating the regulations described in subdivision (b), the Attorney General shall solicit public comment regarding the impact that any regulation might have based on the nondiscrimination characteristics set forth in Section 51 of the Civil Code or in any other applicable law.27007. If any provision of this chapter, or application thereof, to any person or circumstance is held invalid, that invalidity shall not affect other provisions or applications of this chapter that can be given effect without the invalid provision or application, and to this end the provisions of this chapter are declared to be severable. CHAPTER 24. Protecting Our Kids from Social Media Addiction Act27000. This chapter shall be known, and may be cited, as the Protecting Our Kids from Social Media Addiction Act.27000.5. For purposes of this chapter, the following terms have the following meanings:(a) “Addictive feed” means an internet website, online service, online application, or mobile application, or a portion thereof, in which multiple pieces of media generated or shared by users are, either concurrently or sequentially, recommended, selected, or prioritized for display to a user based, in whole or in part, on information provided by the user, or otherwise associated with the user or the user’s device, unless any of the following conditions are met, alone or in combination with one another:(1) The information is not persistently associated with the user or user’s device, and does not concern the user’s previous interactions with media generated or shared by others.(2) The information consists of search terms that are not persistently associated with the user or user’s device.(3) The information consists of user-selected privacy or accessibility settings, technical information concerning the user’s device, or device communications or signals concerning whether the user is a minor.(4) The user expressly and unambiguously requested the specific media or media by the author, creator, or poster of the media, or the blocking, prioritization, or deprioritization of such media, provided that the media is not recommended, selected, or prioritized for display based, in whole or in part, on other information associated with the user or the user’s device, except as otherwise permitted by this chapter and, in the case of audio or video content, is not automatically played.(5) The media consists of direct, private communications between users.(6) The media recommended, selected, or prioritized for display is exclusively the next media in a preexisting sequence from the same author, creator, poster, or source and, in the case of audio or video content, is not automatically played.(7) The recommendation, selection, or prioritization of the media is necessary to comply with this chapter or any regulations promulgated pursuant to this chapter.(b) (1) “Addictive internet-based service or application” means an internet website, online service, online application, or mobile application, including, but not limited to, a “social media platform” as defined in Section 22675 of the Business and Professions Code, that offers users or provides users with an addictive feed as a significant part of the service provided by that internet website, online service, online application, or mobile application.(2) “Addictive internet-based service or application” does not apply to either of the following:(A) An internet website, online service, online application, or mobile application for which interactions between users are limited to commercial transactions or to consumer reviews of products, sellers, services, events, or places, or any combination thereof.(B) An internet website, online service, online application, or mobile application that operates a feed for the primary purpose of cloud storage.(c) “Media” means text, audio, an image, or a video.(d) “Minor” means an individual under 18 years of age who is located in the State of California.(e) “Operator” means a person who operates or provides an internet website, an online service, an online application, or a mobile application.(f) “Parent” means a parent or guardian, including as defined in regulations promulgated pursuant to this chapter.(g) “User” means a person who uses an internet website, online service, online application, or mobile application. “User” does not include the operator or a person acting as an agent of the operator.27001. (a) It shall be unlawful for the operator of an addictive internet-based service or application to provide an addictive feed to a user unless either of the following is met:(1) (A) Except as provided in subparagraph (B), the operator does not have actual knowledge that the user is a minor.(B) Commencing January 1, 2027, the operator has reasonably determined that the user is not a minor, including pursuant to regulations promulgated by the Attorney General.(2) The operator has obtained verifiable parental consent to provide an addictive feed to the user who is a minor.(b) Information collected for the purpose of determining a user’s age or verifying parental consent pursuant to this chapter shall not be used for any purpose other than compliance with this chapter or with another applicable law. The information collected shall be deleted immediately after it is used to determine a user’s age or to verify parental consent, except as necessary to comply with state or federal law.27002. (a) (1) Except as provided in paragraph (2), it shall be unlawful for the operator of an addictive internet-based service or application, between the hours of 12 a.m. and 6 a.m., in the user’s local time zone, and between the hours of 8 a.m. and 3 p.m., from Monday through Friday from September through May in the user’s local time zone, to send notifications to a user if the operator has actual knowledge that the user is a minor unless the operator has obtained verifiable parental consent to send those notifications.(2) Commencing January 1, 2027, it shall be unlawful for the operator of an addictive internet-based service or application, between the hours of 12 a.m. and 6 a.m., in the user’s local time zone, and between the hours of 8 a.m. and 3 p.m., from Monday through Friday from September through May in the user’s local time zone, to send notifications to a user whom the operator has not reasonably determined is not a minor, including pursuant to regulations promulgated by the Attorney General, unless the operator has obtained verifiable parental consent to send those notifications.(b) The operator of an addictive internet-based service or application shall provide a mechanism through which the verified parent of a user who is a minor may do any of the following:(1) Prevent their child from accessing or receiving notifications from the addictive internet-based service or application between specific hours chosen by the parent. This setting shall be set by the operator as on by default, in a manner in which the child’s access is limited between the hours of 12 a.m. and 6 a.m., in the user’s local time zone.(2) Limit their child’s access to any addictive feed from the addictive internet-based service or application to a length of time per day specified by the verified parent. This setting shall be set by the operator as on by default, in a manner in which the child’s access is limited to one hour per day unless modified by the verified parent.(3) Limit their child’s ability to view the number of likes or other forms of feedback to pieces of media within an addictive feed. This setting shall be set by the operator as on by default.(4) Require that the default feed provided to the child when entering the internet-based service or application be one in which pieces of media are not recommended, selected, or prioritized for display based on information provided by the user, or otherwise associated with the user or the user’s device, other than the user’s age or status as a minor.(5) Set their child’s account to private mode, in a manner in which only users to whom the child is connected on the addictive internet-based service or application may view or respond to content posted by the child. This setting shall be set by the operator as on by default.27003. (a) This chapter shall not be construed as requiring the operator of an addictive internet-based service or application to give a parent any additional or special access to, or control over, the data or accounts of their child.(b) This chapter shall not be construed as preventing any action taken in good faith to restrict access to, or availability of, media.27004. (a) An operator may choose not to provide services to minors. However, the operator of an addictive internet-based service or application shall not withhold, degrade, lower the quality of, or increase the price of, any product, service, or feature, other than as required by this chapter, due to a user or parent availing themselves of the rights provided by this chapter, or due to the protections required by this chapter.(b) A parent’s provision of consent as described in Section 27001 or 27002, or the use by a parent of a mechanism as described in Section 27002, does not waive, release, otherwise limit, or serve as a defense to, any claim that the parent, or that the user who is a minor or was a minor at the time of using the internet-based service or application, might have against the operator of an addictive internet-based service or application regarding any harm to the mental health or well-being of the user.(c) The protections provided by this chapter are in addition to those provided by any other applicable law, including, but not limited to, the California Age-Appropriate Design Code Act (Title 1.81.47 (commencing with Section 1798.99.28) of Part 4 of Division 3 of the Civil Code).27005. An operator of an addictive internet-based service or application shall publicly disclose, on an annual basis, the number of minor users of its addictive internet-based service or application, and of that total the number for whom the operator has received verifiable parental consent to provide an addictive feed, and the number of minor users as to whom the controls set forth in Section 27002 are or are not enabled. 27006. (a) This chapter may only be enforced in a civil action brought in the name of the people of the State of California by the Attorney General.(b) The Attorney General shall adopt regulations to further the purposes of this chapter, including regulations regarding age assurance and parental consent by January 1, 2027. The Attorney General may adopt regulations that provide for exceptions to this chapter, but only if those exceptions further the purpose of protecting minors.(c) In promulgating the regulations described in subdivision (b), the Attorney General shall solicit public comment regarding the impact that any regulation might have based on the nondiscrimination characteristics set forth in Section 51 of the Civil Code or in any other applicable law.27007. If any provision of this chapter, or application thereof, to any person or circumstance is held invalid, that invalidity shall not affect other provisions or applications of this chapter that can be given effect without the invalid provision or application, and to this end the provisions of this chapter are declared to be severable. CHAPTER 24. Protecting Our Kids from Social Media Addiction Act CHAPTER 24. Protecting Our Kids from Social Media Addiction Act 27000. This chapter shall be known, and may be cited, as the Protecting Our Kids from Social Media Addiction Act. 27000. This chapter shall be known, and may be cited, as the Protecting Our Kids from Social Media Addiction Act. 27000.5. For purposes of this chapter, the following terms have the following meanings:(a) “Addictive feed” means an internet website, online service, online application, or mobile application, or a portion thereof, in which multiple pieces of media generated or shared by users are, either concurrently or sequentially, recommended, selected, or prioritized for display to a user based, in whole or in part, on information provided by the user, or otherwise associated with the user or the user’s device, unless any of the following conditions are met, alone or in combination with one another:(1) The information is not persistently associated with the user or user’s device, and does not concern the user’s previous interactions with media generated or shared by others.(2) The information consists of search terms that are not persistently associated with the user or user’s device.(3) The information consists of user-selected privacy or accessibility settings, technical information concerning the user’s device, or device communications or signals concerning whether the user is a minor.(4) The user expressly and unambiguously requested the specific media or media by the author, creator, or poster of the media, or the blocking, prioritization, or deprioritization of such media, provided that the media is not recommended, selected, or prioritized for display based, in whole or in part, on other information associated with the user or the user’s device, except as otherwise permitted by this chapter and, in the case of audio or video content, is not automatically played.(5) The media consists of direct, private communications between users.(6) The media recommended, selected, or prioritized for display is exclusively the next media in a preexisting sequence from the same author, creator, poster, or source and, in the case of audio or video content, is not automatically played.(7) The recommendation, selection, or prioritization of the media is necessary to comply with this chapter or any regulations promulgated pursuant to this chapter.(b) (1) “Addictive internet-based service or application” means an internet website, online service, online application, or mobile application, including, but not limited to, a “social media platform” as defined in Section 22675 of the Business and Professions Code, that offers users or provides users with an addictive feed as a significant part of the service provided by that internet website, online service, online application, or mobile application.(2) “Addictive internet-based service or application” does not apply to either of the following:(A) An internet website, online service, online application, or mobile application for which interactions between users are limited to commercial transactions or to consumer reviews of products, sellers, services, events, or places, or any combination thereof.(B) An internet website, online service, online application, or mobile application that operates a feed for the primary purpose of cloud storage.(c) “Media” means text, audio, an image, or a video.(d) “Minor” means an individual under 18 years of age who is located in the State of California.(e) “Operator” means a person who operates or provides an internet website, an online service, an online application, or a mobile application.(f) “Parent” means a parent or guardian, including as defined in regulations promulgated pursuant to this chapter.(g) “User” means a person who uses an internet website, online service, online application, or mobile application. “User” does not include the operator or a person acting as an agent of the operator. 27000.5. For purposes of this chapter, the following terms have the following meanings: (a) “Addictive feed” means an internet website, online service, online application, or mobile application, or a portion thereof, in which multiple pieces of media generated or shared by users are, either concurrently or sequentially, recommended, selected, or prioritized for display to a user based, in whole or in part, on information provided by the user, or otherwise associated with the user or the user’s device, unless any of the following conditions are met, alone or in combination with one another: (1) The information is not persistently associated with the user or user’s device, and does not concern the user’s previous interactions with media generated or shared by others. (2) The information consists of search terms that are not persistently associated with the user or user’s device. (3) The information consists of user-selected privacy or accessibility settings, technical information concerning the user’s device, or device communications or signals concerning whether the user is a minor. (4) The user expressly and unambiguously requested the specific media or media by the author, creator, or poster of the media, or the blocking, prioritization, or deprioritization of such media, provided that the media is not recommended, selected, or prioritized for display based, in whole or in part, on other information associated with the user or the user’s device, except as otherwise permitted by this chapter and, in the case of audio or video content, is not automatically played. (5) The media consists of direct, private communications between users. (6) The media recommended, selected, or prioritized for display is exclusively the next media in a preexisting sequence from the same author, creator, poster, or source and, in the case of audio or video content, is not automatically played. (7) The recommendation, selection, or prioritization of the media is necessary to comply with this chapter or any regulations promulgated pursuant to this chapter. (b) (1) “Addictive internet-based service or application” means an internet website, online service, online application, or mobile application, including, but not limited to, a “social media platform” as defined in Section 22675 of the Business and Professions Code, that offers users or provides users with an addictive feed as a significant part of the service provided by that internet website, online service, online application, or mobile application. (2) “Addictive internet-based service or application” does not apply to either of the following: (A) An internet website, online service, online application, or mobile application for which interactions between users are limited to commercial transactions or to consumer reviews of products, sellers, services, events, or places, or any combination thereof. (B) An internet website, online service, online application, or mobile application that operates a feed for the primary purpose of cloud storage. (c) “Media” means text, audio, an image, or a video. (d) “Minor” means an individual under 18 years of age who is located in the State of California. (e) “Operator” means a person who operates or provides an internet website, an online service, an online application, or a mobile application. (f) “Parent” means a parent or guardian, including as defined in regulations promulgated pursuant to this chapter. (g) “User” means a person who uses an internet website, online service, online application, or mobile application. “User” does not include the operator or a person acting as an agent of the operator. 27001. (a) It shall be unlawful for the operator of an addictive internet-based service or application to provide an addictive feed to a user unless either of the following is met:(1) (A) Except as provided in subparagraph (B), the operator does not have actual knowledge that the user is a minor.(B) Commencing January 1, 2027, the operator has reasonably determined that the user is not a minor, including pursuant to regulations promulgated by the Attorney General.(2) The operator has obtained verifiable parental consent to provide an addictive feed to the user who is a minor.(b) Information collected for the purpose of determining a user’s age or verifying parental consent pursuant to this chapter shall not be used for any purpose other than compliance with this chapter or with another applicable law. The information collected shall be deleted immediately after it is used to determine a user’s age or to verify parental consent, except as necessary to comply with state or federal law. 27001. (a) It shall be unlawful for the operator of an addictive internet-based service or application to provide an addictive feed to a user unless either of the following is met: (1) (A) Except as provided in subparagraph (B), the operator does not have actual knowledge that the user is a minor. (B) Commencing January 1, 2027, the operator has reasonably determined that the user is not a minor, including pursuant to regulations promulgated by the Attorney General. (2) The operator has obtained verifiable parental consent to provide an addictive feed to the user who is a minor. (b) Information collected for the purpose of determining a user’s age or verifying parental consent pursuant to this chapter shall not be used for any purpose other than compliance with this chapter or with another applicable law. The information collected shall be deleted immediately after it is used to determine a user’s age or to verify parental consent, except as necessary to comply with state or federal law. 27002. (a) (1) Except as provided in paragraph (2), it shall be unlawful for the operator of an addictive internet-based service or application, between the hours of 12 a.m. and 6 a.m., in the user’s local time zone, and between the hours of 8 a.m. and 3 p.m., from Monday through Friday from September through May in the user’s local time zone, to send notifications to a user if the operator has actual knowledge that the user is a minor unless the operator has obtained verifiable parental consent to send those notifications.(2) Commencing January 1, 2027, it shall be unlawful for the operator of an addictive internet-based service or application, between the hours of 12 a.m. and 6 a.m., in the user’s local time zone, and between the hours of 8 a.m. and 3 p.m., from Monday through Friday from September through May in the user’s local time zone, to send notifications to a user whom the operator has not reasonably determined is not a minor, including pursuant to regulations promulgated by the Attorney General, unless the operator has obtained verifiable parental consent to send those notifications.(b) The operator of an addictive internet-based service or application shall provide a mechanism through which the verified parent of a user who is a minor may do any of the following:(1) Prevent their child from accessing or receiving notifications from the addictive internet-based service or application between specific hours chosen by the parent. This setting shall be set by the operator as on by default, in a manner in which the child’s access is limited between the hours of 12 a.m. and 6 a.m., in the user’s local time zone.(2) Limit their child’s access to any addictive feed from the addictive internet-based service or application to a length of time per day specified by the verified parent. This setting shall be set by the operator as on by default, in a manner in which the child’s access is limited to one hour per day unless modified by the verified parent.(3) Limit their child’s ability to view the number of likes or other forms of feedback to pieces of media within an addictive feed. This setting shall be set by the operator as on by default.(4) Require that the default feed provided to the child when entering the internet-based service or application be one in which pieces of media are not recommended, selected, or prioritized for display based on information provided by the user, or otherwise associated with the user or the user’s device, other than the user’s age or status as a minor.(5) Set their child’s account to private mode, in a manner in which only users to whom the child is connected on the addictive internet-based service or application may view or respond to content posted by the child. This setting shall be set by the operator as on by default. 27002. (a) (1) Except as provided in paragraph (2), it shall be unlawful for the operator of an addictive internet-based service or application, between the hours of 12 a.m. and 6 a.m., in the user’s local time zone, and between the hours of 8 a.m. and 3 p.m., from Monday through Friday from September through May in the user’s local time zone, to send notifications to a user if the operator has actual knowledge that the user is a minor unless the operator has obtained verifiable parental consent to send those notifications. (2) Commencing January 1, 2027, it shall be unlawful for the operator of an addictive internet-based service or application, between the hours of 12 a.m. and 6 a.m., in the user’s local time zone, and between the hours of 8 a.m. and 3 p.m., from Monday through Friday from September through May in the user’s local time zone, to send notifications to a user whom the operator has not reasonably determined is not a minor, including pursuant to regulations promulgated by the Attorney General, unless the operator has obtained verifiable parental consent to send those notifications. (b) The operator of an addictive internet-based service or application shall provide a mechanism through which the verified parent of a user who is a minor may do any of the following: (1) Prevent their child from accessing or receiving notifications from the addictive internet-based service or application between specific hours chosen by the parent. This setting shall be set by the operator as on by default, in a manner in which the child’s access is limited between the hours of 12 a.m. and 6 a.m., in the user’s local time zone. (2) Limit their child’s access to any addictive feed from the addictive internet-based service or application to a length of time per day specified by the verified parent. This setting shall be set by the operator as on by default, in a manner in which the child’s access is limited to one hour per day unless modified by the verified parent. (3) Limit their child’s ability to view the number of likes or other forms of feedback to pieces of media within an addictive feed. This setting shall be set by the operator as on by default. (4) Require that the default feed provided to the child when entering the internet-based service or application be one in which pieces of media are not recommended, selected, or prioritized for display based on information provided by the user, or otherwise associated with the user or the user’s device, other than the user’s age or status as a minor. (5) Set their child’s account to private mode, in a manner in which only users to whom the child is connected on the addictive internet-based service or application may view or respond to content posted by the child. This setting shall be set by the operator as on by default. 27003. (a) This chapter shall not be construed as requiring the operator of an addictive internet-based service or application to give a parent any additional or special access to, or control over, the data or accounts of their child.(b) This chapter shall not be construed as preventing any action taken in good faith to restrict access to, or availability of, media. 27003. (a) This chapter shall not be construed as requiring the operator of an addictive internet-based service or application to give a parent any additional or special access to, or control over, the data or accounts of their child. (b) This chapter shall not be construed as preventing any action taken in good faith to restrict access to, or availability of, media. 27004. (a) An operator may choose not to provide services to minors. However, the operator of an addictive internet-based service or application shall not withhold, degrade, lower the quality of, or increase the price of, any product, service, or feature, other than as required by this chapter, due to a user or parent availing themselves of the rights provided by this chapter, or due to the protections required by this chapter.(b) A parent’s provision of consent as described in Section 27001 or 27002, or the use by a parent of a mechanism as described in Section 27002, does not waive, release, otherwise limit, or serve as a defense to, any claim that the parent, or that the user who is a minor or was a minor at the time of using the internet-based service or application, might have against the operator of an addictive internet-based service or application regarding any harm to the mental health or well-being of the user.(c) The protections provided by this chapter are in addition to those provided by any other applicable law, including, but not limited to, the California Age-Appropriate Design Code Act (Title 1.81.47 (commencing with Section 1798.99.28) of Part 4 of Division 3 of the Civil Code). 27004. (a) An operator may choose not to provide services to minors. However, the operator of an addictive internet-based service or application shall not withhold, degrade, lower the quality of, or increase the price of, any product, service, or feature, other than as required by this chapter, due to a user or parent availing themselves of the rights provided by this chapter, or due to the protections required by this chapter. (b) A parent’s provision of consent as described in Section 27001 or 27002, or the use by a parent of a mechanism as described in Section 27002, does not waive, release, otherwise limit, or serve as a defense to, any claim that the parent, or that the user who is a minor or was a minor at the time of using the internet-based service or application, might have against the operator of an addictive internet-based service or application regarding any harm to the mental health or well-being of the user. (c) The protections provided by this chapter are in addition to those provided by any other applicable law, including, but not limited to, the California Age-Appropriate Design Code Act (Title 1.81.47 (commencing with Section 1798.99.28) of Part 4 of Division 3 of the Civil Code). 27005. An operator of an addictive internet-based service or application shall publicly disclose, on an annual basis, the number of minor users of its addictive internet-based service or application, and of that total the number for whom the operator has received verifiable parental consent to provide an addictive feed, and the number of minor users as to whom the controls set forth in Section 27002 are or are not enabled. 27005. An operator of an addictive internet-based service or application shall publicly disclose, on an annual basis, the number of minor users of its addictive internet-based service or application, and of that total the number for whom the operator has received verifiable parental consent to provide an addictive feed, and the number of minor users as to whom the controls set forth in Section 27002 are or are not enabled. 27006. (a) This chapter may only be enforced in a civil action brought in the name of the people of the State of California by the Attorney General.(b) The Attorney General shall adopt regulations to further the purposes of this chapter, including regulations regarding age assurance and parental consent by January 1, 2027. The Attorney General may adopt regulations that provide for exceptions to this chapter, but only if those exceptions further the purpose of protecting minors.(c) In promulgating the regulations described in subdivision (b), the Attorney General shall solicit public comment regarding the impact that any regulation might have based on the nondiscrimination characteristics set forth in Section 51 of the Civil Code or in any other applicable law. 27006. (a) This chapter may only be enforced in a civil action brought in the name of the people of the State of California by the Attorney General. (b) The Attorney General shall adopt regulations to further the purposes of this chapter, including regulations regarding age assurance and parental consent by January 1, 2027. The Attorney General may adopt regulations that provide for exceptions to this chapter, but only if those exceptions further the purpose of protecting minors. (c) In promulgating the regulations described in subdivision (b), the Attorney General shall solicit public comment regarding the impact that any regulation might have based on the nondiscrimination characteristics set forth in Section 51 of the Civil Code or in any other applicable law. 27007. If any provision of this chapter, or application thereof, to any person or circumstance is held invalid, that invalidity shall not affect other provisions or applications of this chapter that can be given effect without the invalid provision or application, and to this end the provisions of this chapter are declared to be severable. 27007. If any provision of this chapter, or application thereof, to any person or circumstance is held invalid, that invalidity shall not affect other provisions or applications of this chapter that can be given effect without the invalid provision or application, and to this end the provisions of this chapter are declared to be severable. "
        }
      ],
      "content_type": "legal_document",
      "word_count": 25699,
      "char_count": 161561
    },
    {
      "url": "https://www.flsenate.gov/Session/Bill/2024/3",
      "title": "House Bill 3 (2024) - The Florida Senate",
      "description": "",
      "keywords": "",
      "author": "",
      "published_date": "",
      "scraped_at": "2025-08-28T01:34:52.408887",
      "sections": [
        {
          "title": "Main Content",
          "content": "Skip to Navigation | Skip to Main Content | Skip to Site Map FLHouse.gov | Mobile Site Senate Tracker: Sign Up | Login Skip to Navigation | Skip to Main Content | Skip to Site Map FLHouse.gov | Mobile Site Senate Tracker: Sign Up | Login FLHouse.gov | Mobile Site Senate Tracker: Sign Up | Login Go to Bill: Year: 2026 2025 2025C 2025B 2025A 2024 Org. 2024 2023C 2023 2023B 2022A 2022 Org. 2022D 2022C 2022 2021B 2021A 2021 2020 Org. 2020 2019 I 2019 2018 Org. 2018 2017A 2017 2016 Org. 2016 2015C 2015B 2015A 2015 2014 Org. 2014A 2014 2013 2012 Org. 2012B 2012 2011 2010A 2010 Org. 2010C 2010 2009B 2009 2009A 2008 Org. 2008 2007D 2007C 2007B 2007 2007A 2006 Org. 2006 2005B 2005 2004A 2004 Org. 2004 2003E 2003D 2003C 2003B 2003A 2003 2002 Org. 2002E 2002D 2002 2001C 2001B 2001 2000A (Dec.) 2000 Org. 2000 2000A (Jan.) 1999 1998 Org 1998 Find Statutes: Year: 2024 2023 2022 2021 2020 2019 2018 2017 2016 2015 2014 2013 2012 2011 2010 2009 2008 2007 2006 2005 2004 2003 2002 2001 2000 1999 1998 1997 Within Chapter: Javascript must be enabled for site search. The Florida Senate Home Daily Digest Calendar Filed Today Bill Actions Spotlights August Back-To-School Sales Tax Holiday Year-Round Tax Savings for Hurricane Pre Senator Geraldine Thompson Interim Committee Meetings Senate Photo Gallery Florida Stands with Israel Senators Senator List Find Your Legislators District Maps Vote Disclosures Committees Committee List Committee Publications Session Bills Calendars Journals Appropriations Conferences Reports Executive Appointments Executive Suspensions Redistricting Laws Statutes Help Searching Statutes Constitution Laws of Florida Order - Legistore Media Video Broadcast Schedule Press Releases Publications Videos Topics About Employment Accessibility Visit Us Contact Us Page Program Offices President's Office Majority Office Minority Office Secretary's Office Reference Glossary FAQ Help Links Search Tips Publications Rules Handbooks Advisory Opinions Public Records Tracker Login Sign Up Tracker Help Home > Session > 2024 > House Bill 3 < Previous House Bill Next House Bill > Track This Bill View Bill Summary Glossary of Legislative Terms CS/CS/HB 3: Online Protections for Minors GENERAL BILL by Judiciary Committee ; Regulatory Reform & Economic Development Subcommittee ; Tramont ; Overdorf ; Sirois ; McFarland ; Rayner ; (CO-INTRODUCERS) Anderson ; Bankson ; Barnaby ; Beltran ; Black ; Botana ; Brackett ; Buchanan ; Canady ; Caruso ; Chamberlin ; Chambliss ; Chaney ; Fabricio ; Garcia ; Gonzalez Pittman ; Gossett-Seidman ; Gregory ; Jacques ; Leek ; Lopez, V. ; Massullo ; McClain ; Melo ; Michael ; Mooney ; Payne ; Persons-Mulicka ; Plakon ; Plasencia ; Roth ; Salzman ; Snyder ; Steele ; Temple ; Trabulsy ; Truenow ; Tuck ; Waldron ; Yarkosky ; Yeager Online Protections for Minors; Requiring social media platforms to prohibit certain minors from creating new accounts; requiring social media platforms to terminate certain accounts and provide additional options for termination of such accounts; providing conditions under which social media platforms are required to prohibit certain minors from entering into contracts to become account holders; authorizing the Department of Legal Affairs to bring actions under the Florida Deceptive and Unfair Trade Practices Act for knowing or reckless violations; authorizing the department to issue and enforce civil investigative demands under certain circumstances, etc. Effective Date: 1/1/2025 Last Action: 3/25/2024 - Chapter No. 2024-42; companion bill(s) passed, see CS/CS/HB 1491 (Ch. 2024-54) Bill Text: PDF Senate Committee References: Fiscal Policy (FP) View By Bill Version View By Category Bill History Related Bills (6) Bill Text (5) Amendments (4) Analyses (3) Vote History (3) Citations (3) Bill History Date Chamber Action 1/5/2024 House • Filed 1/9/2024 House • Referred to Regulatory Reform & Economic Development Subcommittee • Referred to Judiciary Committee • Now in Regulatory Reform & Economic Development Subcommittee • Added to Regulatory Reform & Economic Development Subcommittee agenda • 1st Reading (Original Filed Version) 1/11/2024 House • Favorable with CS by Regulatory Reform & Economic Development Subcommittee • Reported out of Regulatory Reform & Economic Development Subcommittee • Laid on Table under Rule 7.18(a) • CS Filed • 1st Reading (Committee Substitute 1) 1/12/2024 House • Referred to Judiciary Committee • Now in Judiciary Committee • Added to Judiciary Committee agenda 1/17/2024 House • Favorable with CS by Judiciary Committee • Reported out of Judiciary Committee 1/18/2024 House • Laid on Table under Rule 7.18(a) • CS Filed • Bill referred to House Calendar • Bill added to Special Order Calendar (1/23/2024) • 1st Reading (Committee Substitute 2) 1/23/2024 House • Read 2nd time • Placed on 3rd reading • Added to Third Reading Calendar 1/24/2024 House • Read 3rd time • CS passed; YEAS 119, NAYS 0 1/24/2024 Senate • In Messages 1/25/2024 Senate • Referred to Fiscal Policy • Received 2/12/2024 Senate • On Committee agenda-- Fiscal Policy, 02/15/24, 12:00 pm, 412 Knott Building --Temporarily Postponed 2/15/2024 Senate • Placed on Special Order Calendar, 02/21/24 --If Received 3/1/2024 Senate • Withdrawn from Fiscal Policy -SJ 575 • Placed on Calendar, on 2nd reading • Placed on Special Order Calendar, 03/04/24 -SJ 575 3/4/2024 Senate • Read 2nd time -SJ 622 • Amendment(s) adopted (961382) -SJ 622 • Read 3rd time -SJ 625 • CS passed as amended; YEAS 30 NAYS 5 -SJ 625 3/4/2024 House • In Messages 3/6/2024 House • Added to Senate Message List • Amendment 961382 Concur • CS passed as amended; YEAS 109, NAYS 4 • Ordered engrossed, then enrolled 3/21/2024 • Signed by Officers and presented to Governor 3/25/2024 • Approved by Governor • Chapter No. 2024-42; companion bill(s) passed, see CS/CS/HB 1491 (Ch. 2024-54) Related Bills Bill Number Subject Filed By Relationship Last Action and Location Track Bills H 1491 (er) Pub. Rec./Investigations by the Department of Legal Affairs Regulatory Reform & Economic Development Subcommittee Linked Last Action: 4/3/2024 Chapter No. 2024-54; companion bill(s) passed, see CS/CS/HB 3 (Ch. 2024-42) H 1 (er) Online Protections for Minors Judiciary Committee Similar Last Action: 3/1/2024 Vetoed by Governor; companion bill(s) passed, see CS/CS/HB 3 (Ch. 2024-42); companion bill(s) passed, see CS/CS/HB 1491 (Ch. 2024-2024-54) H 1377 (er) Pub. Rec./Investigations by the Department of Legal Affairs State Affairs Committee Compare Last Action: 3/1/2024 Vetoed by Governor; companion bill(s) passed, see CS/CS/HB 1491 (Ch. 2024-54), CS/CS/HB 3 (Ch. 2024-42) S 454 Protection of Minors on Social Media Platforms Garcia Compare Last Action: 3/8/2024 S Died in Commerce and Tourism, companion bill(s) passed, see CS/CS/HB 3 (Ch. 2024-42) S 1788 (c1) Social Media Use for Minors Grall Compare Last Action: 3/8/2024 S Died in Fiscal Policy, companion bill(s) passed, see CS/CS/HB 3 (Ch. 2024-42) S 1792 (c1) Online Access to Materials Harmful to Minors Grall Compare Last Action: 3/8/2024 S Died in Fiscal Policy, companion bill(s) passed, see CS/CS/HB 3 (Ch. 2024-42) Bill Text Version Posted Format H 3 Filed 1/5/2024 6:48 PM PDF H 3 c1 1/11/2024 4:55 PM PDF H 3 c2 1/18/2024 8:48 AM PDF H 3 e1 3/7/2024 10:00 AM PDF H 3 er 3/7/2024 10:14 AM PDF Committee Amendments H 3 Filed Amendment Sponsor Filed Last Committee Action Format 427693 - Amendment Remove lines 34-54 and insert: Tramont 1/10/2024 5:29 PM Adopted without Objection 1/11/2024 PDF H 3 c1 Amendment Sponsor Filed Last Committee Action Format 901561 - Amendment Remove line 72 and insert: Tramont 1/16/2024 3:20 PM Adopted 1/17/2024 PDF H 3 c2 Amendment Sponsor Filed Last Committee Action Format 493094 - Amendment (Delete All) Delete everything after the enacting clause and insert: Fiscal Policy (Hutson) 2/14/2024 12:00 PM Web Page PDF Floor Amendments H 3 c2 Amendments Sponsor Filed Last Floor Action Format 961382 - Amendment (Delete All) Delete everything after the enacting clause and insert: Grall 3/1/2024 3:18 PM House: Concur 3/6/2024 Web Page PDF Bill Analyses Type Analysis Author Posted Format Bill Analysis H 3 Fiscal Policy (Pre-Meeting) 2/13/2024 4:48 PM PDF Bill Analysis H 3 Regulatory Reform & Economic Development Subcommittee (Post-Meeting) 3/28/2024 3:10 PM PDF Bill Analysis H 3 Judiciary Committee (Post-Meeting) 1/17/2024 5:59 PM PDF Vote History - Committee No Committee Vote History Available Vote History - Floor Vote Date Chamber Result H 3 c2 1/24/2024 5:03 PM House 119 Yeas - 0 Nays H 3 c2 3/4/2024 10:28 AM Senate 30 Yeas - 5 Nays H 3 c2 3/6/2024 6:16 PM House 109 Yeas - 4 Nays Citations - Statutes (3) Citation Catchline Location in Bill Location In Bill Help 501.1736 Page 3 (pdf) 501.1737 Page 12 (pdf) 501.1738 Page 19 (pdf) Citations - Constitution (0) No Constitutional citations. Citations - Chapter Law (0) No Chapter Law citations. Identical bill Companion bills that are identical word-for-word, not including titles. However, Resolutions and Concurrent Resolutions are considered identical if the only difference is the word \"House\" or \"Senate.\" Similar bill Companion bills that are substantially similar in text or have substantial portions of text that are largely the same. Compare bill Bills that have selected provisions that are similar in text. Linked bill A bill that is contingent upon passage of another bill within the same chamber, e.g., a trust fund bill, a bill providing a public record exemption, or an implementing bill. The page numbers, when listed, for citations are constantly under review. The journals or printed bills of the respective chambers should be consulted as the official documents of the Legislature. The links for the page numbers are formatted to open the bill text PDF directly to the page containing the citation. However, if your browser is set to open PDFs in a new window, as is often the case with 64-bit browsers, the bill text will open to the first page. Home Senators Senator List Find Your Legislators District Maps Vote Disclosures Committees Committee List Committee Publications Search Bill Search Tips Statute Search Tips Site Search Tips Session Bills Calendars Journals Appropriations Conferences Reports Executive Appointments Executive Suspensions Redistricting Laws Statutes Constitution Laws of Florida Order - Legistore Media Press Releases Publications Videos Topics Video Broadcast Schedule About Employment Visit Us Contact Us Page Program Offices President's Office Majority Office Minority Office Secretary's Office Reference Glossary FAQ Help Links Search Tips Publications Rules Handbooks Advisory Opinions Public Records Connect with the Senate Twitter RSS Senate Tracker Login Sign Up Tracker Help Plug-ins Adobe Acrobat Reader WinZip Disclaimer: The information on this system is unverified. The journals or printed bills of the respective chambers should be consulted for official purposes. Privacy Statement|Accessibility Copyright  2000- 2025 State of Florida. Go to Bill: Year: 2026 2025 2025C 2025B 2025A 2024 Org. 2024 2023C 2023 2023B 2022A 2022 Org. 2022D 2022C 2022 2021B 2021A 2021 2020 Org. 2020 2019 I 2019 2018 Org. 2018 2017A 2017 2016 Org. 2016 2015C 2015B 2015A 2015 2014 Org. 2014A 2014 2013 2012 Org. 2012B 2012 2011 2010A 2010 Org. 2010C 2010 2009B 2009 2009A 2008 Org. 2008 2007D 2007C 2007B 2007 2007A 2006 Org. 2006 2005B 2005 2004A 2004 Org. 2004 2003E 2003D 2003C 2003B 2003A 2003 2002 Org. 2002E 2002D 2002 2001C 2001B 2001 2000A (Dec.) 2000 Org. 2000 2000A (Jan.) 1999 1998 Org 1998 Find Statutes: Year: 2024 2023 2022 2021 2020 2019 2018 2017 2016 2015 2014 2013 2012 2011 2010 2009 2008 2007 2006 2005 2004 2003 2002 2001 2000 1999 1998 1997 Within Chapter: Javascript must be enabled for site search. The Florida Senate Home Daily Digest Calendar Filed Today Bill Actions Spotlights August Back-To-School Sales Tax Holiday Year-Round Tax Savings for Hurricane Pre Senator Geraldine Thompson Interim Committee Meetings Senate Photo Gallery Florida Stands with Israel Senators Senator List Find Your Legislators District Maps Vote Disclosures Committees Committee List Committee Publications Session Bills Calendars Journals Appropriations Conferences Reports Executive Appointments Executive Suspensions Redistricting Laws Statutes Help Searching Statutes Constitution Laws of Florida Order - Legistore Media Video Broadcast Schedule Press Releases Publications Videos Topics About Employment Accessibility Visit Us Contact Us Page Program Offices President's Office Majority Office Minority Office Secretary's Office Reference Glossary FAQ Help Links Search Tips Publications Rules Handbooks Advisory Opinions Public Records Tracker Login Sign Up Tracker Help Home > Session > 2024 > House Bill 3 < Previous House Bill Next House Bill > Track This Bill View Bill Summary Glossary of Legislative Terms CS/CS/HB 3: Online Protections for Minors GENERAL BILL by Judiciary Committee ; Regulatory Reform & Economic Development Subcommittee ; Tramont ; Overdorf ; Sirois ; McFarland ; Rayner ; (CO-INTRODUCERS) Anderson ; Bankson ; Barnaby ; Beltran ; Black ; Botana ; Brackett ; Buchanan ; Canady ; Caruso ; Chamberlin ; Chambliss ; Chaney ; Fabricio ; Garcia ; Gonzalez Pittman ; Gossett-Seidman ; Gregory ; Jacques ; Leek ; Lopez, V. ; Massullo ; McClain ; Melo ; Michael ; Mooney ; Payne ; Persons-Mulicka ; Plakon ; Plasencia ; Roth ; Salzman ; Snyder ; Steele ; Temple ; Trabulsy ; Truenow ; Tuck ; Waldron ; Yarkosky ; Yeager Online Protections for Minors; Requiring social media platforms to prohibit certain minors from creating new accounts; requiring social media platforms to terminate certain accounts and provide additional options for termination of such accounts; providing conditions under which social media platforms are required to prohibit certain minors from entering into contracts to become account holders; authorizing the Department of Legal Affairs to bring actions under the Florida Deceptive and Unfair Trade Practices Act for knowing or reckless violations; authorizing the department to issue and enforce civil investigative demands under certain circumstances, etc. Effective Date: 1/1/2025 Last Action: 3/25/2024 - Chapter No. 2024-42; companion bill(s) passed, see CS/CS/HB 1491 (Ch. 2024-54) Bill Text: PDF Senate Committee References: Fiscal Policy (FP) View By Bill Version View By Category Bill History Related Bills (6) Bill Text (5) Amendments (4) Analyses (3) Vote History (3) Citations (3) Bill History Date Chamber Action 1/5/2024 House • Filed 1/9/2024 House • Referred to Regulatory Reform & Economic Development Subcommittee • Referred to Judiciary Committee • Now in Regulatory Reform & Economic Development Subcommittee • Added to Regulatory Reform & Economic Development Subcommittee agenda • 1st Reading (Original Filed Version) 1/11/2024 House • Favorable with CS by Regulatory Reform & Economic Development Subcommittee • Reported out of Regulatory Reform & Economic Development Subcommittee • Laid on Table under Rule 7.18(a) • CS Filed • 1st Reading (Committee Substitute 1) 1/12/2024 House • Referred to Judiciary Committee • Now in Judiciary Committee • Added to Judiciary Committee agenda 1/17/2024 House • Favorable with CS by Judiciary Committee • Reported out of Judiciary Committee 1/18/2024 House • Laid on Table under Rule 7.18(a) • CS Filed • Bill referred to House Calendar • Bill added to Special Order Calendar (1/23/2024) • 1st Reading (Committee Substitute 2) 1/23/2024 House • Read 2nd time • Placed on 3rd reading • Added to Third Reading Calendar 1/24/2024 House • Read 3rd time • CS passed; YEAS 119, NAYS 0 1/24/2024 Senate • In Messages 1/25/2024 Senate • Referred to Fiscal Policy • Received 2/12/2024 Senate • On Committee agenda-- Fiscal Policy, 02/15/24, 12:00 pm, 412 Knott Building --Temporarily Postponed 2/15/2024 Senate • Placed on Special Order Calendar, 02/21/24 --If Received 3/1/2024 Senate • Withdrawn from Fiscal Policy -SJ 575 • Placed on Calendar, on 2nd reading • Placed on Special Order Calendar, 03/04/24 -SJ 575 3/4/2024 Senate • Read 2nd time -SJ 622 • Amendment(s) adopted (961382) -SJ 622 • Read 3rd time -SJ 625 • CS passed as amended; YEAS 30 NAYS 5 -SJ 625 3/4/2024 House • In Messages 3/6/2024 House • Added to Senate Message List • Amendment 961382 Concur • CS passed as amended; YEAS 109, NAYS 4 • Ordered engrossed, then enrolled 3/21/2024 • Signed by Officers and presented to Governor 3/25/2024 • Approved by Governor • Chapter No. 2024-42; companion bill(s) passed, see CS/CS/HB 1491 (Ch. 2024-54) Related Bills Bill Number Subject Filed By Relationship Last Action and Location Track Bills H 1491 (er) Pub. Rec./Investigations by the Department of Legal Affairs Regulatory Reform & Economic Development Subcommittee Linked Last Action: 4/3/2024 Chapter No. 2024-54; companion bill(s) passed, see CS/CS/HB 3 (Ch. 2024-42) H 1 (er) Online Protections for Minors Judiciary Committee Similar Last Action: 3/1/2024 Vetoed by Governor; companion bill(s) passed, see CS/CS/HB 3 (Ch. 2024-42); companion bill(s) passed, see CS/CS/HB 1491 (Ch. 2024-2024-54) H 1377 (er) Pub. Rec./Investigations by the Department of Legal Affairs State Affairs Committee Compare Last Action: 3/1/2024 Vetoed by Governor; companion bill(s) passed, see CS/CS/HB 1491 (Ch. 2024-54), CS/CS/HB 3 (Ch. 2024-42) S 454 Protection of Minors on Social Media Platforms Garcia Compare Last Action: 3/8/2024 S Died in Commerce and Tourism, companion bill(s) passed, see CS/CS/HB 3 (Ch. 2024-42) S 1788 (c1) Social Media Use for Minors Grall Compare Last Action: 3/8/2024 S Died in Fiscal Policy, companion bill(s) passed, see CS/CS/HB 3 (Ch. 2024-42) S 1792 (c1) Online Access to Materials Harmful to Minors Grall Compare Last Action: 3/8/2024 S Died in Fiscal Policy, companion bill(s) passed, see CS/CS/HB 3 (Ch. 2024-42) Bill Text Version Posted Format H 3 Filed 1/5/2024 6:48 PM PDF H 3 c1 1/11/2024 4:55 PM PDF H 3 c2 1/18/2024 8:48 AM PDF H 3 e1 3/7/2024 10:00 AM PDF H 3 er 3/7/2024 10:14 AM PDF Committee Amendments H 3 Filed Amendment Sponsor Filed Last Committee Action Format 427693 - Amendment Remove lines 34-54 and insert: Tramont 1/10/2024 5:29 PM Adopted without Objection 1/11/2024 PDF H 3 c1 Amendment Sponsor Filed Last Committee Action Format 901561 - Amendment Remove line 72 and insert: Tramont 1/16/2024 3:20 PM Adopted 1/17/2024 PDF H 3 c2 Amendment Sponsor Filed Last Committee Action Format 493094 - Amendment (Delete All) Delete everything after the enacting clause and insert: Fiscal Policy (Hutson) 2/14/2024 12:00 PM Web Page PDF Floor Amendments H 3 c2 Amendments Sponsor Filed Last Floor Action Format 961382 - Amendment (Delete All) Delete everything after the enacting clause and insert: Grall 3/1/2024 3:18 PM House: Concur 3/6/2024 Web Page PDF Bill Analyses Type Analysis Author Posted Format Bill Analysis H 3 Fiscal Policy (Pre-Meeting) 2/13/2024 4:48 PM PDF Bill Analysis H 3 Regulatory Reform & Economic Development Subcommittee (Post-Meeting) 3/28/2024 3:10 PM PDF Bill Analysis H 3 Judiciary Committee (Post-Meeting) 1/17/2024 5:59 PM PDF Vote History - Committee No Committee Vote History Available Vote History - Floor Vote Date Chamber Result H 3 c2 1/24/2024 5:03 PM House 119 Yeas - 0 Nays H 3 c2 3/4/2024 10:28 AM Senate 30 Yeas - 5 Nays H 3 c2 3/6/2024 6:16 PM House 109 Yeas - 4 Nays Citations - Statutes (3) Citation Catchline Location in Bill Location In Bill Help 501.1736 Page 3 (pdf) 501.1737 Page 12 (pdf) 501.1738 Page 19 (pdf) Citations - Constitution (0) No Constitutional citations. Citations - Chapter Law (0) No Chapter Law citations. Identical bill Companion bills that are identical word-for-word, not including titles. However, Resolutions and Concurrent Resolutions are considered identical if the only difference is the word \"House\" or \"Senate.\" Similar bill Companion bills that are substantially similar in text or have substantial portions of text that are largely the same. Compare bill Bills that have selected provisions that are similar in text. Linked bill A bill that is contingent upon passage of another bill within the same chamber, e.g., a trust fund bill, a bill providing a public record exemption, or an implementing bill. The page numbers, when listed, for citations are constantly under review. The journals or printed bills of the respective chambers should be consulted as the official documents of the Legislature. The links for the page numbers are formatted to open the bill text PDF directly to the page containing the citation. However, if your browser is set to open PDFs in a new window, as is often the case with 64-bit browsers, the bill text will open to the first page. Home Senators Senator List Find Your Legislators District Maps Vote Disclosures Committees Committee List Committee Publications Search Bill Search Tips Statute Search Tips Site Search Tips Session Bills Calendars Journals Appropriations Conferences Reports Executive Appointments Executive Suspensions Redistricting Laws Statutes Constitution Laws of Florida Order - Legistore Media Press Releases Publications Videos Topics Video Broadcast Schedule About Employment Visit Us Contact Us Page Program Offices President's Office Majority Office Minority Office Secretary's Office Reference Glossary FAQ Help Links Search Tips Publications Rules Handbooks Advisory Opinions Public Records Connect with the Senate Twitter RSS Senate Tracker Login Sign Up Tracker Help Plug-ins Adobe Acrobat Reader WinZip Disclaimer: The information on this system is unverified. The journals or printed bills of the respective chambers should be consulted for official purposes. Privacy Statement|Accessibility Copyright  2000- 2025 State of Florida. Go to Bill: Year: 2026 2025 2025C 2025B 2025A 2024 Org. 2024 2023C 2023 2023B 2022A 2022 Org. 2022D 2022C 2022 2021B 2021A 2021 2020 Org. 2020 2019 I 2019 2018 Org. 2018 2017A 2017 2016 Org. 2016 2015C 2015B 2015A 2015 2014 Org. 2014A 2014 2013 2012 Org. 2012B 2012 2011 2010A 2010 Org. 2010C 2010 2009B 2009 2009A 2008 Org. 2008 2007D 2007C 2007B 2007 2007A 2006 Org. 2006 2005B 2005 2004A 2004 Org. 2004 2003E 2003D 2003C 2003B 2003A 2003 2002 Org. 2002E 2002D 2002 2001C 2001B 2001 2000A (Dec.) 2000 Org. 2000 2000A (Jan.) 1999 1998 Org 1998 Find Statutes: Year: 2024 2023 2022 2021 2020 2019 2018 2017 2016 2015 2014 2013 2012 2011 2010 2009 2008 2007 2006 2005 2004 2003 2002 2001 2000 1999 1998 1997 Within Chapter: Javascript must be enabled for site search. The Florida Senate Home Daily Digest Calendar Filed Today Bill Actions Spotlights August Back-To-School Sales Tax Holiday Year-Round Tax Savings for Hurricane Pre Senator Geraldine Thompson Interim Committee Meetings Senate Photo Gallery Florida Stands with Israel Senators Senator List Find Your Legislators District Maps Vote Disclosures Committees Committee List Committee Publications Session Bills Calendars Journals Appropriations Conferences Reports Executive Appointments Executive Suspensions Redistricting Laws Statutes Help Searching Statutes Constitution Laws of Florida Order - Legistore Media Video Broadcast Schedule Press Releases Publications Videos Topics About Employment Accessibility Visit Us Contact Us Page Program Offices President's Office Majority Office Minority Office Secretary's Office Reference Glossary FAQ Help Links Search Tips Publications Rules Handbooks Advisory Opinions Public Records Tracker Login Sign Up Tracker Help Go to Bill: Year: 2026 2025 2025C 2025B 2025A 2024 Org. 2024 2023C 2023 2023B 2022A 2022 Org. 2022D 2022C 2022 2021B 2021A 2021 2020 Org. 2020 2019 I 2019 2018 Org. 2018 2017A 2017 2016 Org. 2016 2015C 2015B 2015A 2015 2014 Org. 2014A 2014 2013 2012 Org. 2012B 2012 2011 2010A 2010 Org. 2010C 2010 2009B 2009 2009A 2008 Org. 2008 2007D 2007C 2007B 2007 2007A 2006 Org. 2006 2005B 2005 2004A 2004 Org. 2004 2003E 2003D 2003C 2003B 2003A 2003 2002 Org. 2002E 2002D 2002 2001C 2001B 2001 2000A (Dec.) 2000 Org. 2000 2000A (Jan.) 1999 1998 Org 1998 Find Statutes: Year: 2024 2023 2022 2021 2020 2019 2018 2017 2016 2015 2014 2013 2012 2011 2010 2009 2008 2007 2006 2005 2004 2003 2002 2001 2000 1999 1998 1997 Within Chapter: Go to Bill: Year: 2026 2025 2025C 2025B 2025A 2024 Org. 2024 2023C 2023 2023B 2022A 2022 Org. 2022D 2022C 2022 2021B 2021A 2021 2020 Org. 2020 2019 I 2019 2018 Org. 2018 2017A 2017 2016 Org. 2016 2015C 2015B 2015A 2015 2014 Org. 2014A 2014 2013 2012 Org. 2012B 2012 2011 2010A 2010 Org. 2010C 2010 2009B 2009 2009A 2008 Org. 2008 2007D 2007C 2007B 2007 2007A 2006 Org. 2006 2005B 2005 2004A 2004 Org. 2004 2003E 2003D 2003C 2003B 2003A 2003 2002 Org. 2002E 2002D 2002 2001C 2001B 2001 2000A (Dec.) 2000 Org. 2000 2000A (Jan.) 1999 1998 Org 1998 Find Statutes: Year: 2024 2023 2022 2021 2020 2019 2018 2017 2016 2015 2014 2013 2012 2011 2010 2009 2008 2007 2006 2005 2004 2003 2002 2001 2000 1999 1998 1997 Within Chapter: Javascript must be enabled for site search. "
        },
        {
          "title": "The Florida Senate",
          "content": "Daily Digest Calendar Filed Today Bill Actions Spotlights August Back-To-School Sales Tax Holiday Year-Round Tax Savings for Hurricane Pre Senator Geraldine Thompson Interim Committee Meetings Senate Photo Gallery Florida Stands with Israel Daily Digest "
        },
        {
          "title": "Daily Digest",
          "content": "Filed Today Bill Actions Filed Today Bill Actions Spotlights August Back-To-School Sales Tax Holiday Year-Round Tax Savings for Hurricane Pre Senator Geraldine Thompson Interim Committee Meetings Senate Photo Gallery Florida Stands with Israel "
        },
        {
          "title": "Spotlights",
          "content": "Senator List Find Your Legislators District Maps Vote Disclosures Senator List Find Your Legislators District Maps Vote Disclosures Senator List Find Your Legislators District Maps Vote Disclosures Committee List Committee Publications Committee List Committee Publications Committee List Committee Publications Bills Calendars Journals Appropriations Conferences Reports Executive Appointments Executive Suspensions Redistricting Bills Calendars Journals Appropriations Conferences Reports Appropriations Conferences Executive Appointments Executive Suspensions Redistricting Executive Appointments Executive Suspensions Redistricting Statutes Help Searching Statutes Constitution Laws of Florida Order - Legistore Statutes Help Searching Statutes Constitution Help Searching Statutes Constitution Laws of Florida Order - Legistore Laws of Florida Order - Legistore Video Broadcast Schedule Press Releases Publications Videos Topics Video Broadcast Schedule Press Releases Publications Video Broadcast Schedule Press Releases Publications Videos Topics Employment Accessibility Visit Us Contact Us Page Program Employment Accessibility Accessibility Visit Us Contact Us Page Program Page Program President's Office Majority Office Minority Office Secretary's Office President's Office Majority Office President's Office Majority Office Minority Office Secretary's Office Minority Office Secretary's Office Glossary FAQ Help Links Search Tips Publications Rules Handbooks Advisory Opinions Public Records Glossary FAQ Help Links Search Tips Search Tips Publications Rules Handbooks Advisory Opinions Public Records Publications Advisory Opinions Public Records Login Sign Up Tracker Help Login Sign Up Tracker Help Tracker Help Home > Session > 2024 > House Bill 3 < Previous House Bill Next House Bill > Track This Bill View Bill Summary Glossary of Legislative Terms CS/CS/HB 3: Online Protections for Minors GENERAL BILL by Judiciary Committee ; Regulatory Reform & Economic Development Subcommittee ; Tramont ; Overdorf ; Sirois ; McFarland ; Rayner ; (CO-INTRODUCERS) Anderson ; Bankson ; Barnaby ; Beltran ; Black ; Botana ; Brackett ; Buchanan ; Canady ; Caruso ; Chamberlin ; Chambliss ; Chaney ; Fabricio ; Garcia ; Gonzalez Pittman ; Gossett-Seidman ; Gregory ; Jacques ; Leek ; Lopez, V. ; Massullo ; McClain ; Melo ; Michael ; Mooney ; Payne ; Persons-Mulicka ; Plakon ; Plasencia ; Roth ; Salzman ; Snyder ; Steele ; Temple ; Trabulsy ; Truenow ; Tuck ; Waldron ; Yarkosky ; Yeager Online Protections for Minors; Requiring social media platforms to prohibit certain minors from creating new accounts; requiring social media platforms to terminate certain accounts and provide additional options for termination of such accounts; providing conditions under which social media platforms are required to prohibit certain minors from entering into contracts to become account holders; authorizing the Department of Legal Affairs to bring actions under the Florida Deceptive and Unfair Trade Practices Act for knowing or reckless violations; authorizing the department to issue and enforce civil investigative demands under certain circumstances, etc. Effective Date: 1/1/2025 Last Action: 3/25/2024 - Chapter No. 2024-42; companion bill(s) passed, see CS/CS/HB 1491 (Ch. 2024-54) Bill Text: PDF Senate Committee References: Fiscal Policy (FP) View By Bill Version View By Category Bill History Related Bills (6) Bill Text (5) Amendments (4) Analyses (3) Vote History (3) Citations (3) Bill History Date Chamber Action 1/5/2024 House • Filed 1/9/2024 House • Referred to Regulatory Reform & Economic Development Subcommittee • Referred to Judiciary Committee • Now in Regulatory Reform & Economic Development Subcommittee • Added to Regulatory Reform & Economic Development Subcommittee agenda • 1st Reading (Original Filed Version) 1/11/2024 House • Favorable with CS by Regulatory Reform & Economic Development Subcommittee • Reported out of Regulatory Reform & Economic Development Subcommittee • Laid on Table under Rule 7.18(a) • CS Filed • 1st Reading (Committee Substitute 1) 1/12/2024 House • Referred to Judiciary Committee • Now in Judiciary Committee • Added to Judiciary Committee agenda 1/17/2024 House • Favorable with CS by Judiciary Committee • Reported out of Judiciary Committee 1/18/2024 House • Laid on Table under Rule 7.18(a) • CS Filed • Bill referred to House Calendar • Bill added to Special Order Calendar (1/23/2024) • 1st Reading (Committee Substitute 2) 1/23/2024 House • Read 2nd time • Placed on 3rd reading • Added to Third Reading Calendar 1/24/2024 House • Read 3rd time • CS passed; YEAS 119, NAYS 0 1/24/2024 Senate • In Messages 1/25/2024 Senate • Referred to Fiscal Policy • Received 2/12/2024 Senate • On Committee agenda-- Fiscal Policy, 02/15/24, 12:00 pm, 412 Knott Building --Temporarily Postponed 2/15/2024 Senate • Placed on Special Order Calendar, 02/21/24 --If Received 3/1/2024 Senate • Withdrawn from Fiscal Policy -SJ 575 • Placed on Calendar, on 2nd reading • Placed on Special Order Calendar, 03/04/24 -SJ 575 3/4/2024 Senate • Read 2nd time -SJ 622 • Amendment(s) adopted (961382) -SJ 622 • Read 3rd time -SJ 625 • CS passed as amended; YEAS 30 NAYS 5 -SJ 625 3/4/2024 House • In Messages 3/6/2024 House • Added to Senate Message List • Amendment 961382 Concur • CS passed as amended; YEAS 109, NAYS 4 • Ordered engrossed, then enrolled 3/21/2024 • Signed by Officers and presented to Governor 3/25/2024 • Approved by Governor • Chapter No. 2024-42; companion bill(s) passed, see CS/CS/HB 1491 (Ch. 2024-54) Related Bills Bill Number Subject Filed By Relationship Last Action and Location Track Bills H 1491 (er) Pub. Rec./Investigations by the Department of Legal Affairs Regulatory Reform & Economic Development Subcommittee Linked Last Action: 4/3/2024 Chapter No. 2024-54; companion bill(s) passed, see CS/CS/HB 3 (Ch. 2024-42) H 1 (er) Online Protections for Minors Judiciary Committee Similar Last Action: 3/1/2024 Vetoed by Governor; companion bill(s) passed, see CS/CS/HB 3 (Ch. 2024-42); companion bill(s) passed, see CS/CS/HB 1491 (Ch. 2024-2024-54) H 1377 (er) Pub. Rec./Investigations by the Department of Legal Affairs State Affairs Committee Compare Last Action: 3/1/2024 Vetoed by Governor; companion bill(s) passed, see CS/CS/HB 1491 (Ch. 2024-54), CS/CS/HB 3 (Ch. 2024-42) S 454 Protection of Minors on Social Media Platforms Garcia Compare Last Action: 3/8/2024 S Died in Commerce and Tourism, companion bill(s) passed, see CS/CS/HB 3 (Ch. 2024-42) S 1788 (c1) Social Media Use for Minors Grall Compare Last Action: 3/8/2024 S Died in Fiscal Policy, companion bill(s) passed, see CS/CS/HB 3 (Ch. 2024-42) S 1792 (c1) Online Access to Materials Harmful to Minors Grall Compare Last Action: 3/8/2024 S Died in Fiscal Policy, companion bill(s) passed, see CS/CS/HB 3 (Ch. 2024-42) Bill Text Version Posted Format H 3 Filed 1/5/2024 6:48 PM PDF H 3 c1 1/11/2024 4:55 PM PDF H 3 c2 1/18/2024 8:48 AM PDF H 3 e1 3/7/2024 10:00 AM PDF H 3 er 3/7/2024 10:14 AM PDF Committee Amendments H 3 Filed Amendment Sponsor Filed Last Committee Action Format 427693 - Amendment Remove lines 34-54 and insert: Tramont 1/10/2024 5:29 PM Adopted without Objection 1/11/2024 PDF H 3 c1 Amendment Sponsor Filed Last Committee Action Format 901561 - Amendment Remove line 72 and insert: Tramont 1/16/2024 3:20 PM Adopted 1/17/2024 PDF H 3 c2 Amendment Sponsor Filed Last Committee Action Format 493094 - Amendment (Delete All) Delete everything after the enacting clause and insert: Fiscal Policy (Hutson) 2/14/2024 12:00 PM Web Page PDF Floor Amendments H 3 c2 Amendments Sponsor Filed Last Floor Action Format 961382 - Amendment (Delete All) Delete everything after the enacting clause and insert: Grall 3/1/2024 3:18 PM House: Concur 3/6/2024 Web Page PDF Bill Analyses Type Analysis Author Posted Format Bill Analysis H 3 Fiscal Policy (Pre-Meeting) 2/13/2024 4:48 PM PDF Bill Analysis H 3 Regulatory Reform & Economic Development Subcommittee (Post-Meeting) 3/28/2024 3:10 PM PDF Bill Analysis H 3 Judiciary Committee (Post-Meeting) 1/17/2024 5:59 PM PDF Vote History - Committee No Committee Vote History Available Vote History - Floor Vote Date Chamber Result H 3 c2 1/24/2024 5:03 PM House 119 Yeas - 0 Nays H 3 c2 3/4/2024 10:28 AM Senate 30 Yeas - 5 Nays H 3 c2 3/6/2024 6:16 PM House 109 Yeas - 4 Nays Citations - Statutes (3) Citation Catchline Location in Bill Location In Bill Help 501.1736 Page 3 (pdf) 501.1737 Page 12 (pdf) 501.1738 Page 19 (pdf) Citations - Constitution (0) No Constitutional citations. Citations - Chapter Law (0) No Chapter Law citations. Identical bill Companion bills that are identical word-for-word, not including titles. However, Resolutions and Concurrent Resolutions are considered identical if the only difference is the word \"House\" or \"Senate.\" Similar bill Companion bills that are substantially similar in text or have substantial portions of text that are largely the same. Compare bill Bills that have selected provisions that are similar in text. Linked bill A bill that is contingent upon passage of another bill within the same chamber, e.g., a trust fund bill, a bill providing a public record exemption, or an implementing bill. The page numbers, when listed, for citations are constantly under review. The journals or printed bills of the respective chambers should be consulted as the official documents of the Legislature. The links for the page numbers are formatted to open the bill text PDF directly to the page containing the citation. However, if your browser is set to open PDFs in a new window, as is often the case with 64-bit browsers, the bill text will open to the first page. Home > Session > 2024 > House Bill 3 < Previous House Bill Next House Bill > Track This Bill View Bill Summary Glossary of Legislative Terms CS/CS/HB 3: Online Protections for Minors GENERAL BILL by Judiciary Committee ; Regulatory Reform & Economic Development Subcommittee ; Tramont ; Overdorf ; Sirois ; McFarland ; Rayner ; (CO-INTRODUCERS) Anderson ; Bankson ; Barnaby ; Beltran ; Black ; Botana ; Brackett ; Buchanan ; Canady ; Caruso ; Chamberlin ; Chambliss ; Chaney ; Fabricio ; Garcia ; Gonzalez Pittman ; Gossett-Seidman ; Gregory ; Jacques ; Leek ; Lopez, V. ; Massullo ; McClain ; Melo ; Michael ; Mooney ; Payne ; Persons-Mulicka ; Plakon ; Plasencia ; Roth ; Salzman ; Snyder ; Steele ; Temple ; Trabulsy ; Truenow ; Tuck ; Waldron ; Yarkosky ; Yeager Online Protections for Minors; Requiring social media platforms to prohibit certain minors from creating new accounts; requiring social media platforms to terminate certain accounts and provide additional options for termination of such accounts; providing conditions under which social media platforms are required to prohibit certain minors from entering into contracts to become account holders; authorizing the Department of Legal Affairs to bring actions under the Florida Deceptive and Unfair Trade Practices Act for knowing or reckless violations; authorizing the department to issue and enforce civil investigative demands under certain circumstances, etc. Effective Date: 1/1/2025 Last Action: 3/25/2024 - Chapter No. 2024-42; companion bill(s) passed, see CS/CS/HB 1491 (Ch. 2024-54) Bill Text: PDF Senate Committee References: Fiscal Policy (FP) View By Bill Version View By Category Bill History Related Bills (6) Bill Text (5) Amendments (4) Analyses (3) Vote History (3) Citations (3) Bill History Date Chamber Action 1/5/2024 House • Filed 1/9/2024 House • Referred to Regulatory Reform & Economic Development Subcommittee • Referred to Judiciary Committee • Now in Regulatory Reform & Economic Development Subcommittee • Added to Regulatory Reform & Economic Development Subcommittee agenda • 1st Reading (Original Filed Version) 1/11/2024 House • Favorable with CS by Regulatory Reform & Economic Development Subcommittee • Reported out of Regulatory Reform & Economic Development Subcommittee • Laid on Table under Rule 7.18(a) • CS Filed • 1st Reading (Committee Substitute 1) 1/12/2024 House • Referred to Judiciary Committee • Now in Judiciary Committee • Added to Judiciary Committee agenda 1/17/2024 House • Favorable with CS by Judiciary Committee • Reported out of Judiciary Committee 1/18/2024 House • Laid on Table under Rule 7.18(a) • CS Filed • Bill referred to House Calendar • Bill added to Special Order Calendar (1/23/2024) • 1st Reading (Committee Substitute 2) 1/23/2024 House • Read 2nd time • Placed on 3rd reading • Added to Third Reading Calendar 1/24/2024 House • Read 3rd time • CS passed; YEAS 119, NAYS 0 1/24/2024 Senate • In Messages 1/25/2024 Senate • Referred to Fiscal Policy • Received 2/12/2024 Senate • On Committee agenda-- Fiscal Policy, 02/15/24, 12:00 pm, 412 Knott Building --Temporarily Postponed 2/15/2024 Senate • Placed on Special Order Calendar, 02/21/24 --If Received 3/1/2024 Senate • Withdrawn from Fiscal Policy -SJ 575 • Placed on Calendar, on 2nd reading • Placed on Special Order Calendar, 03/04/24 -SJ 575 3/4/2024 Senate • Read 2nd time -SJ 622 • Amendment(s) adopted (961382) -SJ 622 • Read 3rd time -SJ 625 • CS passed as amended; YEAS 30 NAYS 5 -SJ 625 3/4/2024 House • In Messages 3/6/2024 House • Added to Senate Message List • Amendment 961382 Concur • CS passed as amended; YEAS 109, NAYS 4 • Ordered engrossed, then enrolled 3/21/2024 • Signed by Officers and presented to Governor 3/25/2024 • Approved by Governor • Chapter No. 2024-42; companion bill(s) passed, see CS/CS/HB 1491 (Ch. 2024-54) Related Bills Bill Number Subject Filed By Relationship Last Action and Location Track Bills H 1491 (er) Pub. Rec./Investigations by the Department of Legal Affairs Regulatory Reform & Economic Development Subcommittee Linked Last Action: 4/3/2024 Chapter No. 2024-54; companion bill(s) passed, see CS/CS/HB 3 (Ch. 2024-42) H 1 (er) Online Protections for Minors Judiciary Committee Similar Last Action: 3/1/2024 Vetoed by Governor; companion bill(s) passed, see CS/CS/HB 3 (Ch. 2024-42); companion bill(s) passed, see CS/CS/HB 1491 (Ch. 2024-2024-54) H 1377 (er) Pub. Rec./Investigations by the Department of Legal Affairs State Affairs Committee Compare Last Action: 3/1/2024 Vetoed by Governor; companion bill(s) passed, see CS/CS/HB 1491 (Ch. 2024-54), CS/CS/HB 3 (Ch. 2024-42) S 454 Protection of Minors on Social Media Platforms Garcia Compare Last Action: 3/8/2024 S Died in Commerce and Tourism, companion bill(s) passed, see CS/CS/HB 3 (Ch. 2024-42) S 1788 (c1) Social Media Use for Minors Grall Compare Last Action: 3/8/2024 S Died in Fiscal Policy, companion bill(s) passed, see CS/CS/HB 3 (Ch. 2024-42) S 1792 (c1) Online Access to Materials Harmful to Minors Grall Compare Last Action: 3/8/2024 S Died in Fiscal Policy, companion bill(s) passed, see CS/CS/HB 3 (Ch. 2024-42) Bill Text Version Posted Format H 3 Filed 1/5/2024 6:48 PM PDF H 3 c1 1/11/2024 4:55 PM PDF H 3 c2 1/18/2024 8:48 AM PDF H 3 e1 3/7/2024 10:00 AM PDF H 3 er 3/7/2024 10:14 AM PDF Committee Amendments H 3 Filed Amendment Sponsor Filed Last Committee Action Format 427693 - Amendment Remove lines 34-54 and insert: Tramont 1/10/2024 5:29 PM Adopted without Objection 1/11/2024 PDF H 3 c1 Amendment Sponsor Filed Last Committee Action Format 901561 - Amendment Remove line 72 and insert: Tramont 1/16/2024 3:20 PM Adopted 1/17/2024 PDF H 3 c2 Amendment Sponsor Filed Last Committee Action Format 493094 - Amendment (Delete All) Delete everything after the enacting clause and insert: Fiscal Policy (Hutson) 2/14/2024 12:00 PM Web Page PDF Floor Amendments H 3 c2 Amendments Sponsor Filed Last Floor Action Format 961382 - Amendment (Delete All) Delete everything after the enacting clause and insert: Grall 3/1/2024 3:18 PM House: Concur 3/6/2024 Web Page PDF Bill Analyses Type Analysis Author Posted Format Bill Analysis H 3 Fiscal Policy (Pre-Meeting) 2/13/2024 4:48 PM PDF Bill Analysis H 3 Regulatory Reform & Economic Development Subcommittee (Post-Meeting) 3/28/2024 3:10 PM PDF Bill Analysis H 3 Judiciary Committee (Post-Meeting) 1/17/2024 5:59 PM PDF Vote History - Committee No Committee Vote History Available Vote History - Floor Vote Date Chamber Result H 3 c2 1/24/2024 5:03 PM House 119 Yeas - 0 Nays H 3 c2 3/4/2024 10:28 AM Senate 30 Yeas - 5 Nays H 3 c2 3/6/2024 6:16 PM House 109 Yeas - 4 Nays Citations - Statutes (3) Citation Catchline Location in Bill Location In Bill Help 501.1736 Page 3 (pdf) 501.1737 Page 12 (pdf) 501.1738 Page 19 (pdf) Citations - Constitution (0) No Constitutional citations. Citations - Chapter Law (0) No Chapter Law citations. Identical bill Companion bills that are identical word-for-word, not including titles. However, Resolutions and Concurrent Resolutions are considered identical if the only difference is the word \"House\" or \"Senate.\" Similar bill Companion bills that are substantially similar in text or have substantial portions of text that are largely the same. Compare bill Bills that have selected provisions that are similar in text. Linked bill A bill that is contingent upon passage of another bill within the same chamber, e.g., a trust fund bill, a bill providing a public record exemption, or an implementing bill. The page numbers, when listed, for citations are constantly under review. The journals or printed bills of the respective chambers should be consulted as the official documents of the Legislature. The links for the page numbers are formatted to open the bill text PDF directly to the page containing the citation. However, if your browser is set to open PDFs in a new window, as is often the case with 64-bit browsers, the bill text will open to the first page. Home > Session > 2024 > House Bill 3 < Previous House Bill Next House Bill > Track This Bill View Bill Summary Glossary of Legislative Terms CS/CS/HB 3: Online Protections for Minors GENERAL BILL by Judiciary Committee ; Regulatory Reform & Economic Development Subcommittee ; Tramont ; Overdorf ; Sirois ; McFarland ; Rayner ; (CO-INTRODUCERS) Anderson ; Bankson ; Barnaby ; Beltran ; Black ; Botana ; Brackett ; Buchanan ; Canady ; Caruso ; Chamberlin ; Chambliss ; Chaney ; Fabricio ; Garcia ; Gonzalez Pittman ; Gossett-Seidman ; Gregory ; Jacques ; Leek ; Lopez, V. ; Massullo ; McClain ; Melo ; Michael ; Mooney ; Payne ; Persons-Mulicka ; Plakon ; Plasencia ; Roth ; Salzman ; Snyder ; Steele ; Temple ; Trabulsy ; Truenow ; Tuck ; Waldron ; Yarkosky ; Yeager Online Protections for Minors; Requiring social media platforms to prohibit certain minors from creating new accounts; requiring social media platforms to terminate certain accounts and provide additional options for termination of such accounts; providing conditions under which social media platforms are required to prohibit certain minors from entering into contracts to become account holders; authorizing the Department of Legal Affairs to bring actions under the Florida Deceptive and Unfair Trade Practices Act for knowing or reckless violations; authorizing the department to issue and enforce civil investigative demands under certain circumstances, etc. Effective Date: 1/1/2025 Last Action: 3/25/2024 - Chapter No. 2024-42; companion bill(s) passed, see CS/CS/HB 1491 (Ch. 2024-54) Bill Text: PDF Senate Committee References: Fiscal Policy (FP) View By Bill Version View By Category Bill History Related Bills (6) Bill Text (5) Amendments (4) Analyses (3) Vote History (3) Citations (3) Bill History Date Chamber Action 1/5/2024 House • Filed 1/9/2024 House • Referred to Regulatory Reform & Economic Development Subcommittee • Referred to Judiciary Committee • Now in Regulatory Reform & Economic Development Subcommittee • Added to Regulatory Reform & Economic Development Subcommittee agenda • 1st Reading (Original Filed Version) 1/11/2024 House • Favorable with CS by Regulatory Reform & Economic Development Subcommittee • Reported out of Regulatory Reform & Economic Development Subcommittee • Laid on Table under Rule 7.18(a) • CS Filed • 1st Reading (Committee Substitute 1) 1/12/2024 House • Referred to Judiciary Committee • Now in Judiciary Committee • Added to Judiciary Committee agenda 1/17/2024 House • Favorable with CS by Judiciary Committee • Reported out of Judiciary Committee 1/18/2024 House • Laid on Table under Rule 7.18(a) • CS Filed • Bill referred to House Calendar • Bill added to Special Order Calendar (1/23/2024) • 1st Reading (Committee Substitute 2) 1/23/2024 House • Read 2nd time • Placed on 3rd reading • Added to Third Reading Calendar 1/24/2024 House • Read 3rd time • CS passed; YEAS 119, NAYS 0 1/24/2024 Senate • In Messages 1/25/2024 Senate • Referred to Fiscal Policy • Received 2/12/2024 Senate • On Committee agenda-- Fiscal Policy, 02/15/24, 12:00 pm, 412 Knott Building --Temporarily Postponed 2/15/2024 Senate • Placed on Special Order Calendar, 02/21/24 --If Received 3/1/2024 Senate • Withdrawn from Fiscal Policy -SJ 575 • Placed on Calendar, on 2nd reading • Placed on Special Order Calendar, 03/04/24 -SJ 575 3/4/2024 Senate • Read 2nd time -SJ 622 • Amendment(s) adopted (961382) -SJ 622 • Read 3rd time -SJ 625 • CS passed as amended; YEAS 30 NAYS 5 -SJ 625 3/4/2024 House • In Messages 3/6/2024 House • Added to Senate Message List • Amendment 961382 Concur • CS passed as amended; YEAS 109, NAYS 4 • Ordered engrossed, then enrolled 3/21/2024 • Signed by Officers and presented to Governor 3/25/2024 • Approved by Governor • Chapter No. 2024-42; companion bill(s) passed, see CS/CS/HB 1491 (Ch. 2024-54) Related Bills Bill Number Subject Filed By Relationship Last Action and Location Track Bills H 1491 (er) Pub. Rec./Investigations by the Department of Legal Affairs Regulatory Reform & Economic Development Subcommittee Linked Last Action: 4/3/2024 Chapter No. 2024-54; companion bill(s) passed, see CS/CS/HB 3 (Ch. 2024-42) H 1 (er) Online Protections for Minors Judiciary Committee Similar Last Action: 3/1/2024 Vetoed by Governor; companion bill(s) passed, see CS/CS/HB 3 (Ch. 2024-42); companion bill(s) passed, see CS/CS/HB 1491 (Ch. 2024-2024-54) H 1377 (er) Pub. Rec./Investigations by the Department of Legal Affairs State Affairs Committee Compare Last Action: 3/1/2024 Vetoed by Governor; companion bill(s) passed, see CS/CS/HB 1491 (Ch. 2024-54), CS/CS/HB 3 (Ch. 2024-42) S 454 Protection of Minors on Social Media Platforms Garcia Compare Last Action: 3/8/2024 S Died in Commerce and Tourism, companion bill(s) passed, see CS/CS/HB 3 (Ch. 2024-42) S 1788 (c1) Social Media Use for Minors Grall Compare Last Action: 3/8/2024 S Died in Fiscal Policy, companion bill(s) passed, see CS/CS/HB 3 (Ch. 2024-42) S 1792 (c1) Online Access to Materials Harmful to Minors Grall Compare Last Action: 3/8/2024 S Died in Fiscal Policy, companion bill(s) passed, see CS/CS/HB 3 (Ch. 2024-42) Bill Text Version Posted Format H 3 Filed 1/5/2024 6:48 PM PDF H 3 c1 1/11/2024 4:55 PM PDF H 3 c2 1/18/2024 8:48 AM PDF H 3 e1 3/7/2024 10:00 AM PDF H 3 er 3/7/2024 10:14 AM PDF Committee Amendments H 3 Filed Amendment Sponsor Filed Last Committee Action Format 427693 - Amendment Remove lines 34-54 and insert: Tramont 1/10/2024 5:29 PM Adopted without Objection 1/11/2024 PDF H 3 c1 Amendment Sponsor Filed Last Committee Action Format 901561 - Amendment Remove line 72 and insert: Tramont 1/16/2024 3:20 PM Adopted 1/17/2024 PDF H 3 c2 Amendment Sponsor Filed Last Committee Action Format 493094 - Amendment (Delete All) Delete everything after the enacting clause and insert: Fiscal Policy (Hutson) 2/14/2024 12:00 PM Web Page PDF Floor Amendments H 3 c2 Amendments Sponsor Filed Last Floor Action Format 961382 - Amendment (Delete All) Delete everything after the enacting clause and insert: Grall 3/1/2024 3:18 PM House: Concur 3/6/2024 Web Page PDF Bill Analyses Type Analysis Author Posted Format Bill Analysis H 3 Fiscal Policy (Pre-Meeting) 2/13/2024 4:48 PM PDF Bill Analysis H 3 Regulatory Reform & Economic Development Subcommittee (Post-Meeting) 3/28/2024 3:10 PM PDF Bill Analysis H 3 Judiciary Committee (Post-Meeting) 1/17/2024 5:59 PM PDF Vote History - Committee No Committee Vote History Available Vote History - Floor Vote Date Chamber Result H 3 c2 1/24/2024 5:03 PM House 119 Yeas - 0 Nays H 3 c2 3/4/2024 10:28 AM Senate 30 Yeas - 5 Nays H 3 c2 3/6/2024 6:16 PM House 109 Yeas - 4 Nays Citations - Statutes (3) Citation Catchline Location in Bill Location In Bill Help 501.1736 Page 3 (pdf) 501.1737 Page 12 (pdf) 501.1738 Page 19 (pdf) Citations - Constitution (0) No Constitutional citations. Citations - Chapter Law (0) No Chapter Law citations. < Previous House Bill Next House Bill > Track This Bill View Bill Summary Glossary of Legislative Terms Track This Bill View Bill Summary Glossary of Legislative Terms "
        },
        {
          "title": "CS/CS/HB 3: Online Protections for Minors",
          "content": "GENERAL BILL by Judiciary Committee ; Regulatory Reform & Economic Development Subcommittee ; Tramont ; Overdorf ; Sirois ; McFarland ; Rayner ; (CO-INTRODUCERS) Anderson ; Bankson ; Barnaby ; Beltran ; Black ; Botana ; Brackett ; Buchanan ; Canady ; Caruso ; Chamberlin ; Chambliss ; Chaney ; Fabricio ; Garcia ; Gonzalez Pittman ; Gossett-Seidman ; Gregory ; Jacques ; Leek ; Lopez, V. ; Massullo ; McClain ; Melo ; Michael ; Mooney ; Payne ; Persons-Mulicka ; Plakon ; Plasencia ; Roth ; Salzman ; Snyder ; Steele ; Temple ; Trabulsy ; Truenow ; Tuck ; Waldron ; Yarkosky ; Yeager Online Protections for Minors; Requiring social media platforms to prohibit certain minors from creating new accounts; requiring social media platforms to terminate certain accounts and provide additional options for termination of such accounts; providing conditions under which social media platforms are required to prohibit certain minors from entering into contracts to become account holders; authorizing the Department of Legal Affairs to bring actions under the Florida Deceptive and Unfair Trade Practices Act for knowing or reckless violations; authorizing the department to issue and enforce civil investigative demands under certain circumstances, etc. Effective Date: 1/1/2025 Last Action: 3/25/2024 - Chapter No. 2024-42; companion bill(s) passed, see CS/CS/HB 1491 (Ch. 2024-54) Bill Text: PDF Senate Committee References: Fiscal Policy (FP) Effective Date: 1/1/2025 Last Action: 3/25/2024 - Chapter No. 2024-42; companion bill(s) passed, see CS/CS/HB 1491 (Ch. 2024-54) Bill Text: PDF Senate Committee References: Fiscal Policy (FP) View By Bill Version View By Category View By Bill Version View By Category Bill History Related Bills (6) Bill Text (5) Amendments (4) Analyses (3) Vote History (3) Citations (3) Bill History Date Chamber Action 1/5/2024 House • Filed 1/9/2024 House • Referred to Regulatory Reform & Economic Development Subcommittee • Referred to Judiciary Committee • Now in Regulatory Reform & Economic Development Subcommittee • Added to Regulatory Reform & Economic Development Subcommittee agenda • 1st Reading (Original Filed Version) 1/11/2024 House • Favorable with CS by Regulatory Reform & Economic Development Subcommittee • Reported out of Regulatory Reform & Economic Development Subcommittee • Laid on Table under Rule 7.18(a) • CS Filed • 1st Reading (Committee Substitute 1) 1/12/2024 House • Referred to Judiciary Committee • Now in Judiciary Committee • Added to Judiciary Committee agenda 1/17/2024 House • Favorable with CS by Judiciary Committee • Reported out of Judiciary Committee 1/18/2024 House • Laid on Table under Rule 7.18(a) • CS Filed • Bill referred to House Calendar • Bill added to Special Order Calendar (1/23/2024) • 1st Reading (Committee Substitute 2) 1/23/2024 House • Read 2nd time • Placed on 3rd reading • Added to Third Reading Calendar 1/24/2024 House • Read 3rd time • CS passed; YEAS 119, NAYS 0 1/24/2024 Senate • In Messages 1/25/2024 Senate • Referred to Fiscal Policy • Received 2/12/2024 Senate • On Committee agenda-- Fiscal Policy, 02/15/24, 12:00 pm, 412 Knott Building --Temporarily Postponed 2/15/2024 Senate • Placed on Special Order Calendar, 02/21/24 --If Received 3/1/2024 Senate • Withdrawn from Fiscal Policy -SJ 575 • Placed on Calendar, on 2nd reading • Placed on Special Order Calendar, 03/04/24 -SJ 575 3/4/2024 Senate • Read 2nd time -SJ 622 • Amendment(s) adopted (961382) -SJ 622 • Read 3rd time -SJ 625 • CS passed as amended; YEAS 30 NAYS 5 -SJ 625 3/4/2024 House • In Messages 3/6/2024 House • Added to Senate Message List • Amendment 961382 Concur • CS passed as amended; YEAS 109, NAYS 4 • Ordered engrossed, then enrolled 3/21/2024 • Signed by Officers and presented to Governor 3/25/2024 • Approved by Governor • Chapter No. 2024-42; companion bill(s) passed, see CS/CS/HB 1491 (Ch. 2024-54) Related Bills Bill Number Subject Filed By Relationship Last Action and Location Track Bills H 1491 (er) Pub. Rec./Investigations by the Department of Legal Affairs Regulatory Reform & Economic Development Subcommittee Linked Last Action: 4/3/2024 Chapter No. 2024-54; companion bill(s) passed, see CS/CS/HB 3 (Ch. 2024-42) H 1 (er) Online Protections for Minors Judiciary Committee Similar Last Action: 3/1/2024 Vetoed by Governor; companion bill(s) passed, see CS/CS/HB 3 (Ch. 2024-42); companion bill(s) passed, see CS/CS/HB 1491 (Ch. 2024-2024-54) H 1377 (er) Pub. Rec./Investigations by the Department of Legal Affairs State Affairs Committee Compare Last Action: 3/1/2024 Vetoed by Governor; companion bill(s) passed, see CS/CS/HB 1491 (Ch. 2024-54), CS/CS/HB 3 (Ch. 2024-42) S 454 Protection of Minors on Social Media Platforms Garcia Compare Last Action: 3/8/2024 S Died in Commerce and Tourism, companion bill(s) passed, see CS/CS/HB 3 (Ch. 2024-42) S 1788 (c1) Social Media Use for Minors Grall Compare Last Action: 3/8/2024 S Died in Fiscal Policy, companion bill(s) passed, see CS/CS/HB 3 (Ch. 2024-42) S 1792 (c1) Online Access to Materials Harmful to Minors Grall Compare Last Action: 3/8/2024 S Died in Fiscal Policy, companion bill(s) passed, see CS/CS/HB 3 (Ch. 2024-42) Bill Text Version Posted Format H 3 Filed 1/5/2024 6:48 PM PDF H 3 c1 1/11/2024 4:55 PM PDF H 3 c2 1/18/2024 8:48 AM PDF H 3 e1 3/7/2024 10:00 AM PDF H 3 er 3/7/2024 10:14 AM PDF Committee Amendments H 3 Filed Amendment Sponsor Filed Last Committee Action Format 427693 - Amendment Remove lines 34-54 and insert: Tramont 1/10/2024 5:29 PM Adopted without Objection 1/11/2024 PDF H 3 c1 Amendment Sponsor Filed Last Committee Action Format 901561 - Amendment Remove line 72 and insert: Tramont 1/16/2024 3:20 PM Adopted 1/17/2024 PDF H 3 c2 Amendment Sponsor Filed Last Committee Action Format 493094 - Amendment (Delete All) Delete everything after the enacting clause and insert: Fiscal Policy (Hutson) 2/14/2024 12:00 PM Web Page PDF Floor Amendments H 3 c2 Amendments Sponsor Filed Last Floor Action Format 961382 - Amendment (Delete All) Delete everything after the enacting clause and insert: Grall 3/1/2024 3:18 PM House: Concur 3/6/2024 Web Page PDF Bill Analyses Type Analysis Author Posted Format Bill Analysis H 3 Fiscal Policy (Pre-Meeting) 2/13/2024 4:48 PM PDF Bill Analysis H 3 Regulatory Reform & Economic Development Subcommittee (Post-Meeting) 3/28/2024 3:10 PM PDF Bill Analysis H 3 Judiciary Committee (Post-Meeting) 1/17/2024 5:59 PM PDF Vote History - Committee No Committee Vote History Available Vote History - Floor Vote Date Chamber Result H 3 c2 1/24/2024 5:03 PM House 119 Yeas - 0 Nays H 3 c2 3/4/2024 10:28 AM Senate 30 Yeas - 5 Nays H 3 c2 3/6/2024 6:16 PM House 109 Yeas - 4 Nays Citations - Statutes (3) Citation Catchline Location in Bill Location In Bill Help 501.1736 Page 3 (pdf) 501.1737 Page 12 (pdf) 501.1738 Page 19 (pdf) Citations - Constitution (0) No Constitutional citations. Citations - Chapter Law (0) No Chapter Law citations. Bill History Related Bills (6) Bill Text (5) Amendments (4) Analyses (3) Vote History (3) Citations (3) Bill History Date Chamber Action 1/5/2024 House • Filed 1/9/2024 House • Referred to Regulatory Reform & Economic Development Subcommittee • Referred to Judiciary Committee • Now in Regulatory Reform & Economic Development Subcommittee • Added to Regulatory Reform & Economic Development Subcommittee agenda • 1st Reading (Original Filed Version) 1/11/2024 House • Favorable with CS by Regulatory Reform & Economic Development Subcommittee • Reported out of Regulatory Reform & Economic Development Subcommittee • Laid on Table under Rule 7.18(a) • CS Filed • 1st Reading (Committee Substitute 1) 1/12/2024 House • Referred to Judiciary Committee • Now in Judiciary Committee • Added to Judiciary Committee agenda 1/17/2024 House • Favorable with CS by Judiciary Committee • Reported out of Judiciary Committee 1/18/2024 House • Laid on Table under Rule 7.18(a) • CS Filed • Bill referred to House Calendar • Bill added to Special Order Calendar (1/23/2024) • 1st Reading (Committee Substitute 2) 1/23/2024 House • Read 2nd time • Placed on 3rd reading • Added to Third Reading Calendar 1/24/2024 House • Read 3rd time • CS passed; YEAS 119, NAYS 0 1/24/2024 Senate • In Messages 1/25/2024 Senate • Referred to Fiscal Policy • Received 2/12/2024 Senate • On Committee agenda-- Fiscal Policy, 02/15/24, 12:00 pm, 412 Knott Building --Temporarily Postponed 2/15/2024 Senate • Placed on Special Order Calendar, 02/21/24 --If Received 3/1/2024 Senate • Withdrawn from Fiscal Policy -SJ 575 • Placed on Calendar, on 2nd reading • Placed on Special Order Calendar, 03/04/24 -SJ 575 3/4/2024 Senate • Read 2nd time -SJ 622 • Amendment(s) adopted (961382) -SJ 622 • Read 3rd time -SJ 625 • CS passed as amended; YEAS 30 NAYS 5 -SJ 625 3/4/2024 House • In Messages 3/6/2024 House • Added to Senate Message List • Amendment 961382 Concur • CS passed as amended; YEAS 109, NAYS 4 • Ordered engrossed, then enrolled 3/21/2024 • Signed by Officers and presented to Governor 3/25/2024 • Approved by Governor • Chapter No. 2024-42; companion bill(s) passed, see CS/CS/HB 1491 (Ch. 2024-54) "
        },
        {
          "title": "Bill History",
          "content": "Related Bills Bill Number Subject Filed By Relationship Last Action and Location Track Bills H 1491 (er) Pub. Rec./Investigations by the Department of Legal Affairs Regulatory Reform & Economic Development Subcommittee Linked Last Action: 4/3/2024 Chapter No. 2024-54; companion bill(s) passed, see CS/CS/HB 3 (Ch. 2024-42) H 1 (er) Online Protections for Minors Judiciary Committee Similar Last Action: 3/1/2024 Vetoed by Governor; companion bill(s) passed, see CS/CS/HB 3 (Ch. 2024-42); companion bill(s) passed, see CS/CS/HB 1491 (Ch. 2024-2024-54) H 1377 (er) Pub. Rec./Investigations by the Department of Legal Affairs State Affairs Committee Compare Last Action: 3/1/2024 Vetoed by Governor; companion bill(s) passed, see CS/CS/HB 1491 (Ch. 2024-54), CS/CS/HB 3 (Ch. 2024-42) S 454 Protection of Minors on Social Media Platforms Garcia Compare Last Action: 3/8/2024 S Died in Commerce and Tourism, companion bill(s) passed, see CS/CS/HB 3 (Ch. 2024-42) S 1788 (c1) Social Media Use for Minors Grall Compare Last Action: 3/8/2024 S Died in Fiscal Policy, companion bill(s) passed, see CS/CS/HB 3 (Ch. 2024-42) S 1792 (c1) Online Access to Materials Harmful to Minors Grall Compare Last Action: 3/8/2024 S Died in Fiscal Policy, companion bill(s) passed, see CS/CS/HB 3 (Ch. 2024-42) "
        },
        {
          "title": "Related Bills",
          "content": "Bill Text Version Posted Format H 3 Filed 1/5/2024 6:48 PM PDF H 3 c1 1/11/2024 4:55 PM PDF H 3 c2 1/18/2024 8:48 AM PDF H 3 e1 3/7/2024 10:00 AM PDF H 3 er 3/7/2024 10:14 AM PDF "
        },
        {
          "title": "Bill Text",
          "content": "Committee Amendments H 3 Filed Amendment Sponsor Filed Last Committee Action Format 427693 - Amendment Remove lines 34-54 and insert: Tramont 1/10/2024 5:29 PM Adopted without Objection 1/11/2024 PDF H 3 c1 Amendment Sponsor Filed Last Committee Action Format 901561 - Amendment Remove line 72 and insert: Tramont 1/16/2024 3:20 PM Adopted 1/17/2024 PDF H 3 c2 Amendment Sponsor Filed Last Committee Action Format 493094 - Amendment (Delete All) Delete everything after the enacting clause and insert: Fiscal Policy (Hutson) 2/14/2024 12:00 PM Web Page PDF Floor Amendments H 3 c2 Amendments Sponsor Filed Last Floor Action Format 961382 - Amendment (Delete All) Delete everything after the enacting clause and insert: Grall 3/1/2024 3:18 PM House: Concur 3/6/2024 Web Page PDF Committee Amendments H 3 Filed Amendment Sponsor Filed Last Committee Action Format 427693 - Amendment Remove lines 34-54 and insert: Tramont 1/10/2024 5:29 PM Adopted without Objection 1/11/2024 PDF H 3 c1 Amendment Sponsor Filed Last Committee Action Format 901561 - Amendment Remove line 72 and insert: Tramont 1/16/2024 3:20 PM Adopted 1/17/2024 PDF H 3 c2 Amendment Sponsor Filed Last Committee Action Format 493094 - Amendment (Delete All) Delete everything after the enacting clause and insert: Fiscal Policy (Hutson) 2/14/2024 12:00 PM Web Page PDF "
        },
        {
          "title": "Committee Amendments",
          "content": "H 3 Filed Amendment Sponsor Filed Last Committee Action Format 427693 - Amendment Remove lines 34-54 and insert: Tramont 1/10/2024 5:29 PM Adopted without Objection 1/11/2024 PDF H 3 c1 Amendment Sponsor Filed Last Committee Action Format 901561 - Amendment Remove line 72 and insert: Tramont 1/16/2024 3:20 PM Adopted 1/17/2024 PDF H 3 c2 Amendment Sponsor Filed Last Committee Action Format 493094 - Amendment (Delete All) Delete everything after the enacting clause and insert: Fiscal Policy (Hutson) 2/14/2024 12:00 PM Web Page PDF Floor Amendments H 3 c2 Amendments Sponsor Filed Last Floor Action Format 961382 - Amendment (Delete All) Delete everything after the enacting clause and insert: Grall 3/1/2024 3:18 PM House: Concur 3/6/2024 Web Page PDF "
        },
        {
          "title": "Floor Amendments",
          "content": "H 3 c2 Amendments Sponsor Filed Last Floor Action Format 961382 - Amendment (Delete All) Delete everything after the enacting clause and insert: Grall 3/1/2024 3:18 PM House: Concur 3/6/2024 Web Page PDF Bill Analyses Type Analysis Author Posted Format Bill Analysis H 3 Fiscal Policy (Pre-Meeting) 2/13/2024 4:48 PM PDF Bill Analysis H 3 Regulatory Reform & Economic Development Subcommittee (Post-Meeting) 3/28/2024 3:10 PM PDF Bill Analysis H 3 Judiciary Committee (Post-Meeting) 1/17/2024 5:59 PM PDF "
        },
        {
          "title": "Bill Analyses",
          "content": "Vote History - Committee No Committee Vote History Available Vote History - Floor Vote Date Chamber Result H 3 c2 1/24/2024 5:03 PM House 119 Yeas - 0 Nays H 3 c2 3/4/2024 10:28 AM Senate 30 Yeas - 5 Nays H 3 c2 3/6/2024 6:16 PM House 109 Yeas - 4 Nays "
        },
        {
          "title": "Vote History - Floor",
          "content": "Citations - Statutes (3) Citation Catchline Location in Bill Location In Bill Help 501.1736 Page 3 (pdf) 501.1737 Page 12 (pdf) 501.1738 Page 19 (pdf) Citations - Constitution (0) No Constitutional citations. Citations - Chapter Law (0) No Chapter Law citations. "
        },
        {
          "title": "Citations - Constitution (0)",
          "content": "No Constitutional citations. "
        },
        {
          "title": "Citations - Chapter Law (0)",
          "content": "No Chapter Law citations. Identical bill Companion bills that are identical word-for-word, not including titles. However, Resolutions and Concurrent Resolutions are considered identical if the only difference is the word \"House\" or \"Senate.\" Similar bill Companion bills that are substantially similar in text or have substantial portions of text that are largely the same. Compare bill Bills that have selected provisions that are similar in text. Linked bill A bill that is contingent upon passage of another bill within the same chamber, e.g., a trust fund bill, a bill providing a public record exemption, or an implementing bill. Identical bill Companion bills that are identical word-for-word, not including titles. However, Resolutions and Concurrent Resolutions are considered identical if the only difference is the word \"House\" or \"Senate.\" Similar bill Companion bills that are substantially similar in text or have substantial portions of text that are largely the same. Compare bill Bills that have selected provisions that are similar in text. Linked bill A bill that is contingent upon passage of another bill within the same chamber, e.g., a trust fund bill, a bill providing a public record exemption, or an implementing bill. The page numbers, when listed, for citations are constantly under review. The journals or printed bills of the respective chambers should be consulted as the official documents of the Legislature. The links for the page numbers are formatted to open the bill text PDF directly to the page containing the citation. However, if your browser is set to open PDFs in a new window, as is often the case with 64-bit browsers, the bill text will open to the first page. The page numbers, when listed, for citations are constantly under review. The journals or printed bills of the respective chambers should be consulted as the official documents of the Legislature. The links for the page numbers are formatted to open the bill text PDF directly to the page containing the citation. However, if your browser is set to open PDFs in a new window, as is often the case with 64-bit browsers, the bill text will open to the first page. Senators Senator List Find Your Legislators District Maps Vote Disclosures Committees Committee List Committee Publications Search Bill Search Tips Statute Search Tips Site Search Tips Session Bills Calendars Journals Appropriations Conferences Reports Executive Appointments Executive Suspensions Redistricting Laws Statutes Constitution Laws of Florida Order - Legistore Media Press Releases Publications Videos Topics Video Broadcast Schedule About Employment Visit Us Contact Us Page Program Offices President's Office Majority Office Minority Office Secretary's Office Reference Glossary FAQ Help Links Search Tips Publications Rules Handbooks Advisory Opinions Public Records Connect with the Senate Twitter RSS Senate Tracker Login Sign Up Tracker Help Plug-ins Adobe Acrobat Reader WinZip Connect with the Senate Senate Tracker Disclaimer: The information on this system is unverified. The journals or printed bills of the respective chambers should be consulted for official purposes. Privacy Statement|Accessibility Copyright  2000- 2025 State of Florida. Disclaimer: The information on this system is unverified. The journals or printed bills of the respective chambers should be consulted for official purposes. Disclaimer: The information on this system is unverified. The journals or printed bills of the respective chambers should be consulted for official purposes. Privacy Statement|Accessibility Copyright  2000- 2025 State of Florida. "
        }
      ],
      "content_type": "legal_document",
      "word_count": 10712,
      "char_count": 67589
    },
    {
      "url": "https://en.wikipedia.org/wiki/Utah_Social_Media_Regulation_Act",
      "title": "Utah Social Media Regulation Act - Wikipedia",
      "description": "",
      "keywords": "",
      "author": "",
      "published_date": "",
      "scraped_at": "2025-08-28T01:34:55.519939",
      "sections": [
        {
          "title": "Introduction",
          "content": "Utah Social Media Regulation ActUtah State Legislature Long title S.B. 152 and H.B. 311 Signed bySpencer CoxSignedMarch 23, 2023Status: Blocked S.B. 152 and H.B. 311 S.B. 152 and H.B. 311, collectively known as the Utah Social Media Regulation Act, were social media bills that were passed by the Utah State Legislature in March 2023. The bills would've collectively imposed restrictions on how social networking services serve minors in the state of Utah, including mandatory age verification, and restrictions on data collection, algorithmic recommendations, and on when social networks would've been accessible to minors. The Act was intended to take effect in March 2024. However, following a lawsuit over the Act by NetChoice, the Utah attorney general stated in January 2024 that its implementation had been delayed to October 2024, but was likely to be repealed and amended. On September 10, 2024 Chief Judge Robert J. Shelby issued a written order granting a request from NetChoice, a tech industry group, for a preliminary injunction, meaning that Utah will be unable to enforce its social media law as litigation plays out.[1] The law was appealed to the 10th Circuit on October 11, 2024 and is awaiting a decision.[2] "
        },
        {
          "title": "Provisions",
          "content": "The Act comprises two bills, S.B. 152 and H.B. 311, which respectively regulate access to social network accounts registered to minors, and impose obligations on social networking services to follow design practices that protect the privacy of minors.[3][4] The bills would apply to social networks with more than 5 million active users in the United States.[5] Social networking services would've verified the age of all users in the state of Utah, or else their account must've been deleted. The Act does not specify a specific method of age verification. Users who are under 18 must have consent from a parent or guardian to open an account, and the parent must be able to have access to the account and its data for monitoring.[6] Unless required to comply with state or federal law, social networks were prohibited from collecting data based on the activity of minors, and may've not displayed targeted advertising or algorithmic recommendations of content, users, or groups to minors. A social network must not allow minors to access the service between the hours of 10:30 p.m., and 6:30 a.m. without parental consent.[3][4] H.B. 311 prohibits social networks from exposing features to minors that cause them to have an \"addiction\" to the platform; the service must perform quarterly audits, and may be sued by users for harms caused by providing \"addictive\" features; there is a rebuttable presumption of harm if the plaintiff is 16 or younger.[3][4] The bills prescribed fines of $2,500 per-violation for violations of the provisions of S.B. 152, and up to $250,000 in liabilities (plus fines of $2,500 per-user) for violations of the addiction rules.[7] "
        },
        {
          "title": "History",
          "content": "The two bills were passed in early-March 2023,[8] and signed by Governor Spencer Cox on March 23, 2023.[3][4] Cox cited studies linking social media addiction to increases in depression and suicide among youth.[5] They were originally intended to take effect on March 1, 2024.[3][4] In the wake of a lawsuit in Arkansas by the trade association NetChoice over a similar bill, state senator and bill author Mike McKell stated that he planned to introduce amendments when the legislature resumed in 2024.[9] In December 2023, NetChoice filed a lawsuit in Utah seeking to block the Act, citing that its definition of a social network was too vague, and that it \"restricts who can express themselves, what can be said, and when and how speech on covered websites can occur, down to the very hours of the day minors can use covered websites. The First Amendment, reinforced by decades of precedent, allows none of this.\"[5] In regards to its age verification requirements, NetChoice argued that \"it may not be enough to simply verify the age of whatever person may be listed on a form of identification (even if they have such a record) because that record may not accurately reflect who the individual actually is.\" The office of the attorney general stated that the state was \"reviewing the lawsuit but remains intently focused on the goal of this legislation: Protecting young people from negative and harmful effects of social media use.\"[5] In January 2024, Attorney General Sean Reyes asked the court to delay a hearing over the bill, stating that its effective date had been delayed to October 2024, and that the legislature planned to repeal and replace the bills.[10][11] "
        },
        {
          "title": "See also",
          "content": "Age appropriate design code "
        },
        {
          "title": "References",
          "content": "^ \"Federal judge blocks Utah social media law\". Deseret News. 2024-09-11. Retrieved 2024-09-11. ^ NetChoice v. Reyes, et al 24-4100 | U.S. Court of Appeals, Tenth Circuit | Justia ^ a b c d e LLP, Hunton Andrews Kurth (2023-03-10). \"Utah Legislature Passes Bills Restricting Social Media Accounts for Minors\". Privacy & Information Security Law Blog. Retrieved 2024-04-23. ^ a b c d e Jr, Baker McKenzie-Cyrus Vance; Oliver, Mariana; Toltzis, Avishai; Roper, Elizabeth (2023-03-29). \"Utah Signs Bills Regulating Minors' Social Media Usage\". Lexology. Retrieved 2024-04-23. ^ a b c d Schott, Bryan (2023-12-18). \"Utah faces new lawsuit over social media restrictions for minors. Here's why\". The Salt Lake Tribune. Retrieved 2024-02-09. ^ Miller, Saige (2023-03-24). \"Utah passes an age-verification law for anyone using social media\". NPR. Retrieved 2024-05-07. ^ Jacobson, Matthew (2023-10-16). \"Utah proposes new rules to part of bills in regulating social media companies\". KUTV. Retrieved 2023-11-21. ^ Moshiri, Azadeh (2023-03-24). \"Utah is first US state to limit teen social media access\". BBC News. Retrieved 2023-03-27. ^ \"Utah social media law set for adjustments after Ark. lawsuit\". Pluribus News. Retrieved 2024-04-23. ^ Jones, Derrick (2024-01-23). \"Utah's social media child protection law put on hold\". KSL. Retrieved 2024-03-04. ^ Schott, Bryan (2024-01-17). \"Utah's new social media regulation may 'completely change' this year on heels of second lawsuit\". The Salt Lake Tribune. ISSN 0746-3502. Retrieved 2024-03-04. "
        }
      ],
      "references": [
        "^ \"Federal judge blocks Utah social media law\". Deseret News. 2024-09-11. Retrieved 2024-09-11.",
        "^ NetChoice v. Reyes, et al 24-4100 | U.S. Court of Appeals, Tenth Circuit | Justia",
        "^ a b c d e LLP, Hunton Andrews Kurth (2023-03-10). \"Utah Legislature Passes Bills Restricting Social Media Accounts for Minors\". Privacy & Information Security Law Blog. Retrieved 2024-04-23.",
        "^ a b c d e Jr, Baker McKenzie-Cyrus Vance; Oliver, Mariana; Toltzis, Avishai; Roper, Elizabeth (2023-03-29). \"Utah Signs Bills Regulating Minors' Social Media Usage\". Lexology. Retrieved 2024-04-23.",
        "^ a b c d Schott, Bryan (2023-12-18). \"Utah faces new lawsuit over social media restrictions for minors. Here's why\". The Salt Lake Tribune. Retrieved 2024-02-09.",
        "^ Miller, Saige (2023-03-24). \"Utah passes an age-verification law for anyone using social media\". NPR. Retrieved 2024-05-07.",
        "^ Jacobson, Matthew (2023-10-16). \"Utah proposes new rules to part of bills in regulating social media companies\". KUTV. Retrieved 2023-11-21.",
        "^ Moshiri, Azadeh (2023-03-24). \"Utah is first US state to limit teen social media access\". BBC News. Retrieved 2023-03-27.",
        "^ \"Utah social media law set for adjustments after Ark. lawsuit\". Pluribus News. Retrieved 2024-04-23.",
        "^ Jones, Derrick (2024-01-23). \"Utah's social media child protection law put on hold\". KSL. Retrieved 2024-03-04.",
        "^ Schott, Bryan (2024-01-17). \"Utah's new social media regulation may 'completely change' this year on heels of second lawsuit\". The Salt Lake Tribune. ISSN 0746-3502. Retrieved 2024-03-04."
      ],
      "content_type": "wikipedia",
      "word_count": 973,
      "char_count": 6136
    },
    {
      "url": "https://www.law.cornell.edu/uscode/text/18/2258A",
      "title": "18 U.S. Code  2258A - Reporting requirements of providers | U.S. Code | US Law | LII / Legal Information Institute",
      "description": "",
      "keywords": "",
      "author": "",
      "published_date": "",
      "scraped_at": "2025-08-28T01:34:59.902964",
      "sections": [
        {
          "title": "Legal Text",
          "content": "Quick search by citation: Title Section Go! 18 U.S. Code  2258A - Reporting requirements of providers U.S. Code Notes prev | next (a) Duty To Report.— (1) In general.— (A) Duty.—In order to reduce the proliferation of online child sexual exploitation and to prevent the online sexual exploitation of children, a provider— (i) shall, as soon as reasonably possible after obtaining actual knowledge of any facts or circumstances described in paragraph (2)(A), take the actions described in subparagraph (B); and (ii) may, after obtaining actual knowledge of any facts or circumstances described in paragraph (2)(B), take the actions described in subparagraph (B). (B) Actions described.—The actions described in this subparagraph are— (i) providing to the CyberTipline of NCMEC, or any successor to the CyberTipline operated by NCMEC, the mailing address, telephone number, facsimile number, electronic mailing address of, and individual point of contact for, such provider; and (ii) making a report of such facts or circumstances to the CyberTipline, or any successor to the CyberTipline operated by NCMEC. (2) Facts or circumstances.— (A) Apparent violations.— The facts or circumstances described in this subparagraph are any facts or circumstances from which there is an apparent violation of section 2251, 2251A, 2252, 2252A, 2252B, or 2260 that involves child pornography, of section 1591 (if the violation involves a minor), or of [1] 2422(b). (B) Imminent violations.— The facts or circumstances described in this subparagraph are any facts or circumstances which indicate a violation of any of the sections described in subparagraph (A) involving child pornography may be planned or imminent. (b) Contents of Report.—In an effort to prevent the future sexual victimization of children, and to the extent the information is within the custody or control of a provider, the facts and circumstances included in each report under subsection (a)(1) may, at the sole discretion of the provider, include the following information: (1) Information about the involved individual.— Information relating to the identity of any individual who appears to have violated or plans to violate a Federal law described in subsection (a)(2), which may, to the extent reasonably practicable, include the electronic mail address, Internet Protocol address, uniform resource locator, payment information (excluding personally identifiable information), or any other identifying information, including self-reported identifying information. (2) Historical reference.— Information relating to when and how a customer or subscriber of a provider uploaded, transmitted, or received content relating to the report or when and how content relating to the report was reported to, or discovered by the provider, including a date and time stamp and time zone. (3) Geographic location information.— Information relating to the geographic location of the involved individual or website, which may include the Internet Protocol address or verified address, or, if not reasonably available, at least one form of geographic identifying information, including area code or zip code, provided by the customer or subscriber, or stored or obtained by the provider. (4) Visual depictions of apparent child pornography.— Any visual depiction of apparent child pornography or other content relating to the incident such report is regarding. (5) Complete communication.—The complete communication containing any visual depiction of apparent child pornography or other content, including— (A) any data or information regarding the transmission of the communication; and (B) any visual depictions, data, or other digital files contained in, or attached to, the communication. (c) Forwarding of Report to Law Enforcement.—Pursuant to its clearinghouse role as a private, nonprofit organization, and at the conclusion of its review in furtherance of its nonprofit mission, NCMEC shall make available each report made under subsection (a)(1) to one or more of the following law enforcement agencies: (1) Any Federal law enforcement agency that is involved in the investigation of child sexual exploitation, kidnapping, or enticement crimes. (2) Any State or local law enforcement agency that is involved in the investigation of child sexual exploitation. (3) A foreign law enforcement agency designated by the Attorney General under subsection (d)(3) or a foreign law enforcement agency that has an established relationship with the Federal Bureau of Investigation, Immigration and Customs Enforcement, or INTERPOL, and is involved in the investigation of child sexual exploitation, kidnapping, or enticement crimes. (d) Attorney General Responsibilities.— (1) In general.— The Attorney General shall enforce this section. (2) Designation of federal agencies.— The Attorney General may designate a Federal law enforcement agency or agencies to which a report shall be forwarded under subsection (c)(1). (3) Designation of foreign agencies.—The Attorney General may— (A) in consultation with the Secretary of State, designate foreign law enforcement agencies to which a report may be forwarded under subsection (c)(3); (B) establish the conditions under which such a report may be forwarded to such agencies; and (C) develop a process for foreign law enforcement agencies to request assistance from Federal law enforcement agencies in obtaining evidence related to a report referred under subsection (c)(3). (4) Reporting designated foreign agencies.— The Attorney General may maintain and make available to the Department of State, NCMEC, providers, the Committee on the Judiciary of the Senate, and the Committee on the Judiciary of the House of Representatives a list of the foreign law enforcement agencies designated under paragraph (3). (5) Notification to providers.— (A) In general.—NCMEC may notify a provider of the information described in subparagraph (B), if— (i) a provider notifies NCMEC that the provider is making a report under this section as the result of a request by a foreign law enforcement agency; and (ii) NCMEC forwards the report described in clause (i) to— (I) the requesting foreign law enforcement agency; or (II) another agency in the same country designated by the Attorney General under paragraph (3) or that has an established relationship with the Federal Bureau of Investigation, U.S. Immigration and Customs Enforcement, or INTERPOL and is involved in the investigation of child sexual exploitation, kidnapping, or enticement crimes. (B) Information described.—The information described in this subparagraph is— (i) the identity of the foreign law enforcement agency to which the report was forwarded; and (ii) the date on which the report was forwarded. (C) Notification of inability to forward report.— If a provider notifies NCMEC that the provider is making a report under this section as the result of a request by a foreign law enforcement agency and NCMEC is unable to forward the report as described in subparagraph (A)(ii), NCMEC shall notify the provider that NCMEC was unable to forward the report. (e) Failure To Report.—A provider that knowingly and willfully fails to make a report required under subsection (a)(1) shall be fined— (1) in the case of an initial knowing and willful failure to make a report, not more than $850,000 in the case of a provider with not less than 100,000,000 monthly active users or $600,000 in the case of a provider with less than 100,000,000 monthly active users; and (2) in the case of any second or subsequent knowing and willful failure to make a report, not more than $1,000,000 in the case of a provider with not less than 100,000,000 monthly active users or $850,000 in the case of a provider with less than 100,000,000 monthly active users. (f) Protection of Privacy.—Nothing in this section shall be construed to require a provider to— (1) monitor any user, subscriber, or customer of that provider; (2) monitor the content of any communication of any person described in paragraph (1); or (3) affirmatively search, screen, or scan for facts or circumstances described in sections (a) and (b). (g) Conditions of Disclosure Information Contained Within Report.— (1) In general.— Except as provided in paragraph (2), a law enforcement agency that receives a report under subsection (c) shall not disclose any information contained in that report. (2) Permitted disclosures by law enforcement.— (A) In general.—A law enforcement agency may disclose information in a report received under subsection (c)— (i) to an attorney for the government for use in the performance of the official duties of that attorney; (ii) to such officers and employees of that law enforcement agency, as may be necessary in the performance of their investigative and recordkeeping functions; (iii) to such other government personnel (including personnel of a State or subdivision of a State) as are determined to be necessary by an attorney for the government to assist the attorney in the performance of the official duties of the attorney in enforcing Federal criminal law; (iv) if the report discloses a violation of State criminal law, to an appropriate official of a State or subdivision of a State for the purpose of enforcing such State law; (v) to a defendant in a criminal case or the attorney for that defendant, subject to the terms and limitations under section 3509(m) or a similar State law, to the extent the information relates to a criminal charge pending against that defendant; (vi) subject to subparagraph (B), to a provider if necessary to facilitate response to legal process issued in connection to a criminal investigation, prosecution, or post-conviction remedy relating to that report; and (vii) as ordered by a court upon a showing of good cause and pursuant to any protective orders or other conditions that the court may impose. (B) Limitation.— Nothing in subparagraph (A)(vi) authorizes a law enforcement agency to provide visual depictions of apparent child pornography to a provider. (3) Permitted disclosures by NCMEC.—NCMEC may disclose by mail, electronic transmission, or other reasonable means, information received in a report under subsection (a) only to— (A) any Federal law enforcement agency designated by the Attorney General under subsection (d)(2) or that is involved in the investigation of child sexual exploitation, kidnapping, or enticement crimes; (B) any State, local, or tribal law enforcement agency involved in the investigation of child sexual exploitation, kidnapping, or enticement crimes; (C) any foreign law enforcement agency designated by the Attorney General under subsection (d)(3) or that has an established relationship with the Federal Bureau of Investigation, Immigration and Customs Enforcement, or INTERPOL, and is involved in the investigation of child sexual exploitation, kidnapping, or enticement crimes; (D) a provider as described in section 2258C; and (E) respond to legal process, as necessary. (4) Permitted disclosure by a provider.— A provider that submits a report under subsection (a)(1) may disclose by mail, electronic transmission, or other reasonable means, information, including visual depictions contained in the report, in a manner consistent with permitted disclosures under paragraphs (3) through (8) of section 2702(b) only to a law enforcement agency described in subparagraph (A), (B), or (C) of paragraph (3), to NCMEC, or as necessary to respond to legal process. (h) Preservation.— (1) In general.— For the purposes of this section, a completed submission by a provider of a report to the CyberTipline under subsection (a)(1) shall be treated as a request to preserve the contents provided in the report for 1 year after the submission to the CyberTipline. (2) Preservation of commingled content.— Pursuant to paragraph (1), a provider shall preserve any visual depictions, data, or other digital files that are reasonably accessible and may provide context or additional information about the reported material or person. (3) Protection of preserved materials.— A provider preserving materials under this section shall maintain the materials in a secure location and take appropriate steps to limit access by agents or employees of the service to the materials to that access necessary to comply with the requirements of this subsection. (4) Authorities and duties not affected.— Nothing in this section shall be construed as replacing, amending, or otherwise interfering with the authorities and duties under section 2703. (5) Extension of preservation.— A provider of a report to the CyberTipline under subsection (a)(1) may voluntarily preserve the contents provided in the report (including any comingled content described in paragraph (2)) for longer than 1 year after the submission to the CyberTipline for the purpose of reducing the proliferation of online child sexual exploitation or preventing the online sexual exploitation of children. (6) Method of preservation.— Not later than 1 year after the date of enactment of this paragraph, a provider of a report to the CyberTipline under subsection (a)(1) shall preserve materials under this subsection in a manner that is consistent with the most recent version of the Cybersecurity Framework developed by the National Institute of Standards and Technology, or any successor thereto. (Added Pub. L. 110–401, title V,  501(a), Oct. 13, 2008, 122 Stat. 4243; amended Pub. L. 115–395,  2, Dec. 21, 2018, 132 Stat. 5287; Pub. L. 118–59,  3, 4(a), May 7, 2024, 138 Stat. 1016.) [1] So in original. Probably should be followed by “section”. Editorial Notes References in Text The date of enactment of this paragraph, referred to in subsec. (h)(6), is the date of enactment of Pub. L. 118–59, which was approved May 7, 2024. Amendments 2024—Subsec. (a)(2)(A). Pub. L. 118–59,  4(a)(1), inserted “, of section 1591 (if the violation involves a minor), or of 2422(b)” after “child pornography”. Subsec. (e)(1). Pub. L. 118–59,  4(a)(2)(A), substituted “$850,000 in the case of a provider with not less than 100,000,000 monthly active users or $600,000 in the case of a provider with less than 100,000,000 monthly active users” for “$150,000”. Subsec. (e)(2). Pub. L. 118–59,  4(a)(2)(B), substituted “$1,000,000 in the case of a provider with not less than 100,000,000 monthly active users or $850,000 in the case of a provider with less than 100,000,000 monthly active users” for “$300,000”. Subsec. (h)(1). Pub. L. 118–59,  3(1), substituted “1 year” for “90 days”. Subsec. (h)(5), (6). Pub. L. 118–59,  3(2), added pars. (5) and (6). 2018—Pub. L. 115–395,  2(1), substituted “providers” for “electronic communication service providers and remote computing service providers” in section catchline. Subsec. (a)(1). Pub. L. 115–395,  2(2)(A), amended par. (1) generally. Prior to amendment, par. (1) related to general reporting duty of electronic communication service providers. Subsec. (a)(2). Pub. L. 115–395,  2(2)(B), amended par. (2) generally. Prior to amendment, par. (2) described facts or circumstances of apparent violations requiring report. Subsec. (b). Pub. L. 115–395,  2(3)(A), in introductory provisions, substituted “In an effort to prevent the future sexual victimization of children, and to the extent the information is within the custody or control of a provider, the facts and circumstances included in each report under subsection (a)(1) may, at the sole discretion of the provider, include” for “To the extent the information is within the custody or control of an electronic communication service provider or a remote computing service provider, the facts and circumstances included in each report under subsection (a)(1) may include”. Subsec. (b)(1). Pub. L. 115–395,  2(3)(B), inserted “or plans to violate” after “who appears to have violated” and “payment information (excluding personally identifiable information),” after “uniform resource locator,”. Subsec. (b)(2). Pub. L. 115–395,  2(3)(C), substituted “a provider uploaded, transmitted, or received content relating to the report or when and how content relating to the report was reported to, or discovered by the provider” for “an electronic communication service or a remote computing service uploaded, transmitted, or received apparent child pornography or when and how apparent child pornography was reported to, or discovered by the electronic communication service provider or remote computing service provider”. Subsec. (b)(3). Pub. L. 115–395,  2(3)(D), amended par. (3) generally. Prior to amendment, text read as follows: “(A) In general.—Information relating to the geographic location of the involved individual or website, which may include the Internet Protocol address or verified billing address, or, if not reasonably available, at least 1 form of geographic identifying information, including area code or zip code. “(B) Inclusion.—The information described in subparagraph (A) may also include any geographic information provided to the electronic communication service or remote computing service by the customer or subscriber.” Subsec. (b)(4). Pub. L. 115–395,  2(3)(E), in heading, substituted “Visual depictions” for “Images” and, in text, substituted “visual depiction” for “image” and inserted “or other content” after “apparent child pornography”. Subsec. (b)(5). Pub. L. 115–395,  2(3)(F), substituted “visual depiction” for “image” and inserted “or other content” after “apparent child pornography” in introductory provisions and substituted “visual depictions” for “images” in subpar. (B). Subsec. (c). Pub. L. 115–395,  2(4), amended subsec. (c) generally. Prior to amendment, subsec. (c) related to forwarding of reports to domestic and foreign law enforcement agencies. Subsec. (d)(2). Pub. L. 115–395,  2(5)(A), substituted “may designate a” for “shall designate promptly the”. Subsec. (d)(3). Pub. L. 115–395,  2(5)(B), substituted “may” for “shall promptly” in introductory provisions and “designate” for “designate the” in subpar. (A). Subsec. (d)(4). Pub. L. 115–395,  2(5)(C), substituted “may” for “shall”, “NCMEC” for “the National Center for Missing and Exploited Children”, and “providers” for “electronic communication service providers, remote computing service providers”. Subsec. (d)(5). Pub. L. 115–395,  2(5)(E), (F), redesignated par. (6) as (5) and amended it generally. Prior to amendment, par. related to contents of Center’s notification to providers of report forwarded at request of foreign law enforcement agency. Pub. L. 115–395,  2(5)(D), struck out par. (5). Text read as follows: “It is the sense of Congress that— “(A) combating the international manufacturing, possession, and trade in online child pornography requires cooperation with competent, qualified, and appropriately trained foreign law enforcement agencies; and “(B) the Attorney General, in cooperation with the Secretary of State, should make a substantial effort to expand the list of foreign agencies designated under paragraph (3).” Subsec. (d)(6). Pub. L. 115–395,  2(5)(E), redesignated par. (6) as (5). Subsec. (e). Pub. L. 115–395,  2(6), substituted “A provider” for “An electronic communication service provider or remote computing service provider”. Subsec. (f). Pub. L. 115–395,  2(7)(A), substituted “a provider” for “an electronic communication service provider or a remote computing service provider” in introductory provisions. Subsec. (f)(3). Pub. L. 115–395,  2(7)(B), substituted “search, screen, or scan for” for “seek”. Subsec. (g)(2)(A)(vi). Pub. L. 115–395,  2(8)(A)(i), which directed substitution of “a provider” for “an electronic communication service provider or remote computing service provider”, was executed by making the substitution for “an electronic communication service provider or remote computing provider”, to reflect the probable intent of Congress. Subsec. (g)(2)(B). Pub. L. 115–395,  2(8)(A)(ii), amended subpar. (B) generally. Prior to amendment, text read as follows: “(i) Limitations on further disclosure.—The electronic communication service provider or remote computing service provider shall be prohibited from disclosing the contents of a report provided under subparagraph (A)(vi) to any person, except as necessary to respond to the legal process. “(ii) Effect.—Nothing in subparagraph (A)(vi) authorizes a law enforcement agency to provide child pornography images to an electronic communications service provider or a remote computing service.” Subsec. (g)(3). Pub. L. 115–395,  2(8)(B)(i), (ii), in heading, substituted “NCMEC” for “the national center for missing and exploited children” and, in introductory provisions, substituted “NCMEC may disclose by mail, electronic transmission, or other reasonable means, information received in a report under subsection (a) only to” for “The National Center for Missing and Exploited Children may disclose information received in a report under subsection (a) only”. Subsec. (g)(3)(A). Pub. L. 115–395,  2(8)(B)(iii), substituted “any Federal law enforcement agency” for “to any Federal law enforcement agency” and inserted “or that is involved in the investigation of child sexual exploitation, kidnapping, or enticement crimes” before semicolon at end. Subsec. (g)(3)(B). Pub. L. 115–395,  2(8)(B)(iv), substituted “any State” for “to any State” and “child sexual exploitation” for “child pornography, child exploitation”. Subsec. (g)(3)(C). Pub. L. 115–395,  2(8)(B)(v), substituted “any foreign law enforcement agency” for “to any foreign law enforcement agency” and “or that has an established relationship with the Federal Bureau of Investigation, Immigration and Customs Enforcement, or INTERPOL, and is involved in the investigation of child sexual exploitation, kidnapping, or enticement crimes;” for “; and”. Subsec. (g)(3)(D). Pub. L. 115–395,  2(8)(B)(vi), substituted “a provider” for “an electronic communication service provider or remote computing service provider” and “; and” for period at end. Subsec. (g)(3)(E). Pub. L. 115–395,  2(8)(B)(vii), added subpar. (E). Subsec. (g)(4). Pub. L. 115–395,  2(8)(C), added par. (4). Subsec. (h)(1). Pub. L. 115–395,  2(9)(A), substituted “a completed submission by a provider of a report to the CyberTipline under subsection (a)(1) shall be treated as a request to preserve the contents provided in the report for 90 days after the submission to the CyberTipline” for “the notification to an electronic communication service provider or a remote computing service provider by the CyberTipline of receipt of a report under subsection (a)(1) shall be treated as a request to preserve, as if such request was made pursuant to section 2703(f)”. Subsec. (h)(2). Pub. L. 115–395,  2(9)(D), in heading, substituted “content” for “images” and, in text, substituted “a provider” for “an electronic communication service provider or a remote computing service”, “visual depictions” for “images”, and “reasonably accessible and may provide context or additional information about the reported material or person” for “commingled or interspersed among the images of apparent child pornography within a particular communication or user-created folder or directory”. Final substitution, which directed striking out text containing “user created”, was executed instead to text which contained “user-created”, to reflect the probable intent of Congress. Pub. L. 115–395,  2(9)(B), (C), redesignated par. (3) as (2) and struck out former par. (2). Prior to amendment, text of par. (2) read as follows: “Pursuant to paragraph (1), an electronic communication service provider or a remote computing service shall preserve the contents of the report provided pursuant to subsection (b) for 90 days after such notification by the CyberTipline.” Subsec. (h)(3). Pub. L. 115–395,  2(9)(E), which directed substitution of “A provider” for “An electronic communication service or remote computing service”, was executed by making the substitution for “An electronic communications service or remote computing service”, to reflect the probable intent of Congress. Pub. L. 115–395,  2(9)(C), redesignated par. (4) as (3). Former par. (3) redesignated (2). Subsec. (h)(4), (5). Pub. L. 115–395,  2(9)(C), redesignated pars. (4) and (5) as (3) and (4), respectively. Statutory Notes and Related Subsidiaries Guidelines Pub. L. 118–59,  4(b), May 7, 2024, 138 Stat. 1017, provided that: “Not later than 180 days after the date of enactment of this Act [May 7, 2024], the National Center for Missing & Exploited Children may issue guidelines, as appropriate, to providers required or permitted to take actions described in section 2258A(a)(1)(B) of title 18, United States Code, on the relevant identifiers for content that may indicate sex trafficking of children, as described in section 1591 of that title, or enticement, as described in section 2422(b) of that title.” Quick search by citation: Title Section Go! 18 U.S. Code  2258A - Reporting requirements of providers U.S. Code Notes prev | next (a) Duty To Report.— (1) In general.— (A) Duty.—In order to reduce the proliferation of online child sexual exploitation and to prevent the online sexual exploitation of children, a provider— (i) shall, as soon as reasonably possible after obtaining actual knowledge of any facts or circumstances described in paragraph (2)(A), take the actions described in subparagraph (B); and (ii) may, after obtaining actual knowledge of any facts or circumstances described in paragraph (2)(B), take the actions described in subparagraph (B). (B) Actions described.—The actions described in this subparagraph are— (i) providing to the CyberTipline of NCMEC, or any successor to the CyberTipline operated by NCMEC, the mailing address, telephone number, facsimile number, electronic mailing address of, and individual point of contact for, such provider; and (ii) making a report of such facts or circumstances to the CyberTipline, or any successor to the CyberTipline operated by NCMEC. (2) Facts or circumstances.— (A) Apparent violations.— The facts or circumstances described in this subparagraph are any facts or circumstances from which there is an apparent violation of section 2251, 2251A, 2252, 2252A, 2252B, or 2260 that involves child pornography, of section 1591 (if the violation involves a minor), or of [1] 2422(b). (B) Imminent violations.— The facts or circumstances described in this subparagraph are any facts or circumstances which indicate a violation of any of the sections described in subparagraph (A) involving child pornography may be planned or imminent. (b) Contents of Report.—In an effort to prevent the future sexual victimization of children, and to the extent the information is within the custody or control of a provider, the facts and circumstances included in each report under subsection (a)(1) may, at the sole discretion of the provider, include the following information: (1) Information about the involved individual.— Information relating to the identity of any individual who appears to have violated or plans to violate a Federal law described in subsection (a)(2), which may, to the extent reasonably practicable, include the electronic mail address, Internet Protocol address, uniform resource locator, payment information (excluding personally identifiable information), or any other identifying information, including self-reported identifying information. (2) Historical reference.— Information relating to when and how a customer or subscriber of a provider uploaded, transmitted, or received content relating to the report or when and how content relating to the report was reported to, or discovered by the provider, including a date and time stamp and time zone. (3) Geographic location information.— Information relating to the geographic location of the involved individual or website, which may include the Internet Protocol address or verified address, or, if not reasonably available, at least one form of geographic identifying information, including area code or zip code, provided by the customer or subscriber, or stored or obtained by the provider. (4) Visual depictions of apparent child pornography.— Any visual depiction of apparent child pornography or other content relating to the incident such report is regarding. (5) Complete communication.—The complete communication containing any visual depiction of apparent child pornography or other content, including— (A) any data or information regarding the transmission of the communication; and (B) any visual depictions, data, or other digital files contained in, or attached to, the communication. (c) Forwarding of Report to Law Enforcement.—Pursuant to its clearinghouse role as a private, nonprofit organization, and at the conclusion of its review in furtherance of its nonprofit mission, NCMEC shall make available each report made under subsection (a)(1) to one or more of the following law enforcement agencies: (1) Any Federal law enforcement agency that is involved in the investigation of child sexual exploitation, kidnapping, or enticement crimes. (2) Any State or local law enforcement agency that is involved in the investigation of child sexual exploitation. (3) A foreign law enforcement agency designated by the Attorney General under subsection (d)(3) or a foreign law enforcement agency that has an established relationship with the Federal Bureau of Investigation, Immigration and Customs Enforcement, or INTERPOL, and is involved in the investigation of child sexual exploitation, kidnapping, or enticement crimes. (d) Attorney General Responsibilities.— (1) In general.— The Attorney General shall enforce this section. (2) Designation of federal agencies.— The Attorney General may designate a Federal law enforcement agency or agencies to which a report shall be forwarded under subsection (c)(1). (3) Designation of foreign agencies.—The Attorney General may— (A) in consultation with the Secretary of State, designate foreign law enforcement agencies to which a report may be forwarded under subsection (c)(3); (B) establish the conditions under which such a report may be forwarded to such agencies; and (C) develop a process for foreign law enforcement agencies to request assistance from Federal law enforcement agencies in obtaining evidence related to a report referred under subsection (c)(3). (4) Reporting designated foreign agencies.— The Attorney General may maintain and make available to the Department of State, NCMEC, providers, the Committee on the Judiciary of the Senate, and the Committee on the Judiciary of the House of Representatives a list of the foreign law enforcement agencies designated under paragraph (3). (5) Notification to providers.— (A) In general.—NCMEC may notify a provider of the information described in subparagraph (B), if— (i) a provider notifies NCMEC that the provider is making a report under this section as the result of a request by a foreign law enforcement agency; and (ii) NCMEC forwards the report described in clause (i) to— (I) the requesting foreign law enforcement agency; or (II) another agency in the same country designated by the Attorney General under paragraph (3) or that has an established relationship with the Federal Bureau of Investigation, U.S. Immigration and Customs Enforcement, or INTERPOL and is involved in the investigation of child sexual exploitation, kidnapping, or enticement crimes. (B) Information described.—The information described in this subparagraph is— (i) the identity of the foreign law enforcement agency to which the report was forwarded; and (ii) the date on which the report was forwarded. (C) Notification of inability to forward report.— If a provider notifies NCMEC that the provider is making a report under this section as the result of a request by a foreign law enforcement agency and NCMEC is unable to forward the report as described in subparagraph (A)(ii), NCMEC shall notify the provider that NCMEC was unable to forward the report. (e) Failure To Report.—A provider that knowingly and willfully fails to make a report required under subsection (a)(1) shall be fined— (1) in the case of an initial knowing and willful failure to make a report, not more than $850,000 in the case of a provider with not less than 100,000,000 monthly active users or $600,000 in the case of a provider with less than 100,000,000 monthly active users; and (2) in the case of any second or subsequent knowing and willful failure to make a report, not more than $1,000,000 in the case of a provider with not less than 100,000,000 monthly active users or $850,000 in the case of a provider with less than 100,000,000 monthly active users. (f) Protection of Privacy.—Nothing in this section shall be construed to require a provider to— (1) monitor any user, subscriber, or customer of that provider; (2) monitor the content of any communication of any person described in paragraph (1); or (3) affirmatively search, screen, or scan for facts or circumstances described in sections (a) and (b). (g) Conditions of Disclosure Information Contained Within Report.— (1) In general.— Except as provided in paragraph (2), a law enforcement agency that receives a report under subsection (c) shall not disclose any information contained in that report. (2) Permitted disclosures by law enforcement.— (A) In general.—A law enforcement agency may disclose information in a report received under subsection (c)— (i) to an attorney for the government for use in the performance of the official duties of that attorney; (ii) to such officers and employees of that law enforcement agency, as may be necessary in the performance of their investigative and recordkeeping functions; (iii) to such other government personnel (including personnel of a State or subdivision of a State) as are determined to be necessary by an attorney for the government to assist the attorney in the performance of the official duties of the attorney in enforcing Federal criminal law; (iv) if the report discloses a violation of State criminal law, to an appropriate official of a State or subdivision of a State for the purpose of enforcing such State law; (v) to a defendant in a criminal case or the attorney for that defendant, subject to the terms and limitations under section 3509(m) or a similar State law, to the extent the information relates to a criminal charge pending against that defendant; (vi) subject to subparagraph (B), to a provider if necessary to facilitate response to legal process issued in connection to a criminal investigation, prosecution, or post-conviction remedy relating to that report; and (vii) as ordered by a court upon a showing of good cause and pursuant to any protective orders or other conditions that the court may impose. (B) Limitation.— Nothing in subparagraph (A)(vi) authorizes a law enforcement agency to provide visual depictions of apparent child pornography to a provider. (3) Permitted disclosures by NCMEC.—NCMEC may disclose by mail, electronic transmission, or other reasonable means, information received in a report under subsection (a) only to— (A) any Federal law enforcement agency designated by the Attorney General under subsection (d)(2) or that is involved in the investigation of child sexual exploitation, kidnapping, or enticement crimes; (B) any State, local, or tribal law enforcement agency involved in the investigation of child sexual exploitation, kidnapping, or enticement crimes; (C) any foreign law enforcement agency designated by the Attorney General under subsection (d)(3) or that has an established relationship with the Federal Bureau of Investigation, Immigration and Customs Enforcement, or INTERPOL, and is involved in the investigation of child sexual exploitation, kidnapping, or enticement crimes; (D) a provider as described in section 2258C; and (E) respond to legal process, as necessary. (4) Permitted disclosure by a provider.— A provider that submits a report under subsection (a)(1) may disclose by mail, electronic transmission, or other reasonable means, information, including visual depictions contained in the report, in a manner consistent with permitted disclosures under paragraphs (3) through (8) of section 2702(b) only to a law enforcement agency described in subparagraph (A), (B), or (C) of paragraph (3), to NCMEC, or as necessary to respond to legal process. (h) Preservation.— (1) In general.— For the purposes of this section, a completed submission by a provider of a report to the CyberTipline under subsection (a)(1) shall be treated as a request to preserve the contents provided in the report for 1 year after the submission to the CyberTipline. (2) Preservation of commingled content.— Pursuant to paragraph (1), a provider shall preserve any visual depictions, data, or other digital files that are reasonably accessible and may provide context or additional information about the reported material or person. (3) Protection of preserved materials.— A provider preserving materials under this section shall maintain the materials in a secure location and take appropriate steps to limit access by agents or employees of the service to the materials to that access necessary to comply with the requirements of this subsection. (4) Authorities and duties not affected.— Nothing in this section shall be construed as replacing, amending, or otherwise interfering with the authorities and duties under section 2703. (5) Extension of preservation.— A provider of a report to the CyberTipline under subsection (a)(1) may voluntarily preserve the contents provided in the report (including any comingled content described in paragraph (2)) for longer than 1 year after the submission to the CyberTipline for the purpose of reducing the proliferation of online child sexual exploitation or preventing the online sexual exploitation of children. (6) Method of preservation.— Not later than 1 year after the date of enactment of this paragraph, a provider of a report to the CyberTipline under subsection (a)(1) shall preserve materials under this subsection in a manner that is consistent with the most recent version of the Cybersecurity Framework developed by the National Institute of Standards and Technology, or any successor thereto. (Added Pub. L. 110–401, title V,  501(a), Oct. 13, 2008, 122 Stat. 4243; amended Pub. L. 115–395,  2, Dec. 21, 2018, 132 Stat. 5287; Pub. L. 118–59,  3, 4(a), May 7, 2024, 138 Stat. 1016.) [1] So in original. Probably should be followed by “section”. Editorial Notes References in Text The date of enactment of this paragraph, referred to in subsec. (h)(6), is the date of enactment of Pub. L. 118–59, which was approved May 7, 2024. Amendments 2024—Subsec. (a)(2)(A). Pub. L. 118–59,  4(a)(1), inserted “, of section 1591 (if the violation involves a minor), or of 2422(b)” after “child pornography”. Subsec. (e)(1). Pub. L. 118–59,  4(a)(2)(A), substituted “$850,000 in the case of a provider with not less than 100,000,000 monthly active users or $600,000 in the case of a provider with less than 100,000,000 monthly active users” for “$150,000”. Subsec. (e)(2). Pub. L. 118–59,  4(a)(2)(B), substituted “$1,000,000 in the case of a provider with not less than 100,000,000 monthly active users or $850,000 in the case of a provider with less than 100,000,000 monthly active users” for “$300,000”. Subsec. (h)(1). Pub. L. 118–59,  3(1), substituted “1 year” for “90 days”. Subsec. (h)(5), (6). Pub. L. 118–59,  3(2), added pars. (5) and (6). 2018—Pub. L. 115–395,  2(1), substituted “providers” for “electronic communication service providers and remote computing service providers” in section catchline. Subsec. (a)(1). Pub. L. 115–395,  2(2)(A), amended par. (1) generally. Prior to amendment, par. (1) related to general reporting duty of electronic communication service providers. Subsec. (a)(2). Pub. L. 115–395,  2(2)(B), amended par. (2) generally. Prior to amendment, par. (2) described facts or circumstances of apparent violations requiring report. Subsec. (b). Pub. L. 115–395,  2(3)(A), in introductory provisions, substituted “In an effort to prevent the future sexual victimization of children, and to the extent the information is within the custody or control of a provider, the facts and circumstances included in each report under subsection (a)(1) may, at the sole discretion of the provider, include” for “To the extent the information is within the custody or control of an electronic communication service provider or a remote computing service provider, the facts and circumstances included in each report under subsection (a)(1) may include”. Subsec. (b)(1). Pub. L. 115–395,  2(3)(B), inserted “or plans to violate” after “who appears to have violated” and “payment information (excluding personally identifiable information),” after “uniform resource locator,”. Subsec. (b)(2). Pub. L. 115–395,  2(3)(C), substituted “a provider uploaded, transmitted, or received content relating to the report or when and how content relating to the report was reported to, or discovered by the provider” for “an electronic communication service or a remote computing service uploaded, transmitted, or received apparent child pornography or when and how apparent child pornography was reported to, or discovered by the electronic communication service provider or remote computing service provider”. Subsec. (b)(3). Pub. L. 115–395,  2(3)(D), amended par. (3) generally. Prior to amendment, text read as follows: “(A) In general.—Information relating to the geographic location of the involved individual or website, which may include the Internet Protocol address or verified billing address, or, if not reasonably available, at least 1 form of geographic identifying information, including area code or zip code. “(B) Inclusion.—The information described in subparagraph (A) may also include any geographic information provided to the electronic communication service or remote computing service by the customer or subscriber.” Subsec. (b)(4). Pub. L. 115–395,  2(3)(E), in heading, substituted “Visual depictions” for “Images” and, in text, substituted “visual depiction” for “image” and inserted “or other content” after “apparent child pornography”. Subsec. (b)(5). Pub. L. 115–395,  2(3)(F), substituted “visual depiction” for “image” and inserted “or other content” after “apparent child pornography” in introductory provisions and substituted “visual depictions” for “images” in subpar. (B). Subsec. (c). Pub. L. 115–395,  2(4), amended subsec. (c) generally. Prior to amendment, subsec. (c) related to forwarding of reports to domestic and foreign law enforcement agencies. Subsec. (d)(2). Pub. L. 115–395,  2(5)(A), substituted “may designate a” for “shall designate promptly the”. Subsec. (d)(3). Pub. L. 115–395,  2(5)(B), substituted “may” for “shall promptly” in introductory provisions and “designate” for “designate the” in subpar. (A). Subsec. (d)(4). Pub. L. 115–395,  2(5)(C), substituted “may” for “shall”, “NCMEC” for “the National Center for Missing and Exploited Children”, and “providers” for “electronic communication service providers, remote computing service providers”. Subsec. (d)(5). Pub. L. 115–395,  2(5)(E), (F), redesignated par. (6) as (5) and amended it generally. Prior to amendment, par. related to contents of Center’s notification to providers of report forwarded at request of foreign law enforcement agency. Pub. L. 115–395,  2(5)(D), struck out par. (5). Text read as follows: “It is the sense of Congress that— “(A) combating the international manufacturing, possession, and trade in online child pornography requires cooperation with competent, qualified, and appropriately trained foreign law enforcement agencies; and “(B) the Attorney General, in cooperation with the Secretary of State, should make a substantial effort to expand the list of foreign agencies designated under paragraph (3).” Subsec. (d)(6). Pub. L. 115–395,  2(5)(E), redesignated par. (6) as (5). Subsec. (e). Pub. L. 115–395,  2(6), substituted “A provider” for “An electronic communication service provider or remote computing service provider”. Subsec. (f). Pub. L. 115–395,  2(7)(A), substituted “a provider” for “an electronic communication service provider or a remote computing service provider” in introductory provisions. Subsec. (f)(3). Pub. L. 115–395,  2(7)(B), substituted “search, screen, or scan for” for “seek”. Subsec. (g)(2)(A)(vi). Pub. L. 115–395,  2(8)(A)(i), which directed substitution of “a provider” for “an electronic communication service provider or remote computing service provider”, was executed by making the substitution for “an electronic communication service provider or remote computing provider”, to reflect the probable intent of Congress. Subsec. (g)(2)(B). Pub. L. 115–395,  2(8)(A)(ii), amended subpar. (B) generally. Prior to amendment, text read as follows: “(i) Limitations on further disclosure.—The electronic communication service provider or remote computing service provider shall be prohibited from disclosing the contents of a report provided under subparagraph (A)(vi) to any person, except as necessary to respond to the legal process. “(ii) Effect.—Nothing in subparagraph (A)(vi) authorizes a law enforcement agency to provide child pornography images to an electronic communications service provider or a remote computing service.” Subsec. (g)(3). Pub. L. 115–395,  2(8)(B)(i), (ii), in heading, substituted “NCMEC” for “the national center for missing and exploited children” and, in introductory provisions, substituted “NCMEC may disclose by mail, electronic transmission, or other reasonable means, information received in a report under subsection (a) only to” for “The National Center for Missing and Exploited Children may disclose information received in a report under subsection (a) only”. Subsec. (g)(3)(A). Pub. L. 115–395,  2(8)(B)(iii), substituted “any Federal law enforcement agency” for “to any Federal law enforcement agency” and inserted “or that is involved in the investigation of child sexual exploitation, kidnapping, or enticement crimes” before semicolon at end. Subsec. (g)(3)(B). Pub. L. 115–395,  2(8)(B)(iv), substituted “any State” for “to any State” and “child sexual exploitation” for “child pornography, child exploitation”. Subsec. (g)(3)(C). Pub. L. 115–395,  2(8)(B)(v), substituted “any foreign law enforcement agency” for “to any foreign law enforcement agency” and “or that has an established relationship with the Federal Bureau of Investigation, Immigration and Customs Enforcement, or INTERPOL, and is involved in the investigation of child sexual exploitation, kidnapping, or enticement crimes;” for “; and”. Subsec. (g)(3)(D). Pub. L. 115–395,  2(8)(B)(vi), substituted “a provider” for “an electronic communication service provider or remote computing service provider” and “; and” for period at end. Subsec. (g)(3)(E). Pub. L. 115–395,  2(8)(B)(vii), added subpar. (E). Subsec. (g)(4). Pub. L. 115–395,  2(8)(C), added par. (4). Subsec. (h)(1). Pub. L. 115–395,  2(9)(A), substituted “a completed submission by a provider of a report to the CyberTipline under subsection (a)(1) shall be treated as a request to preserve the contents provided in the report for 90 days after the submission to the CyberTipline” for “the notification to an electronic communication service provider or a remote computing service provider by the CyberTipline of receipt of a report under subsection (a)(1) shall be treated as a request to preserve, as if such request was made pursuant to section 2703(f)”. Subsec. (h)(2). Pub. L. 115–395,  2(9)(D), in heading, substituted “content” for “images” and, in text, substituted “a provider” for “an electronic communication service provider or a remote computing service”, “visual depictions” for “images”, and “reasonably accessible and may provide context or additional information about the reported material or person” for “commingled or interspersed among the images of apparent child pornography within a particular communication or user-created folder or directory”. Final substitution, which directed striking out text containing “user created”, was executed instead to text which contained “user-created”, to reflect the probable intent of Congress. Pub. L. 115–395,  2(9)(B), (C), redesignated par. (3) as (2) and struck out former par. (2). Prior to amendment, text of par. (2) read as follows: “Pursuant to paragraph (1), an electronic communication service provider or a remote computing service shall preserve the contents of the report provided pursuant to subsection (b) for 90 days after such notification by the CyberTipline.” Subsec. (h)(3). Pub. L. 115–395,  2(9)(E), which directed substitution of “A provider” for “An electronic communication service or remote computing service”, was executed by making the substitution for “An electronic communications service or remote computing service”, to reflect the probable intent of Congress. Pub. L. 115–395,  2(9)(C), redesignated par. (4) as (3). Former par. (3) redesignated (2). Subsec. (h)(4), (5). Pub. L. 115–395,  2(9)(C), redesignated pars. (4) and (5) as (3) and (4), respectively. Statutory Notes and Related Subsidiaries Guidelines Pub. L. 118–59,  4(b), May 7, 2024, 138 Stat. 1017, provided that: “Not later than 180 days after the date of enactment of this Act [May 7, 2024], the National Center for Missing & Exploited Children may issue guidelines, as appropriate, to providers required or permitted to take actions described in section 2258A(a)(1)(B) of title 18, United States Code, on the relevant identifiers for content that may indicate sex trafficking of children, as described in section 1591 of that title, or enticement, as described in section 2422(b) of that title.” Quick search by citation: Title Section Go! 18 U.S. Code  2258A - Reporting requirements of providers U.S. Code Notes prev | next (a) Duty To Report.— (1) In general.— (A) Duty.—In order to reduce the proliferation of online child sexual exploitation and to prevent the online sexual exploitation of children, a provider— (i) shall, as soon as reasonably possible after obtaining actual knowledge of any facts or circumstances described in paragraph (2)(A), take the actions described in subparagraph (B); and (ii) may, after obtaining actual knowledge of any facts or circumstances described in paragraph (2)(B), take the actions described in subparagraph (B). (B) Actions described.—The actions described in this subparagraph are— (i) providing to the CyberTipline of NCMEC, or any successor to the CyberTipline operated by NCMEC, the mailing address, telephone number, facsimile number, electronic mailing address of, and individual point of contact for, such provider; and (ii) making a report of such facts or circumstances to the CyberTipline, or any successor to the CyberTipline operated by NCMEC. (2) Facts or circumstances.— (A) Apparent violations.— The facts or circumstances described in this subparagraph are any facts or circumstances from which there is an apparent violation of section 2251, 2251A, 2252, 2252A, 2252B, or 2260 that involves child pornography, of section 1591 (if the violation involves a minor), or of [1] 2422(b). (B) Imminent violations.— The facts or circumstances described in this subparagraph are any facts or circumstances which indicate a violation of any of the sections described in subparagraph (A) involving child pornography may be planned or imminent. (b) Contents of Report.—In an effort to prevent the future sexual victimization of children, and to the extent the information is within the custody or control of a provider, the facts and circumstances included in each report under subsection (a)(1) may, at the sole discretion of the provider, include the following information: (1) Information about the involved individual.— Information relating to the identity of any individual who appears to have violated or plans to violate a Federal law described in subsection (a)(2), which may, to the extent reasonably practicable, include the electronic mail address, Internet Protocol address, uniform resource locator, payment information (excluding personally identifiable information), or any other identifying information, including self-reported identifying information. (2) Historical reference.— Information relating to when and how a customer or subscriber of a provider uploaded, transmitted, or received content relating to the report or when and how content relating to the report was reported to, or discovered by the provider, including a date and time stamp and time zone. (3) Geographic location information.— Information relating to the geographic location of the involved individual or website, which may include the Internet Protocol address or verified address, or, if not reasonably available, at least one form of geographic identifying information, including area code or zip code, provided by the customer or subscriber, or stored or obtained by the provider. (4) Visual depictions of apparent child pornography.— Any visual depiction of apparent child pornography or other content relating to the incident such report is regarding. (5) Complete communication.—The complete communication containing any visual depiction of apparent child pornography or other content, including— (A) any data or information regarding the transmission of the communication; and (B) any visual depictions, data, or other digital files contained in, or attached to, the communication. (c) Forwarding of Report to Law Enforcement.—Pursuant to its clearinghouse role as a private, nonprofit organization, and at the conclusion of its review in furtherance of its nonprofit mission, NCMEC shall make available each report made under subsection (a)(1) to one or more of the following law enforcement agencies: (1) Any Federal law enforcement agency that is involved in the investigation of child sexual exploitation, kidnapping, or enticement crimes. (2) Any State or local law enforcement agency that is involved in the investigation of child sexual exploitation. (3) A foreign law enforcement agency designated by the Attorney General under subsection (d)(3) or a foreign law enforcement agency that has an established relationship with the Federal Bureau of Investigation, Immigration and Customs Enforcement, or INTERPOL, and is involved in the investigation of child sexual exploitation, kidnapping, or enticement crimes. (d) Attorney General Responsibilities.— (1) In general.— The Attorney General shall enforce this section. (2) Designation of federal agencies.— The Attorney General may designate a Federal law enforcement agency or agencies to which a report shall be forwarded under subsection (c)(1). (3) Designation of foreign agencies.—The Attorney General may— (A) in consultation with the Secretary of State, designate foreign law enforcement agencies to which a report may be forwarded under subsection (c)(3); (B) establish the conditions under which such a report may be forwarded to such agencies; and (C) develop a process for foreign law enforcement agencies to request assistance from Federal law enforcement agencies in obtaining evidence related to a report referred under subsection (c)(3). (4) Reporting designated foreign agencies.— The Attorney General may maintain and make available to the Department of State, NCMEC, providers, the Committee on the Judiciary of the Senate, and the Committee on the Judiciary of the House of Representatives a list of the foreign law enforcement agencies designated under paragraph (3). (5) Notification to providers.— (A) In general.—NCMEC may notify a provider of the information described in subparagraph (B), if— (i) a provider notifies NCMEC that the provider is making a report under this section as the result of a request by a foreign law enforcement agency; and (ii) NCMEC forwards the report described in clause (i) to— (I) the requesting foreign law enforcement agency; or (II) another agency in the same country designated by the Attorney General under paragraph (3) or that has an established relationship with the Federal Bureau of Investigation, U.S. Immigration and Customs Enforcement, or INTERPOL and is involved in the investigation of child sexual exploitation, kidnapping, or enticement crimes. (B) Information described.—The information described in this subparagraph is— (i) the identity of the foreign law enforcement agency to which the report was forwarded; and (ii) the date on which the report was forwarded. (C) Notification of inability to forward report.— If a provider notifies NCMEC that the provider is making a report under this section as the result of a request by a foreign law enforcement agency and NCMEC is unable to forward the report as described in subparagraph (A)(ii), NCMEC shall notify the provider that NCMEC was unable to forward the report. (e) Failure To Report.—A provider that knowingly and willfully fails to make a report required under subsection (a)(1) shall be fined— (1) in the case of an initial knowing and willful failure to make a report, not more than $850,000 in the case of a provider with not less than 100,000,000 monthly active users or $600,000 in the case of a provider with less than 100,000,000 monthly active users; and (2) in the case of any second or subsequent knowing and willful failure to make a report, not more than $1,000,000 in the case of a provider with not less than 100,000,000 monthly active users or $850,000 in the case of a provider with less than 100,000,000 monthly active users. (f) Protection of Privacy.—Nothing in this section shall be construed to require a provider to— (1) monitor any user, subscriber, or customer of that provider; (2) monitor the content of any communication of any person described in paragraph (1); or (3) affirmatively search, screen, or scan for facts or circumstances described in sections (a) and (b). (g) Conditions of Disclosure Information Contained Within Report.— (1) In general.— Except as provided in paragraph (2), a law enforcement agency that receives a report under subsection (c) shall not disclose any information contained in that report. (2) Permitted disclosures by law enforcement.— (A) In general.—A law enforcement agency may disclose information in a report received under subsection (c)— (i) to an attorney for the government for use in the performance of the official duties of that attorney; (ii) to such officers and employees of that law enforcement agency, as may be necessary in the performance of their investigative and recordkeeping functions; (iii) to such other government personnel (including personnel of a State or subdivision of a State) as are determined to be necessary by an attorney for the government to assist the attorney in the performance of the official duties of the attorney in enforcing Federal criminal law; (iv) if the report discloses a violation of State criminal law, to an appropriate official of a State or subdivision of a State for the purpose of enforcing such State law; (v) to a defendant in a criminal case or the attorney for that defendant, subject to the terms and limitations under section 3509(m) or a similar State law, to the extent the information relates to a criminal charge pending against that defendant; (vi) subject to subparagraph (B), to a provider if necessary to facilitate response to legal process issued in connection to a criminal investigation, prosecution, or post-conviction remedy relating to that report; and (vii) as ordered by a court upon a showing of good cause and pursuant to any protective orders or other conditions that the court may impose. (B) Limitation.— Nothing in subparagraph (A)(vi) authorizes a law enforcement agency to provide visual depictions of apparent child pornography to a provider. (3) Permitted disclosures by NCMEC.—NCMEC may disclose by mail, electronic transmission, or other reasonable means, information received in a report under subsection (a) only to— (A) any Federal law enforcement agency designated by the Attorney General under subsection (d)(2) or that is involved in the investigation of child sexual exploitation, kidnapping, or enticement crimes; (B) any State, local, or tribal law enforcement agency involved in the investigation of child sexual exploitation, kidnapping, or enticement crimes; (C) any foreign law enforcement agency designated by the Attorney General under subsection (d)(3) or that has an established relationship with the Federal Bureau of Investigation, Immigration and Customs Enforcement, or INTERPOL, and is involved in the investigation of child sexual exploitation, kidnapping, or enticement crimes; (D) a provider as described in section 2258C; and (E) respond to legal process, as necessary. (4) Permitted disclosure by a provider.— A provider that submits a report under subsection (a)(1) may disclose by mail, electronic transmission, or other reasonable means, information, including visual depictions contained in the report, in a manner consistent with permitted disclosures under paragraphs (3) through (8) of section 2702(b) only to a law enforcement agency described in subparagraph (A), (B), or (C) of paragraph (3), to NCMEC, or as necessary to respond to legal process. (h) Preservation.— (1) In general.— For the purposes of this section, a completed submission by a provider of a report to the CyberTipline under subsection (a)(1) shall be treated as a request to preserve the contents provided in the report for 1 year after the submission to the CyberTipline. (2) Preservation of commingled content.— Pursuant to paragraph (1), a provider shall preserve any visual depictions, data, or other digital files that are reasonably accessible and may provide context or additional information about the reported material or person. (3) Protection of preserved materials.— A provider preserving materials under this section shall maintain the materials in a secure location and take appropriate steps to limit access by agents or employees of the service to the materials to that access necessary to comply with the requirements of this subsection. (4) Authorities and duties not affected.— Nothing in this section shall be construed as replacing, amending, or otherwise interfering with the authorities and duties under section 2703. (5) Extension of preservation.— A provider of a report to the CyberTipline under subsection (a)(1) may voluntarily preserve the contents provided in the report (including any comingled content described in paragraph (2)) for longer than 1 year after the submission to the CyberTipline for the purpose of reducing the proliferation of online child sexual exploitation or preventing the online sexual exploitation of children. (6) Method of preservation.— Not later than 1 year after the date of enactment of this paragraph, a provider of a report to the CyberTipline under subsection (a)(1) shall preserve materials under this subsection in a manner that is consistent with the most recent version of the Cybersecurity Framework developed by the National Institute of Standards and Technology, or any successor thereto. (Added Pub. L. 110–401, title V,  501(a), Oct. 13, 2008, 122 Stat. 4243; amended Pub. L. 115–395,  2, Dec. 21, 2018, 132 Stat. 5287; Pub. L. 118–59,  3, 4(a), May 7, 2024, 138 Stat. 1016.) [1] So in original. Probably should be followed by “section”. Editorial Notes References in Text The date of enactment of this paragraph, referred to in subsec. (h)(6), is the date of enactment of Pub. L. 118–59, which was approved May 7, 2024. Amendments 2024—Subsec. (a)(2)(A). Pub. L. 118–59,  4(a)(1), inserted “, of section 1591 (if the violation involves a minor), or of 2422(b)” after “child pornography”. Subsec. (e)(1). Pub. L. 118–59,  4(a)(2)(A), substituted “$850,000 in the case of a provider with not less than 100,000,000 monthly active users or $600,000 in the case of a provider with less than 100,000,000 monthly active users” for “$150,000”. Subsec. (e)(2). Pub. L. 118–59,  4(a)(2)(B), substituted “$1,000,000 in the case of a provider with not less than 100,000,000 monthly active users or $850,000 in the case of a provider with less than 100,000,000 monthly active users” for “$300,000”. Subsec. (h)(1). Pub. L. 118–59,  3(1), substituted “1 year” for “90 days”. Subsec. (h)(5), (6). Pub. L. 118–59,  3(2), added pars. (5) and (6). 2018—Pub. L. 115–395,  2(1), substituted “providers” for “electronic communication service providers and remote computing service providers” in section catchline. Subsec. (a)(1). Pub. L. 115–395,  2(2)(A), amended par. (1) generally. Prior to amendment, par. (1) related to general reporting duty of electronic communication service providers. Subsec. (a)(2). Pub. L. 115–395,  2(2)(B), amended par. (2) generally. Prior to amendment, par. (2) described facts or circumstances of apparent violations requiring report. Subsec. (b). Pub. L. 115–395,  2(3)(A), in introductory provisions, substituted “In an effort to prevent the future sexual victimization of children, and to the extent the information is within the custody or control of a provider, the facts and circumstances included in each report under subsection (a)(1) may, at the sole discretion of the provider, include” for “To the extent the information is within the custody or control of an electronic communication service provider or a remote computing service provider, the facts and circumstances included in each report under subsection (a)(1) may include”. Subsec. (b)(1). Pub. L. 115–395,  2(3)(B), inserted “or plans to violate” after “who appears to have violated” and “payment information (excluding personally identifiable information),” after “uniform resource locator,”. Subsec. (b)(2). Pub. L. 115–395,  2(3)(C), substituted “a provider uploaded, transmitted, or received content relating to the report or when and how content relating to the report was reported to, or discovered by the provider” for “an electronic communication service or a remote computing service uploaded, transmitted, or received apparent child pornography or when and how apparent child pornography was reported to, or discovered by the electronic communication service provider or remote computing service provider”. Subsec. (b)(3). Pub. L. 115–395,  2(3)(D), amended par. (3) generally. Prior to amendment, text read as follows: “(A) In general.—Information relating to the geographic location of the involved individual or website, which may include the Internet Protocol address or verified billing address, or, if not reasonably available, at least 1 form of geographic identifying information, including area code or zip code. “(B) Inclusion.—The information described in subparagraph (A) may also include any geographic information provided to the electronic communication service or remote computing service by the customer or subscriber.” Subsec. (b)(4). Pub. L. 115–395,  2(3)(E), in heading, substituted “Visual depictions” for “Images” and, in text, substituted “visual depiction” for “image” and inserted “or other content” after “apparent child pornography”. Subsec. (b)(5). Pub. L. 115–395,  2(3)(F), substituted “visual depiction” for “image” and inserted “or other content” after “apparent child pornography” in introductory provisions and substituted “visual depictions” for “images” in subpar. (B). Subsec. (c). Pub. L. 115–395,  2(4), amended subsec. (c) generally. Prior to amendment, subsec. (c) related to forwarding of reports to domestic and foreign law enforcement agencies. Subsec. (d)(2). Pub. L. 115–395,  2(5)(A), substituted “may designate a” for “shall designate promptly the”. Subsec. (d)(3). Pub. L. 115–395,  2(5)(B), substituted “may” for “shall promptly” in introductory provisions and “designate” for “designate the” in subpar. (A). Subsec. (d)(4). Pub. L. 115–395,  2(5)(C), substituted “may” for “shall”, “NCMEC” for “the National Center for Missing and Exploited Children”, and “providers” for “electronic communication service providers, remote computing service providers”. Subsec. (d)(5). Pub. L. 115–395,  2(5)(E), (F), redesignated par. (6) as (5) and amended it generally. Prior to amendment, par. related to contents of Center’s notification to providers of report forwarded at request of foreign law enforcement agency. Pub. L. 115–395,  2(5)(D), struck out par. (5). Text read as follows: “It is the sense of Congress that— “(A) combating the international manufacturing, possession, and trade in online child pornography requires cooperation with competent, qualified, and appropriately trained foreign law enforcement agencies; and “(B) the Attorney General, in cooperation with the Secretary of State, should make a substantial effort to expand the list of foreign agencies designated under paragraph (3).” Subsec. (d)(6). Pub. L. 115–395,  2(5)(E), redesignated par. (6) as (5). Subsec. (e). Pub. L. 115–395,  2(6), substituted “A provider” for “An electronic communication service provider or remote computing service provider”. Subsec. (f). Pub. L. 115–395,  2(7)(A), substituted “a provider” for “an electronic communication service provider or a remote computing service provider” in introductory provisions. Subsec. (f)(3). Pub. L. 115–395,  2(7)(B), substituted “search, screen, or scan for” for “seek”. Subsec. (g)(2)(A)(vi). Pub. L. 115–395,  2(8)(A)(i), which directed substitution of “a provider” for “an electronic communication service provider or remote computing service provider”, was executed by making the substitution for “an electronic communication service provider or remote computing provider”, to reflect the probable intent of Congress. Subsec. (g)(2)(B). Pub. L. 115–395,  2(8)(A)(ii), amended subpar. (B) generally. Prior to amendment, text read as follows: “(i) Limitations on further disclosure.—The electronic communication service provider or remote computing service provider shall be prohibited from disclosing the contents of a report provided under subparagraph (A)(vi) to any person, except as necessary to respond to the legal process. “(ii) Effect.—Nothing in subparagraph (A)(vi) authorizes a law enforcement agency to provide child pornography images to an electronic communications service provider or a remote computing service.” Subsec. (g)(3). Pub. L. 115–395,  2(8)(B)(i), (ii), in heading, substituted “NCMEC” for “the national center for missing and exploited children” and, in introductory provisions, substituted “NCMEC may disclose by mail, electronic transmission, or other reasonable means, information received in a report under subsection (a) only to” for “The National Center for Missing and Exploited Children may disclose information received in a report under subsection (a) only”. Subsec. (g)(3)(A). Pub. L. 115–395,  2(8)(B)(iii), substituted “any Federal law enforcement agency” for “to any Federal law enforcement agency” and inserted “or that is involved in the investigation of child sexual exploitation, kidnapping, or enticement crimes” before semicolon at end. Subsec. (g)(3)(B). Pub. L. 115–395,  2(8)(B)(iv), substituted “any State” for “to any State” and “child sexual exploitation” for “child pornography, child exploitation”. Subsec. (g)(3)(C). Pub. L. 115–395,  2(8)(B)(v), substituted “any foreign law enforcement agency” for “to any foreign law enforcement agency” and “or that has an established relationship with the Federal Bureau of Investigation, Immigration and Customs Enforcement, or INTERPOL, and is involved in the investigation of child sexual exploitation, kidnapping, or enticement crimes;” for “; and”. Subsec. (g)(3)(D). Pub. L. 115–395,  2(8)(B)(vi), substituted “a provider” for “an electronic communication service provider or remote computing service provider” and “; and” for period at end. Subsec. (g)(3)(E). Pub. L. 115–395,  2(8)(B)(vii), added subpar. (E). Subsec. (g)(4). Pub. L. 115–395,  2(8)(C), added par. (4). Subsec. (h)(1). Pub. L. 115–395,  2(9)(A), substituted “a completed submission by a provider of a report to the CyberTipline under subsection (a)(1) shall be treated as a request to preserve the contents provided in the report for 90 days after the submission to the CyberTipline” for “the notification to an electronic communication service provider or a remote computing service provider by the CyberTipline of receipt of a report under subsection (a)(1) shall be treated as a request to preserve, as if such request was made pursuant to section 2703(f)”. Subsec. (h)(2). Pub. L. 115–395,  2(9)(D), in heading, substituted “content” for “images” and, in text, substituted “a provider” for “an electronic communication service provider or a remote computing service”, “visual depictions” for “images”, and “reasonably accessible and may provide context or additional information about the reported material or person” for “commingled or interspersed among the images of apparent child pornography within a particular communication or user-created folder or directory”. Final substitution, which directed striking out text containing “user created”, was executed instead to text which contained “user-created”, to reflect the probable intent of Congress. Pub. L. 115–395,  2(9)(B), (C), redesignated par. (3) as (2) and struck out former par. (2). Prior to amendment, text of par. (2) read as follows: “Pursuant to paragraph (1), an electronic communication service provider or a remote computing service shall preserve the contents of the report provided pursuant to subsection (b) for 90 days after such notification by the CyberTipline.” Subsec. (h)(3). Pub. L. 115–395,  2(9)(E), which directed substitution of “A provider” for “An electronic communication service or remote computing service”, was executed by making the substitution for “An electronic communications service or remote computing service”, to reflect the probable intent of Congress. Pub. L. 115–395,  2(9)(C), redesignated par. (4) as (3). Former par. (3) redesignated (2). Subsec. (h)(4), (5). Pub. L. 115–395,  2(9)(C), redesignated pars. (4) and (5) as (3) and (4), respectively. Statutory Notes and Related Subsidiaries Guidelines Pub. L. 118–59,  4(b), May 7, 2024, 138 Stat. 1017, provided that: “Not later than 180 days after the date of enactment of this Act [May 7, 2024], the National Center for Missing & Exploited Children may issue guidelines, as appropriate, to providers required or permitted to take actions described in section 2258A(a)(1)(B) of title 18, United States Code, on the relevant identifiers for content that may indicate sex trafficking of children, as described in section 1591 of that title, or enticement, as described in section 2422(b) of that title.” U.S. Code Notes prev | next (a) Duty To Report.— (1) In general.— (A) Duty.—In order to reduce the proliferation of online child sexual exploitation and to prevent the online sexual exploitation of children, a provider— (i) shall, as soon as reasonably possible after obtaining actual knowledge of any facts or circumstances described in paragraph (2)(A), take the actions described in subparagraph (B); and (ii) may, after obtaining actual knowledge of any facts or circumstances described in paragraph (2)(B), take the actions described in subparagraph (B). (B) Actions described.—The actions described in this subparagraph are— (i) providing to the CyberTipline of NCMEC, or any successor to the CyberTipline operated by NCMEC, the mailing address, telephone number, facsimile number, electronic mailing address of, and individual point of contact for, such provider; and (ii) making a report of such facts or circumstances to the CyberTipline, or any successor to the CyberTipline operated by NCMEC. (2) Facts or circumstances.— (A) Apparent violations.— The facts or circumstances described in this subparagraph are any facts or circumstances from which there is an apparent violation of section 2251, 2251A, 2252, 2252A, 2252B, or 2260 that involves child pornography, of section 1591 (if the violation involves a minor), or of [1] 2422(b). (B) Imminent violations.— The facts or circumstances described in this subparagraph are any facts or circumstances which indicate a violation of any of the sections described in subparagraph (A) involving child pornography may be planned or imminent. (b) Contents of Report.—In an effort to prevent the future sexual victimization of children, and to the extent the information is within the custody or control of a provider, the facts and circumstances included in each report under subsection (a)(1) may, at the sole discretion of the provider, include the following information: (1) Information about the involved individual.— Information relating to the identity of any individual who appears to have violated or plans to violate a Federal law described in subsection (a)(2), which may, to the extent reasonably practicable, include the electronic mail address, Internet Protocol address, uniform resource locator, payment information (excluding personally identifiable information), or any other identifying information, including self-reported identifying information. (2) Historical reference.— Information relating to when and how a customer or subscriber of a provider uploaded, transmitted, or received content relating to the report or when and how content relating to the report was reported to, or discovered by the provider, including a date and time stamp and time zone. (3) Geographic location information.— Information relating to the geographic location of the involved individual or website, which may include the Internet Protocol address or verified address, or, if not reasonably available, at least one form of geographic identifying information, including area code or zip code, provided by the customer or subscriber, or stored or obtained by the provider. (4) Visual depictions of apparent child pornography.— Any visual depiction of apparent child pornography or other content relating to the incident such report is regarding. (5) Complete communication.—The complete communication containing any visual depiction of apparent child pornography or other content, including— (A) any data or information regarding the transmission of the communication; and (B) any visual depictions, data, or other digital files contained in, or attached to, the communication. (c) Forwarding of Report to Law Enforcement.—Pursuant to its clearinghouse role as a private, nonprofit organization, and at the conclusion of its review in furtherance of its nonprofit mission, NCMEC shall make available each report made under subsection (a)(1) to one or more of the following law enforcement agencies: (1) Any Federal law enforcement agency that is involved in the investigation of child sexual exploitation, kidnapping, or enticement crimes. (2) Any State or local law enforcement agency that is involved in the investigation of child sexual exploitation. (3) A foreign law enforcement agency designated by the Attorney General under subsection (d)(3) or a foreign law enforcement agency that has an established relationship with the Federal Bureau of Investigation, Immigration and Customs Enforcement, or INTERPOL, and is involved in the investigation of child sexual exploitation, kidnapping, or enticement crimes. (d) Attorney General Responsibilities.— (1) In general.— The Attorney General shall enforce this section. (2) Designation of federal agencies.— The Attorney General may designate a Federal law enforcement agency or agencies to which a report shall be forwarded under subsection (c)(1). (3) Designation of foreign agencies.—The Attorney General may— (A) in consultation with the Secretary of State, designate foreign law enforcement agencies to which a report may be forwarded under subsection (c)(3); (B) establish the conditions under which such a report may be forwarded to such agencies; and (C) develop a process for foreign law enforcement agencies to request assistance from Federal law enforcement agencies in obtaining evidence related to a report referred under subsection (c)(3). (4) Reporting designated foreign agencies.— The Attorney General may maintain and make available to the Department of State, NCMEC, providers, the Committee on the Judiciary of the Senate, and the Committee on the Judiciary of the House of Representatives a list of the foreign law enforcement agencies designated under paragraph (3). (5) Notification to providers.— (A) In general.—NCMEC may notify a provider of the information described in subparagraph (B), if— (i) a provider notifies NCMEC that the provider is making a report under this section as the result of a request by a foreign law enforcement agency; and (ii) NCMEC forwards the report described in clause (i) to— (I) the requesting foreign law enforcement agency; or (II) another agency in the same country designated by the Attorney General under paragraph (3) or that has an established relationship with the Federal Bureau of Investigation, U.S. Immigration and Customs Enforcement, or INTERPOL and is involved in the investigation of child sexual exploitation, kidnapping, or enticement crimes. (B) Information described.—The information described in this subparagraph is— (i) the identity of the foreign law enforcement agency to which the report was forwarded; and (ii) the date on which the report was forwarded. (C) Notification of inability to forward report.— If a provider notifies NCMEC that the provider is making a report under this section as the result of a request by a foreign law enforcement agency and NCMEC is unable to forward the report as described in subparagraph (A)(ii), NCMEC shall notify the provider that NCMEC was unable to forward the report. (e) Failure To Report.—A provider that knowingly and willfully fails to make a report required under subsection (a)(1) shall be fined— (1) in the case of an initial knowing and willful failure to make a report, not more than $850,000 in the case of a provider with not less than 100,000,000 monthly active users or $600,000 in the case of a provider with less than 100,000,000 monthly active users; and (2) in the case of any second or subsequent knowing and willful failure to make a report, not more than $1,000,000 in the case of a provider with not less than 100,000,000 monthly active users or $850,000 in the case of a provider with less than 100,000,000 monthly active users. (f) Protection of Privacy.—Nothing in this section shall be construed to require a provider to— (1) monitor any user, subscriber, or customer of that provider; (2) monitor the content of any communication of any person described in paragraph (1); or (3) affirmatively search, screen, or scan for facts or circumstances described in sections (a) and (b). (g) Conditions of Disclosure Information Contained Within Report.— (1) In general.— Except as provided in paragraph (2), a law enforcement agency that receives a report under subsection (c) shall not disclose any information contained in that report. (2) Permitted disclosures by law enforcement.— (A) In general.—A law enforcement agency may disclose information in a report received under subsection (c)— (i) to an attorney for the government for use in the performance of the official duties of that attorney; (ii) to such officers and employees of that law enforcement agency, as may be necessary in the performance of their investigative and recordkeeping functions; (iii) to such other government personnel (including personnel of a State or subdivision of a State) as are determined to be necessary by an attorney for the government to assist the attorney in the performance of the official duties of the attorney in enforcing Federal criminal law; (iv) if the report discloses a violation of State criminal law, to an appropriate official of a State or subdivision of a State for the purpose of enforcing such State law; (v) to a defendant in a criminal case or the attorney for that defendant, subject to the terms and limitations under section 3509(m) or a similar State law, to the extent the information relates to a criminal charge pending against that defendant; (vi) subject to subparagraph (B), to a provider if necessary to facilitate response to legal process issued in connection to a criminal investigation, prosecution, or post-conviction remedy relating to that report; and (vii) as ordered by a court upon a showing of good cause and pursuant to any protective orders or other conditions that the court may impose. (B) Limitation.— Nothing in subparagraph (A)(vi) authorizes a law enforcement agency to provide visual depictions of apparent child pornography to a provider. (3) Permitted disclosures by NCMEC.—NCMEC may disclose by mail, electronic transmission, or other reasonable means, information received in a report under subsection (a) only to— (A) any Federal law enforcement agency designated by the Attorney General under subsection (d)(2) or that is involved in the investigation of child sexual exploitation, kidnapping, or enticement crimes; (B) any State, local, or tribal law enforcement agency involved in the investigation of child sexual exploitation, kidnapping, or enticement crimes; (C) any foreign law enforcement agency designated by the Attorney General under subsection (d)(3) or that has an established relationship with the Federal Bureau of Investigation, Immigration and Customs Enforcement, or INTERPOL, and is involved in the investigation of child sexual exploitation, kidnapping, or enticement crimes; (D) a provider as described in section 2258C; and (E) respond to legal process, as necessary. (4) Permitted disclosure by a provider.— A provider that submits a report under subsection (a)(1) may disclose by mail, electronic transmission, or other reasonable means, information, including visual depictions contained in the report, in a manner consistent with permitted disclosures under paragraphs (3) through (8) of section 2702(b) only to a law enforcement agency described in subparagraph (A), (B), or (C) of paragraph (3), to NCMEC, or as necessary to respond to legal process. (h) Preservation.— (1) In general.— For the purposes of this section, a completed submission by a provider of a report to the CyberTipline under subsection (a)(1) shall be treated as a request to preserve the contents provided in the report for 1 year after the submission to the CyberTipline. (2) Preservation of commingled content.— Pursuant to paragraph (1), a provider shall preserve any visual depictions, data, or other digital files that are reasonably accessible and may provide context or additional information about the reported material or person. (3) Protection of preserved materials.— A provider preserving materials under this section shall maintain the materials in a secure location and take appropriate steps to limit access by agents or employees of the service to the materials to that access necessary to comply with the requirements of this subsection. (4) Authorities and duties not affected.— Nothing in this section shall be construed as replacing, amending, or otherwise interfering with the authorities and duties under section 2703. (5) Extension of preservation.— A provider of a report to the CyberTipline under subsection (a)(1) may voluntarily preserve the contents provided in the report (including any comingled content described in paragraph (2)) for longer than 1 year after the submission to the CyberTipline for the purpose of reducing the proliferation of online child sexual exploitation or preventing the online sexual exploitation of children. (6) Method of preservation.— Not later than 1 year after the date of enactment of this paragraph, a provider of a report to the CyberTipline under subsection (a)(1) shall preserve materials under this subsection in a manner that is consistent with the most recent version of the Cybersecurity Framework developed by the National Institute of Standards and Technology, or any successor thereto. (Added Pub. L. 110–401, title V,  501(a), Oct. 13, 2008, 122 Stat. 4243; amended Pub. L. 115–395,  2, Dec. 21, 2018, 132 Stat. 5287; Pub. L. 118–59,  3, 4(a), May 7, 2024, 138 Stat. 1016.) [1] So in original. Probably should be followed by “section”. Editorial Notes References in Text The date of enactment of this paragraph, referred to in subsec. (h)(6), is the date of enactment of Pub. L. 118–59, which was approved May 7, 2024. Amendments 2024—Subsec. (a)(2)(A). Pub. L. 118–59,  4(a)(1), inserted “, of section 1591 (if the violation involves a minor), or of 2422(b)” after “child pornography”. Subsec. (e)(1). Pub. L. 118–59,  4(a)(2)(A), substituted “$850,000 in the case of a provider with not less than 100,000,000 monthly active users or $600,000 in the case of a provider with less than 100,000,000 monthly active users” for “$150,000”. Subsec. (e)(2). Pub. L. 118–59,  4(a)(2)(B), substituted “$1,000,000 in the case of a provider with not less than 100,000,000 monthly active users or $850,000 in the case of a provider with less than 100,000,000 monthly active users” for “$300,000”. Subsec. (h)(1). Pub. L. 118–59,  3(1), substituted “1 year” for “90 days”. Subsec. (h)(5), (6). Pub. L. 118–59,  3(2), added pars. (5) and (6). 2018—Pub. L. 115–395,  2(1), substituted “providers” for “electronic communication service providers and remote computing service providers” in section catchline. Subsec. (a)(1). Pub. L. 115–395,  2(2)(A), amended par. (1) generally. Prior to amendment, par. (1) related to general reporting duty of electronic communication service providers. Subsec. (a)(2). Pub. L. 115–395,  2(2)(B), amended par. (2) generally. Prior to amendment, par. (2) described facts or circumstances of apparent violations requiring report. Subsec. (b). Pub. L. 115–395,  2(3)(A), in introductory provisions, substituted “In an effort to prevent the future sexual victimization of children, and to the extent the information is within the custody or control of a provider, the facts and circumstances included in each report under subsection (a)(1) may, at the sole discretion of the provider, include” for “To the extent the information is within the custody or control of an electronic communication service provider or a remote computing service provider, the facts and circumstances included in each report under subsection (a)(1) may include”. Subsec. (b)(1). Pub. L. 115–395,  2(3)(B), inserted “or plans to violate” after “who appears to have violated” and “payment information (excluding personally identifiable information),” after “uniform resource locator,”. Subsec. (b)(2). Pub. L. 115–395,  2(3)(C), substituted “a provider uploaded, transmitted, or received content relating to the report or when and how content relating to the report was reported to, or discovered by the provider” for “an electronic communication service or a remote computing service uploaded, transmitted, or received apparent child pornography or when and how apparent child pornography was reported to, or discovered by the electronic communication service provider or remote computing service provider”. Subsec. (b)(3). Pub. L. 115–395,  2(3)(D), amended par. (3) generally. Prior to amendment, text read as follows: “(A) In general.—Information relating to the geographic location of the involved individual or website, which may include the Internet Protocol address or verified billing address, or, if not reasonably available, at least 1 form of geographic identifying information, including area code or zip code. “(B) Inclusion.—The information described in subparagraph (A) may also include any geographic information provided to the electronic communication service or remote computing service by the customer or subscriber.” Subsec. (b)(4). Pub. L. 115–395,  2(3)(E), in heading, substituted “Visual depictions” for “Images” and, in text, substituted “visual depiction” for “image” and inserted “or other content” after “apparent child pornography”. Subsec. (b)(5). Pub. L. 115–395,  2(3)(F), substituted “visual depiction” for “image” and inserted “or other content” after “apparent child pornography” in introductory provisions and substituted “visual depictions” for “images” in subpar. (B). Subsec. (c). Pub. L. 115–395,  2(4), amended subsec. (c) generally. Prior to amendment, subsec. (c) related to forwarding of reports to domestic and foreign law enforcement agencies. Subsec. (d)(2). Pub. L. 115–395,  2(5)(A), substituted “may designate a” for “shall designate promptly the”. Subsec. (d)(3). Pub. L. 115–395,  2(5)(B), substituted “may” for “shall promptly” in introductory provisions and “designate” for “designate the” in subpar. (A). Subsec. (d)(4). Pub. L. 115–395,  2(5)(C), substituted “may” for “shall”, “NCMEC” for “the National Center for Missing and Exploited Children”, and “providers” for “electronic communication service providers, remote computing service providers”. Subsec. (d)(5). Pub. L. 115–395,  2(5)(E), (F), redesignated par. (6) as (5) and amended it generally. Prior to amendment, par. related to contents of Center’s notification to providers of report forwarded at request of foreign law enforcement agency. Pub. L. 115–395,  2(5)(D), struck out par. (5). Text read as follows: “It is the sense of Congress that— “(A) combating the international manufacturing, possession, and trade in online child pornography requires cooperation with competent, qualified, and appropriately trained foreign law enforcement agencies; and “(B) the Attorney General, in cooperation with the Secretary of State, should make a substantial effort to expand the list of foreign agencies designated under paragraph (3).” Subsec. (d)(6). Pub. L. 115–395,  2(5)(E), redesignated par. (6) as (5). Subsec. (e). Pub. L. 115–395,  2(6), substituted “A provider” for “An electronic communication service provider or remote computing service provider”. Subsec. (f). Pub. L. 115–395,  2(7)(A), substituted “a provider” for “an electronic communication service provider or a remote computing service provider” in introductory provisions. Subsec. (f)(3). Pub. L. 115–395,  2(7)(B), substituted “search, screen, or scan for” for “seek”. Subsec. (g)(2)(A)(vi). Pub. L. 115–395,  2(8)(A)(i), which directed substitution of “a provider” for “an electronic communication service provider or remote computing service provider”, was executed by making the substitution for “an electronic communication service provider or remote computing provider”, to reflect the probable intent of Congress. Subsec. (g)(2)(B). Pub. L. 115–395,  2(8)(A)(ii), amended subpar. (B) generally. Prior to amendment, text read as follows: “(i) Limitations on further disclosure.—The electronic communication service provider or remote computing service provider shall be prohibited from disclosing the contents of a report provided under subparagraph (A)(vi) to any person, except as necessary to respond to the legal process. “(ii) Effect.—Nothing in subparagraph (A)(vi) authorizes a law enforcement agency to provide child pornography images to an electronic communications service provider or a remote computing service.” Subsec. (g)(3). Pub. L. 115–395,  2(8)(B)(i), (ii), in heading, substituted “NCMEC” for “the national center for missing and exploited children” and, in introductory provisions, substituted “NCMEC may disclose by mail, electronic transmission, or other reasonable means, information received in a report under subsection (a) only to” for “The National Center for Missing and Exploited Children may disclose information received in a report under subsection (a) only”. Subsec. (g)(3)(A). Pub. L. 115–395,  2(8)(B)(iii), substituted “any Federal law enforcement agency” for “to any Federal law enforcement agency” and inserted “or that is involved in the investigation of child sexual exploitation, kidnapping, or enticement crimes” before semicolon at end. Subsec. (g)(3)(B). Pub. L. 115–395,  2(8)(B)(iv), substituted “any State” for “to any State” and “child sexual exploitation” for “child pornography, child exploitation”. Subsec. (g)(3)(C). Pub. L. 115–395,  2(8)(B)(v), substituted “any foreign law enforcement agency” for “to any foreign law enforcement agency” and “or that has an established relationship with the Federal Bureau of Investigation, Immigration and Customs Enforcement, or INTERPOL, and is involved in the investigation of child sexual exploitation, kidnapping, or enticement crimes;” for “; and”. Subsec. (g)(3)(D). Pub. L. 115–395,  2(8)(B)(vi), substituted “a provider” for “an electronic communication service provider or remote computing service provider” and “; and” for period at end. Subsec. (g)(3)(E). Pub. L. 115–395,  2(8)(B)(vii), added subpar. (E). Subsec. (g)(4). Pub. L. 115–395,  2(8)(C), added par. (4). Subsec. (h)(1). Pub. L. 115–395,  2(9)(A), substituted “a completed submission by a provider of a report to the CyberTipline under subsection (a)(1) shall be treated as a request to preserve the contents provided in the report for 90 days after the submission to the CyberTipline” for “the notification to an electronic communication service provider or a remote computing service provider by the CyberTipline of receipt of a report under subsection (a)(1) shall be treated as a request to preserve, as if such request was made pursuant to section 2703(f)”. Subsec. (h)(2). Pub. L. 115–395,  2(9)(D), in heading, substituted “content” for “images” and, in text, substituted “a provider” for “an electronic communication service provider or a remote computing service”, “visual depictions” for “images”, and “reasonably accessible and may provide context or additional information about the reported material or person” for “commingled or interspersed among the images of apparent child pornography within a particular communication or user-created folder or directory”. Final substitution, which directed striking out text containing “user created”, was executed instead to text which contained “user-created”, to reflect the probable intent of Congress. Pub. L. 115–395,  2(9)(B), (C), redesignated par. (3) as (2) and struck out former par. (2). Prior to amendment, text of par. (2) read as follows: “Pursuant to paragraph (1), an electronic communication service provider or a remote computing service shall preserve the contents of the report provided pursuant to subsection (b) for 90 days after such notification by the CyberTipline.” Subsec. (h)(3). Pub. L. 115–395,  2(9)(E), which directed substitution of “A provider” for “An electronic communication service or remote computing service”, was executed by making the substitution for “An electronic communications service or remote computing service”, to reflect the probable intent of Congress. Pub. L. 115–395,  2(9)(C), redesignated par. (4) as (3). Former par. (3) redesignated (2). Subsec. (h)(4), (5). Pub. L. 115–395,  2(9)(C), redesignated pars. (4) and (5) as (3) and (4), respectively. Statutory Notes and Related Subsidiaries Guidelines Pub. L. 118–59,  4(b), May 7, 2024, 138 Stat. 1017, provided that: “Not later than 180 days after the date of enactment of this Act [May 7, 2024], the National Center for Missing & Exploited Children may issue guidelines, as appropriate, to providers required or permitted to take actions described in section 2258A(a)(1)(B) of title 18, United States Code, on the relevant identifiers for content that may indicate sex trafficking of children, as described in section 1591 of that title, or enticement, as described in section 2422(b) of that title.” U.S. Code Notes prev | next (a) Duty To Report.— (1) In general.— (A) Duty.—In order to reduce the proliferation of online child sexual exploitation and to prevent the online sexual exploitation of children, a provider— (i) shall, as soon as reasonably possible after obtaining actual knowledge of any facts or circumstances described in paragraph (2)(A), take the actions described in subparagraph (B); and (ii) may, after obtaining actual knowledge of any facts or circumstances described in paragraph (2)(B), take the actions described in subparagraph (B). (B) Actions described.—The actions described in this subparagraph are— (i) providing to the CyberTipline of NCMEC, or any successor to the CyberTipline operated by NCMEC, the mailing address, telephone number, facsimile number, electronic mailing address of, and individual point of contact for, such provider; and (ii) making a report of such facts or circumstances to the CyberTipline, or any successor to the CyberTipline operated by NCMEC. (2) Facts or circumstances.— (A) Apparent violations.— The facts or circumstances described in this subparagraph are any facts or circumstances from which there is an apparent violation of section 2251, 2251A, 2252, 2252A, 2252B, or 2260 that involves child pornography, of section 1591 (if the violation involves a minor), or of [1] 2422(b). (B) Imminent violations.— The facts or circumstances described in this subparagraph are any facts or circumstances which indicate a violation of any of the sections described in subparagraph (A) involving child pornography may be planned or imminent. (b) Contents of Report.—In an effort to prevent the future sexual victimization of children, and to the extent the information is within the custody or control of a provider, the facts and circumstances included in each report under subsection (a)(1) may, at the sole discretion of the provider, include the following information: (1) Information about the involved individual.— Information relating to the identity of any individual who appears to have violated or plans to violate a Federal law described in subsection (a)(2), which may, to the extent reasonably practicable, include the electronic mail address, Internet Protocol address, uniform resource locator, payment information (excluding personally identifiable information), or any other identifying information, including self-reported identifying information. (2) Historical reference.— Information relating to when and how a customer or subscriber of a provider uploaded, transmitted, or received content relating to the report or when and how content relating to the report was reported to, or discovered by the provider, including a date and time stamp and time zone. (3) Geographic location information.— Information relating to the geographic location of the involved individual or website, which may include the Internet Protocol address or verified address, or, if not reasonably available, at least one form of geographic identifying information, including area code or zip code, provided by the customer or subscriber, or stored or obtained by the provider. (4) Visual depictions of apparent child pornography.— Any visual depiction of apparent child pornography or other content relating to the incident such report is regarding. (5) Complete communication.—The complete communication containing any visual depiction of apparent child pornography or other content, including— (A) any data or information regarding the transmission of the communication; and (B) any visual depictions, data, or other digital files contained in, or attached to, the communication. (c) Forwarding of Report to Law Enforcement.—Pursuant to its clearinghouse role as a private, nonprofit organization, and at the conclusion of its review in furtherance of its nonprofit mission, NCMEC shall make available each report made under subsection (a)(1) to one or more of the following law enforcement agencies: (1) Any Federal law enforcement agency that is involved in the investigation of child sexual exploitation, kidnapping, or enticement crimes. (2) Any State or local law enforcement agency that is involved in the investigation of child sexual exploitation. (3) A foreign law enforcement agency designated by the Attorney General under subsection (d)(3) or a foreign law enforcement agency that has an established relationship with the Federal Bureau of Investigation, Immigration and Customs Enforcement, or INTERPOL, and is involved in the investigation of child sexual exploitation, kidnapping, or enticement crimes. (d) Attorney General Responsibilities.— (1) In general.— The Attorney General shall enforce this section. (2) Designation of federal agencies.— The Attorney General may designate a Federal law enforcement agency or agencies to which a report shall be forwarded under subsection (c)(1). (3) Designation of foreign agencies.—The Attorney General may— (A) in consultation with the Secretary of State, designate foreign law enforcement agencies to which a report may be forwarded under subsection (c)(3); (B) establish the conditions under which such a report may be forwarded to such agencies; and (C) develop a process for foreign law enforcement agencies to request assistance from Federal law enforcement agencies in obtaining evidence related to a report referred under subsection (c)(3). (4) Reporting designated foreign agencies.— The Attorney General may maintain and make available to the Department of State, NCMEC, providers, the Committee on the Judiciary of the Senate, and the Committee on the Judiciary of the House of Representatives a list of the foreign law enforcement agencies designated under paragraph (3). (5) Notification to providers.— (A) In general.—NCMEC may notify a provider of the information described in subparagraph (B), if— (i) a provider notifies NCMEC that the provider is making a report under this section as the result of a request by a foreign law enforcement agency; and (ii) NCMEC forwards the report described in clause (i) to— (I) the requesting foreign law enforcement agency; or (II) another agency in the same country designated by the Attorney General under paragraph (3) or that has an established relationship with the Federal Bureau of Investigation, U.S. Immigration and Customs Enforcement, or INTERPOL and is involved in the investigation of child sexual exploitation, kidnapping, or enticement crimes. (B) Information described.—The information described in this subparagraph is— (i) the identity of the foreign law enforcement agency to which the report was forwarded; and (ii) the date on which the report was forwarded. (C) Notification of inability to forward report.— If a provider notifies NCMEC that the provider is making a report under this section as the result of a request by a foreign law enforcement agency and NCMEC is unable to forward the report as described in subparagraph (A)(ii), NCMEC shall notify the provider that NCMEC was unable to forward the report. (e) Failure To Report.—A provider that knowingly and willfully fails to make a report required under subsection (a)(1) shall be fined— (1) in the case of an initial knowing and willful failure to make a report, not more than $850,000 in the case of a provider with not less than 100,000,000 monthly active users or $600,000 in the case of a provider with less than 100,000,000 monthly active users; and (2) in the case of any second or subsequent knowing and willful failure to make a report, not more than $1,000,000 in the case of a provider with not less than 100,000,000 monthly active users or $850,000 in the case of a provider with less than 100,000,000 monthly active users. (f) Protection of Privacy.—Nothing in this section shall be construed to require a provider to— (1) monitor any user, subscriber, or customer of that provider; (2) monitor the content of any communication of any person described in paragraph (1); or (3) affirmatively search, screen, or scan for facts or circumstances described in sections (a) and (b). (g) Conditions of Disclosure Information Contained Within Report.— (1) In general.— Except as provided in paragraph (2), a law enforcement agency that receives a report under subsection (c) shall not disclose any information contained in that report. (2) Permitted disclosures by law enforcement.— (A) In general.—A law enforcement agency may disclose information in a report received under subsection (c)— (i) to an attorney for the government for use in the performance of the official duties of that attorney; (ii) to such officers and employees of that law enforcement agency, as may be necessary in the performance of their investigative and recordkeeping functions; (iii) to such other government personnel (including personnel of a State or subdivision of a State) as are determined to be necessary by an attorney for the government to assist the attorney in the performance of the official duties of the attorney in enforcing Federal criminal law; (iv) if the report discloses a violation of State criminal law, to an appropriate official of a State or subdivision of a State for the purpose of enforcing such State law; (v) to a defendant in a criminal case or the attorney for that defendant, subject to the terms and limitations under section 3509(m) or a similar State law, to the extent the information relates to a criminal charge pending against that defendant; (vi) subject to subparagraph (B), to a provider if necessary to facilitate response to legal process issued in connection to a criminal investigation, prosecution, or post-conviction remedy relating to that report; and (vii) as ordered by a court upon a showing of good cause and pursuant to any protective orders or other conditions that the court may impose. (B) Limitation.— Nothing in subparagraph (A)(vi) authorizes a law enforcement agency to provide visual depictions of apparent child pornography to a provider. (3) Permitted disclosures by NCMEC.—NCMEC may disclose by mail, electronic transmission, or other reasonable means, information received in a report under subsection (a) only to— (A) any Federal law enforcement agency designated by the Attorney General under subsection (d)(2) or that is involved in the investigation of child sexual exploitation, kidnapping, or enticement crimes; (B) any State, local, or tribal law enforcement agency involved in the investigation of child sexual exploitation, kidnapping, or enticement crimes; (C) any foreign law enforcement agency designated by the Attorney General under subsection (d)(3) or that has an established relationship with the Federal Bureau of Investigation, Immigration and Customs Enforcement, or INTERPOL, and is involved in the investigation of child sexual exploitation, kidnapping, or enticement crimes; (D) a provider as described in section 2258C; and (E) respond to legal process, as necessary. (4) Permitted disclosure by a provider.— A provider that submits a report under subsection (a)(1) may disclose by mail, electronic transmission, or other reasonable means, information, including visual depictions contained in the report, in a manner consistent with permitted disclosures under paragraphs (3) through (8) of section 2702(b) only to a law enforcement agency described in subparagraph (A), (B), or (C) of paragraph (3), to NCMEC, or as necessary to respond to legal process. (h) Preservation.— (1) In general.— For the purposes of this section, a completed submission by a provider of a report to the CyberTipline under subsection (a)(1) shall be treated as a request to preserve the contents provided in the report for 1 year after the submission to the CyberTipline. (2) Preservation of commingled content.— Pursuant to paragraph (1), a provider shall preserve any visual depictions, data, or other digital files that are reasonably accessible and may provide context or additional information about the reported material or person. (3) Protection of preserved materials.— A provider preserving materials under this section shall maintain the materials in a secure location and take appropriate steps to limit access by agents or employees of the service to the materials to that access necessary to comply with the requirements of this subsection. (4) Authorities and duties not affected.— Nothing in this section shall be construed as replacing, amending, or otherwise interfering with the authorities and duties under section 2703. (5) Extension of preservation.— A provider of a report to the CyberTipline under subsection (a)(1) may voluntarily preserve the contents provided in the report (including any comingled content described in paragraph (2)) for longer than 1 year after the submission to the CyberTipline for the purpose of reducing the proliferation of online child sexual exploitation or preventing the online sexual exploitation of children. (6) Method of preservation.— Not later than 1 year after the date of enactment of this paragraph, a provider of a report to the CyberTipline under subsection (a)(1) shall preserve materials under this subsection in a manner that is consistent with the most recent version of the Cybersecurity Framework developed by the National Institute of Standards and Technology, or any successor thereto. (Added Pub. L. 110–401, title V,  501(a), Oct. 13, 2008, 122 Stat. 4243; amended Pub. L. 115–395,  2, Dec. 21, 2018, 132 Stat. 5287; Pub. L. 118–59,  3, 4(a), May 7, 2024, 138 Stat. 1016.) [1] So in original. Probably should be followed by “section”. Editorial Notes References in Text The date of enactment of this paragraph, referred to in subsec. (h)(6), is the date of enactment of Pub. L. 118–59, which was approved May 7, 2024. Amendments 2024—Subsec. (a)(2)(A). Pub. L. 118–59,  4(a)(1), inserted “, of section 1591 (if the violation involves a minor), or of 2422(b)” after “child pornography”. Subsec. (e)(1). Pub. L. 118–59,  4(a)(2)(A), substituted “$850,000 in the case of a provider with not less than 100,000,000 monthly active users or $600,000 in the case of a provider with less than 100,000,000 monthly active users” for “$150,000”. Subsec. (e)(2). Pub. L. 118–59,  4(a)(2)(B), substituted “$1,000,000 in the case of a provider with not less than 100,000,000 monthly active users or $850,000 in the case of a provider with less than 100,000,000 monthly active users” for “$300,000”. Subsec. (h)(1). Pub. L. 118–59,  3(1), substituted “1 year” for “90 days”. Subsec. (h)(5), (6). Pub. L. 118–59,  3(2), added pars. (5) and (6). 2018—Pub. L. 115–395,  2(1), substituted “providers” for “electronic communication service providers and remote computing service providers” in section catchline. Subsec. (a)(1). Pub. L. 115–395,  2(2)(A), amended par. (1) generally. Prior to amendment, par. (1) related to general reporting duty of electronic communication service providers. Subsec. (a)(2). Pub. L. 115–395,  2(2)(B), amended par. (2) generally. Prior to amendment, par. (2) described facts or circumstances of apparent violations requiring report. Subsec. (b). Pub. L. 115–395,  2(3)(A), in introductory provisions, substituted “In an effort to prevent the future sexual victimization of children, and to the extent the information is within the custody or control of a provider, the facts and circumstances included in each report under subsection (a)(1) may, at the sole discretion of the provider, include” for “To the extent the information is within the custody or control of an electronic communication service provider or a remote computing service provider, the facts and circumstances included in each report under subsection (a)(1) may include”. Subsec. (b)(1). Pub. L. 115–395,  2(3)(B), inserted “or plans to violate” after “who appears to have violated” and “payment information (excluding personally identifiable information),” after “uniform resource locator,”. Subsec. (b)(2). Pub. L. 115–395,  2(3)(C), substituted “a provider uploaded, transmitted, or received content relating to the report or when and how content relating to the report was reported to, or discovered by the provider” for “an electronic communication service or a remote computing service uploaded, transmitted, or received apparent child pornography or when and how apparent child pornography was reported to, or discovered by the electronic communication service provider or remote computing service provider”. Subsec. (b)(3). Pub. L. 115–395,  2(3)(D), amended par. (3) generally. Prior to amendment, text read as follows: “(A) In general.—Information relating to the geographic location of the involved individual or website, which may include the Internet Protocol address or verified billing address, or, if not reasonably available, at least 1 form of geographic identifying information, including area code or zip code. “(B) Inclusion.—The information described in subparagraph (A) may also include any geographic information provided to the electronic communication service or remote computing service by the customer or subscriber.” Subsec. (b)(4). Pub. L. 115–395,  2(3)(E), in heading, substituted “Visual depictions” for “Images” and, in text, substituted “visual depiction” for “image” and inserted “or other content” after “apparent child pornography”. Subsec. (b)(5). Pub. L. 115–395,  2(3)(F), substituted “visual depiction” for “image” and inserted “or other content” after “apparent child pornography” in introductory provisions and substituted “visual depictions” for “images” in subpar. (B). Subsec. (c). Pub. L. 115–395,  2(4), amended subsec. (c) generally. Prior to amendment, subsec. (c) related to forwarding of reports to domestic and foreign law enforcement agencies. Subsec. (d)(2). Pub. L. 115–395,  2(5)(A), substituted “may designate a” for “shall designate promptly the”. Subsec. (d)(3). Pub. L. 115–395,  2(5)(B), substituted “may” for “shall promptly” in introductory provisions and “designate” for “designate the” in subpar. (A). Subsec. (d)(4). Pub. L. 115–395,  2(5)(C), substituted “may” for “shall”, “NCMEC” for “the National Center for Missing and Exploited Children”, and “providers” for “electronic communication service providers, remote computing service providers”. Subsec. (d)(5). Pub. L. 115–395,  2(5)(E), (F), redesignated par. (6) as (5) and amended it generally. Prior to amendment, par. related to contents of Center’s notification to providers of report forwarded at request of foreign law enforcement agency. Pub. L. 115–395,  2(5)(D), struck out par. (5). Text read as follows: “It is the sense of Congress that— “(A) combating the international manufacturing, possession, and trade in online child pornography requires cooperation with competent, qualified, and appropriately trained foreign law enforcement agencies; and “(B) the Attorney General, in cooperation with the Secretary of State, should make a substantial effort to expand the list of foreign agencies designated under paragraph (3).” Subsec. (d)(6). Pub. L. 115–395,  2(5)(E), redesignated par. (6) as (5). Subsec. (e). Pub. L. 115–395,  2(6), substituted “A provider” for “An electronic communication service provider or remote computing service provider”. Subsec. (f). Pub. L. 115–395,  2(7)(A), substituted “a provider” for “an electronic communication service provider or a remote computing service provider” in introductory provisions. Subsec. (f)(3). Pub. L. 115–395,  2(7)(B), substituted “search, screen, or scan for” for “seek”. Subsec. (g)(2)(A)(vi). Pub. L. 115–395,  2(8)(A)(i), which directed substitution of “a provider” for “an electronic communication service provider or remote computing service provider”, was executed by making the substitution for “an electronic communication service provider or remote computing provider”, to reflect the probable intent of Congress. Subsec. (g)(2)(B). Pub. L. 115–395,  2(8)(A)(ii), amended subpar. (B) generally. Prior to amendment, text read as follows: “(i) Limitations on further disclosure.—The electronic communication service provider or remote computing service provider shall be prohibited from disclosing the contents of a report provided under subparagraph (A)(vi) to any person, except as necessary to respond to the legal process. “(ii) Effect.—Nothing in subparagraph (A)(vi) authorizes a law enforcement agency to provide child pornography images to an electronic communications service provider or a remote computing service.” Subsec. (g)(3). Pub. L. 115–395,  2(8)(B)(i), (ii), in heading, substituted “NCMEC” for “the national center for missing and exploited children” and, in introductory provisions, substituted “NCMEC may disclose by mail, electronic transmission, or other reasonable means, information received in a report under subsection (a) only to” for “The National Center for Missing and Exploited Children may disclose information received in a report under subsection (a) only”. Subsec. (g)(3)(A). Pub. L. 115–395,  2(8)(B)(iii), substituted “any Federal law enforcement agency” for “to any Federal law enforcement agency” and inserted “or that is involved in the investigation of child sexual exploitation, kidnapping, or enticement crimes” before semicolon at end. Subsec. (g)(3)(B). Pub. L. 115–395,  2(8)(B)(iv), substituted “any State” for “to any State” and “child sexual exploitation” for “child pornography, child exploitation”. Subsec. (g)(3)(C). Pub. L. 115–395,  2(8)(B)(v), substituted “any foreign law enforcement agency” for “to any foreign law enforcement agency” and “or that has an established relationship with the Federal Bureau of Investigation, Immigration and Customs Enforcement, or INTERPOL, and is involved in the investigation of child sexual exploitation, kidnapping, or enticement crimes;” for “; and”. Subsec. (g)(3)(D). Pub. L. 115–395,  2(8)(B)(vi), substituted “a provider” for “an electronic communication service provider or remote computing service provider” and “; and” for period at end. Subsec. (g)(3)(E). Pub. L. 115–395,  2(8)(B)(vii), added subpar. (E). Subsec. (g)(4). Pub. L. 115–395,  2(8)(C), added par. (4). Subsec. (h)(1). Pub. L. 115–395,  2(9)(A), substituted “a completed submission by a provider of a report to the CyberTipline under subsection (a)(1) shall be treated as a request to preserve the contents provided in the report for 90 days after the submission to the CyberTipline” for “the notification to an electronic communication service provider or a remote computing service provider by the CyberTipline of receipt of a report under subsection (a)(1) shall be treated as a request to preserve, as if such request was made pursuant to section 2703(f)”. Subsec. (h)(2). Pub. L. 115–395,  2(9)(D), in heading, substituted “content” for “images” and, in text, substituted “a provider” for “an electronic communication service provider or a remote computing service”, “visual depictions” for “images”, and “reasonably accessible and may provide context or additional information about the reported material or person” for “commingled or interspersed among the images of apparent child pornography within a particular communication or user-created folder or directory”. Final substitution, which directed striking out text containing “user created”, was executed instead to text which contained “user-created”, to reflect the probable intent of Congress. Pub. L. 115–395,  2(9)(B), (C), redesignated par. (3) as (2) and struck out former par. (2). Prior to amendment, text of par. (2) read as follows: “Pursuant to paragraph (1), an electronic communication service provider or a remote computing service shall preserve the contents of the report provided pursuant to subsection (b) for 90 days after such notification by the CyberTipline.” Subsec. (h)(3). Pub. L. 115–395,  2(9)(E), which directed substitution of “A provider” for “An electronic communication service or remote computing service”, was executed by making the substitution for “An electronic communications service or remote computing service”, to reflect the probable intent of Congress. Pub. L. 115–395,  2(9)(C), redesignated par. (4) as (3). Former par. (3) redesignated (2). Subsec. (h)(4), (5). Pub. L. 115–395,  2(9)(C), redesignated pars. (4) and (5) as (3) and (4), respectively. Statutory Notes and Related Subsidiaries Guidelines Pub. L. 118–59,  4(b), May 7, 2024, 138 Stat. 1017, provided that: “Not later than 180 days after the date of enactment of this Act [May 7, 2024], the National Center for Missing & Exploited Children may issue guidelines, as appropriate, to providers required or permitted to take actions described in section 2258A(a)(1)(B) of title 18, United States Code, on the relevant identifiers for content that may indicate sex trafficking of children, as described in section 1591 of that title, or enticement, as described in section 2422(b) of that title.” prev | next (a) Duty To Report.— (1) In general.— (A) Duty.—In order to reduce the proliferation of online child sexual exploitation and to prevent the online sexual exploitation of children, a provider— (i) shall, as soon as reasonably possible after obtaining actual knowledge of any facts or circumstances described in paragraph (2)(A), take the actions described in subparagraph (B); and (ii) may, after obtaining actual knowledge of any facts or circumstances described in paragraph (2)(B), take the actions described in subparagraph (B). (B) Actions described.—The actions described in this subparagraph are— (i) providing to the CyberTipline of NCMEC, or any successor to the CyberTipline operated by NCMEC, the mailing address, telephone number, facsimile number, electronic mailing address of, and individual point of contact for, such provider; and (ii) making a report of such facts or circumstances to the CyberTipline, or any successor to the CyberTipline operated by NCMEC. (2) Facts or circumstances.— (A) Apparent violations.— The facts or circumstances described in this subparagraph are any facts or circumstances from which there is an apparent violation of section 2251, 2251A, 2252, 2252A, 2252B, or 2260 that involves child pornography, of section 1591 (if the violation involves a minor), or of [1] 2422(b). (B) Imminent violations.— The facts or circumstances described in this subparagraph are any facts or circumstances which indicate a violation of any of the sections described in subparagraph (A) involving child pornography may be planned or imminent. (b) Contents of Report.—In an effort to prevent the future sexual victimization of children, and to the extent the information is within the custody or control of a provider, the facts and circumstances included in each report under subsection (a)(1) may, at the sole discretion of the provider, include the following information: (1) Information about the involved individual.— Information relating to the identity of any individual who appears to have violated or plans to violate a Federal law described in subsection (a)(2), which may, to the extent reasonably practicable, include the electronic mail address, Internet Protocol address, uniform resource locator, payment information (excluding personally identifiable information), or any other identifying information, including self-reported identifying information. (2) Historical reference.— Information relating to when and how a customer or subscriber of a provider uploaded, transmitted, or received content relating to the report or when and how content relating to the report was reported to, or discovered by the provider, including a date and time stamp and time zone. (3) Geographic location information.— Information relating to the geographic location of the involved individual or website, which may include the Internet Protocol address or verified address, or, if not reasonably available, at least one form of geographic identifying information, including area code or zip code, provided by the customer or subscriber, or stored or obtained by the provider. (4) Visual depictions of apparent child pornography.— Any visual depiction of apparent child pornography or other content relating to the incident such report is regarding. (5) Complete communication.—The complete communication containing any visual depiction of apparent child pornography or other content, including— (A) any data or information regarding the transmission of the communication; and (B) any visual depictions, data, or other digital files contained in, or attached to, the communication. (c) Forwarding of Report to Law Enforcement.—Pursuant to its clearinghouse role as a private, nonprofit organization, and at the conclusion of its review in furtherance of its nonprofit mission, NCMEC shall make available each report made under subsection (a)(1) to one or more of the following law enforcement agencies: (1) Any Federal law enforcement agency that is involved in the investigation of child sexual exploitation, kidnapping, or enticement crimes. (2) Any State or local law enforcement agency that is involved in the investigation of child sexual exploitation. (3) A foreign law enforcement agency designated by the Attorney General under subsection (d)(3) or a foreign law enforcement agency that has an established relationship with the Federal Bureau of Investigation, Immigration and Customs Enforcement, or INTERPOL, and is involved in the investigation of child sexual exploitation, kidnapping, or enticement crimes. (d) Attorney General Responsibilities.— (1) In general.— The Attorney General shall enforce this section. (2) Designation of federal agencies.— The Attorney General may designate a Federal law enforcement agency or agencies to which a report shall be forwarded under subsection (c)(1). (3) Designation of foreign agencies.—The Attorney General may— (A) in consultation with the Secretary of State, designate foreign law enforcement agencies to which a report may be forwarded under subsection (c)(3); (B) establish the conditions under which such a report may be forwarded to such agencies; and (C) develop a process for foreign law enforcement agencies to request assistance from Federal law enforcement agencies in obtaining evidence related to a report referred under subsection (c)(3). (4) Reporting designated foreign agencies.— The Attorney General may maintain and make available to the Department of State, NCMEC, providers, the Committee on the Judiciary of the Senate, and the Committee on the Judiciary of the House of Representatives a list of the foreign law enforcement agencies designated under paragraph (3). (5) Notification to providers.— (A) In general.—NCMEC may notify a provider of the information described in subparagraph (B), if— (i) a provider notifies NCMEC that the provider is making a report under this section as the result of a request by a foreign law enforcement agency; and (ii) NCMEC forwards the report described in clause (i) to— (I) the requesting foreign law enforcement agency; or (II) another agency in the same country designated by the Attorney General under paragraph (3) or that has an established relationship with the Federal Bureau of Investigation, U.S. Immigration and Customs Enforcement, or INTERPOL and is involved in the investigation of child sexual exploitation, kidnapping, or enticement crimes. (B) Information described.—The information described in this subparagraph is— (i) the identity of the foreign law enforcement agency to which the report was forwarded; and (ii) the date on which the report was forwarded. (C) Notification of inability to forward report.— If a provider notifies NCMEC that the provider is making a report under this section as the result of a request by a foreign law enforcement agency and NCMEC is unable to forward the report as described in subparagraph (A)(ii), NCMEC shall notify the provider that NCMEC was unable to forward the report. (e) Failure To Report.—A provider that knowingly and willfully fails to make a report required under subsection (a)(1) shall be fined— (1) in the case of an initial knowing and willful failure to make a report, not more than $850,000 in the case of a provider with not less than 100,000,000 monthly active users or $600,000 in the case of a provider with less than 100,000,000 monthly active users; and (2) in the case of any second or subsequent knowing and willful failure to make a report, not more than $1,000,000 in the case of a provider with not less than 100,000,000 monthly active users or $850,000 in the case of a provider with less than 100,000,000 monthly active users. (f) Protection of Privacy.—Nothing in this section shall be construed to require a provider to— (1) monitor any user, subscriber, or customer of that provider; (2) monitor the content of any communication of any person described in paragraph (1); or (3) affirmatively search, screen, or scan for facts or circumstances described in sections (a) and (b). (g) Conditions of Disclosure Information Contained Within Report.— (1) In general.— Except as provided in paragraph (2), a law enforcement agency that receives a report under subsection (c) shall not disclose any information contained in that report. (2) Permitted disclosures by law enforcement.— (A) In general.—A law enforcement agency may disclose information in a report received under subsection (c)— (i) to an attorney for the government for use in the performance of the official duties of that attorney; (ii) to such officers and employees of that law enforcement agency, as may be necessary in the performance of their investigative and recordkeeping functions; (iii) to such other government personnel (including personnel of a State or subdivision of a State) as are determined to be necessary by an attorney for the government to assist the attorney in the performance of the official duties of the attorney in enforcing Federal criminal law; (iv) if the report discloses a violation of State criminal law, to an appropriate official of a State or subdivision of a State for the purpose of enforcing such State law; (v) to a defendant in a criminal case or the attorney for that defendant, subject to the terms and limitations under section 3509(m) or a similar State law, to the extent the information relates to a criminal charge pending against that defendant; (vi) subject to subparagraph (B), to a provider if necessary to facilitate response to legal process issued in connection to a criminal investigation, prosecution, or post-conviction remedy relating to that report; and (vii) as ordered by a court upon a showing of good cause and pursuant to any protective orders or other conditions that the court may impose. (B) Limitation.— Nothing in subparagraph (A)(vi) authorizes a law enforcement agency to provide visual depictions of apparent child pornography to a provider. (3) Permitted disclosures by NCMEC.—NCMEC may disclose by mail, electronic transmission, or other reasonable means, information received in a report under subsection (a) only to— (A) any Federal law enforcement agency designated by the Attorney General under subsection (d)(2) or that is involved in the investigation of child sexual exploitation, kidnapping, or enticement crimes; (B) any State, local, or tribal law enforcement agency involved in the investigation of child sexual exploitation, kidnapping, or enticement crimes; (C) any foreign law enforcement agency designated by the Attorney General under subsection (d)(3) or that has an established relationship with the Federal Bureau of Investigation, Immigration and Customs Enforcement, or INTERPOL, and is involved in the investigation of child sexual exploitation, kidnapping, or enticement crimes; (D) a provider as described in section 2258C; and (E) respond to legal process, as necessary. (4) Permitted disclosure by a provider.— A provider that submits a report under subsection (a)(1) may disclose by mail, electronic transmission, or other reasonable means, information, including visual depictions contained in the report, in a manner consistent with permitted disclosures under paragraphs (3) through (8) of section 2702(b) only to a law enforcement agency described in subparagraph (A), (B), or (C) of paragraph (3), to NCMEC, or as necessary to respond to legal process. (h) Preservation.— (1) In general.— For the purposes of this section, a completed submission by a provider of a report to the CyberTipline under subsection (a)(1) shall be treated as a request to preserve the contents provided in the report for 1 year after the submission to the CyberTipline. (2) Preservation of commingled content.— Pursuant to paragraph (1), a provider shall preserve any visual depictions, data, or other digital files that are reasonably accessible and may provide context or additional information about the reported material or person. (3) Protection of preserved materials.— A provider preserving materials under this section shall maintain the materials in a secure location and take appropriate steps to limit access by agents or employees of the service to the materials to that access necessary to comply with the requirements of this subsection. (4) Authorities and duties not affected.— Nothing in this section shall be construed as replacing, amending, or otherwise interfering with the authorities and duties under section 2703. (5) Extension of preservation.— A provider of a report to the CyberTipline under subsection (a)(1) may voluntarily preserve the contents provided in the report (including any comingled content described in paragraph (2)) for longer than 1 year after the submission to the CyberTipline for the purpose of reducing the proliferation of online child sexual exploitation or preventing the online sexual exploitation of children. (6) Method of preservation.— Not later than 1 year after the date of enactment of this paragraph, a provider of a report to the CyberTipline under subsection (a)(1) shall preserve materials under this subsection in a manner that is consistent with the most recent version of the Cybersecurity Framework developed by the National Institute of Standards and Technology, or any successor thereto. (Added Pub. L. 110–401, title V,  501(a), Oct. 13, 2008, 122 Stat. 4243; amended Pub. L. 115–395,  2, Dec. 21, 2018, 132 Stat. 5287; Pub. L. 118–59,  3, 4(a), May 7, 2024, 138 Stat. 1016.) [1] So in original. Probably should be followed by “section”. Editorial Notes References in Text The date of enactment of this paragraph, referred to in subsec. (h)(6), is the date of enactment of Pub. L. 118–59, which was approved May 7, 2024. Amendments 2024—Subsec. (a)(2)(A). Pub. L. 118–59,  4(a)(1), inserted “, of section 1591 (if the violation involves a minor), or of 2422(b)” after “child pornography”. Subsec. (e)(1). Pub. L. 118–59,  4(a)(2)(A), substituted “$850,000 in the case of a provider with not less than 100,000,000 monthly active users or $600,000 in the case of a provider with less than 100,000,000 monthly active users” for “$150,000”. Subsec. (e)(2). Pub. L. 118–59,  4(a)(2)(B), substituted “$1,000,000 in the case of a provider with not less than 100,000,000 monthly active users or $850,000 in the case of a provider with less than 100,000,000 monthly active users” for “$300,000”. Subsec. (h)(1). Pub. L. 118–59,  3(1), substituted “1 year” for “90 days”. Subsec. (h)(5), (6). Pub. L. 118–59,  3(2), added pars. (5) and (6). 2018—Pub. L. 115–395,  2(1), substituted “providers” for “electronic communication service providers and remote computing service providers” in section catchline. Subsec. (a)(1). Pub. L. 115–395,  2(2)(A), amended par. (1) generally. Prior to amendment, par. (1) related to general reporting duty of electronic communication service providers. Subsec. (a)(2). Pub. L. 115–395,  2(2)(B), amended par. (2) generally. Prior to amendment, par. (2) described facts or circumstances of apparent violations requiring report. Subsec. (b). Pub. L. 115–395,  2(3)(A), in introductory provisions, substituted “In an effort to prevent the future sexual victimization of children, and to the extent the information is within the custody or control of a provider, the facts and circumstances included in each report under subsection (a)(1) may, at the sole discretion of the provider, include” for “To the extent the information is within the custody or control of an electronic communication service provider or a remote computing service provider, the facts and circumstances included in each report under subsection (a)(1) may include”. Subsec. (b)(1). Pub. L. 115–395,  2(3)(B), inserted “or plans to violate” after “who appears to have violated” and “payment information (excluding personally identifiable information),” after “uniform resource locator,”. Subsec. (b)(2). Pub. L. 115–395,  2(3)(C), substituted “a provider uploaded, transmitted, or received content relating to the report or when and how content relating to the report was reported to, or discovered by the provider” for “an electronic communication service or a remote computing service uploaded, transmitted, or received apparent child pornography or when and how apparent child pornography was reported to, or discovered by the electronic communication service provider or remote computing service provider”. Subsec. (b)(3). Pub. L. 115–395,  2(3)(D), amended par. (3) generally. Prior to amendment, text read as follows: “(A) In general.—Information relating to the geographic location of the involved individual or website, which may include the Internet Protocol address or verified billing address, or, if not reasonably available, at least 1 form of geographic identifying information, including area code or zip code. “(B) Inclusion.—The information described in subparagraph (A) may also include any geographic information provided to the electronic communication service or remote computing service by the customer or subscriber.” Subsec. (b)(4). Pub. L. 115–395,  2(3)(E), in heading, substituted “Visual depictions” for “Images” and, in text, substituted “visual depiction” for “image” and inserted “or other content” after “apparent child pornography”. Subsec. (b)(5). Pub. L. 115–395,  2(3)(F), substituted “visual depiction” for “image” and inserted “or other content” after “apparent child pornography” in introductory provisions and substituted “visual depictions” for “images” in subpar. (B). Subsec. (c). Pub. L. 115–395,  2(4), amended subsec. (c) generally. Prior to amendment, subsec. (c) related to forwarding of reports to domestic and foreign law enforcement agencies. Subsec. (d)(2). Pub. L. 115–395,  2(5)(A), substituted “may designate a” for “shall designate promptly the”. Subsec. (d)(3). Pub. L. 115–395,  2(5)(B), substituted “may” for “shall promptly” in introductory provisions and “designate” for “designate the” in subpar. (A). Subsec. (d)(4). Pub. L. 115–395,  2(5)(C), substituted “may” for “shall”, “NCMEC” for “the National Center for Missing and Exploited Children”, and “providers” for “electronic communication service providers, remote computing service providers”. Subsec. (d)(5). Pub. L. 115–395,  2(5)(E), (F), redesignated par. (6) as (5) and amended it generally. Prior to amendment, par. related to contents of Center’s notification to providers of report forwarded at request of foreign law enforcement agency. Pub. L. 115–395,  2(5)(D), struck out par. (5). Text read as follows: “It is the sense of Congress that— “(A) combating the international manufacturing, possession, and trade in online child pornography requires cooperation with competent, qualified, and appropriately trained foreign law enforcement agencies; and “(B) the Attorney General, in cooperation with the Secretary of State, should make a substantial effort to expand the list of foreign agencies designated under paragraph (3).” Subsec. (d)(6). Pub. L. 115–395,  2(5)(E), redesignated par. (6) as (5). Subsec. (e). Pub. L. 115–395,  2(6), substituted “A provider” for “An electronic communication service provider or remote computing service provider”. Subsec. (f). Pub. L. 115–395,  2(7)(A), substituted “a provider” for “an electronic communication service provider or a remote computing service provider” in introductory provisions. Subsec. (f)(3). Pub. L. 115–395,  2(7)(B), substituted “search, screen, or scan for” for “seek”. Subsec. (g)(2)(A)(vi). Pub. L. 115–395,  2(8)(A)(i), which directed substitution of “a provider” for “an electronic communication service provider or remote computing service provider”, was executed by making the substitution for “an electronic communication service provider or remote computing provider”, to reflect the probable intent of Congress. Subsec. (g)(2)(B). Pub. L. 115–395,  2(8)(A)(ii), amended subpar. (B) generally. Prior to amendment, text read as follows: “(i) Limitations on further disclosure.—The electronic communication service provider or remote computing service provider shall be prohibited from disclosing the contents of a report provided under subparagraph (A)(vi) to any person, except as necessary to respond to the legal process. “(ii) Effect.—Nothing in subparagraph (A)(vi) authorizes a law enforcement agency to provide child pornography images to an electronic communications service provider or a remote computing service.” Subsec. (g)(3). Pub. L. 115–395,  2(8)(B)(i), (ii), in heading, substituted “NCMEC” for “the national center for missing and exploited children” and, in introductory provisions, substituted “NCMEC may disclose by mail, electronic transmission, or other reasonable means, information received in a report under subsection (a) only to” for “The National Center for Missing and Exploited Children may disclose information received in a report under subsection (a) only”. Subsec. (g)(3)(A). Pub. L. 115–395,  2(8)(B)(iii), substituted “any Federal law enforcement agency” for “to any Federal law enforcement agency” and inserted “or that is involved in the investigation of child sexual exploitation, kidnapping, or enticement crimes” before semicolon at end. Subsec. (g)(3)(B). Pub. L. 115–395,  2(8)(B)(iv), substituted “any State” for “to any State” and “child sexual exploitation” for “child pornography, child exploitation”. Subsec. (g)(3)(C). Pub. L. 115–395,  2(8)(B)(v), substituted “any foreign law enforcement agency” for “to any foreign law enforcement agency” and “or that has an established relationship with the Federal Bureau of Investigation, Immigration and Customs Enforcement, or INTERPOL, and is involved in the investigation of child sexual exploitation, kidnapping, or enticement crimes;” for “; and”. Subsec. (g)(3)(D). Pub. L. 115–395,  2(8)(B)(vi), substituted “a provider” for “an electronic communication service provider or remote computing service provider” and “; and” for period at end. Subsec. (g)(3)(E). Pub. L. 115–395,  2(8)(B)(vii), added subpar. (E). Subsec. (g)(4). Pub. L. 115–395,  2(8)(C), added par. (4). Subsec. (h)(1). Pub. L. 115–395,  2(9)(A), substituted “a completed submission by a provider of a report to the CyberTipline under subsection (a)(1) shall be treated as a request to preserve the contents provided in the report for 90 days after the submission to the CyberTipline” for “the notification to an electronic communication service provider or a remote computing service provider by the CyberTipline of receipt of a report under subsection (a)(1) shall be treated as a request to preserve, as if such request was made pursuant to section 2703(f)”. Subsec. (h)(2). Pub. L. 115–395,  2(9)(D), in heading, substituted “content” for “images” and, in text, substituted “a provider” for “an electronic communication service provider or a remote computing service”, “visual depictions” for “images”, and “reasonably accessible and may provide context or additional information about the reported material or person” for “commingled or interspersed among the images of apparent child pornography within a particular communication or user-created folder or directory”. Final substitution, which directed striking out text containing “user created”, was executed instead to text which contained “user-created”, to reflect the probable intent of Congress. Pub. L. 115–395,  2(9)(B), (C), redesignated par. (3) as (2) and struck out former par. (2). Prior to amendment, text of par. (2) read as follows: “Pursuant to paragraph (1), an electronic communication service provider or a remote computing service shall preserve the contents of the report provided pursuant to subsection (b) for 90 days after such notification by the CyberTipline.” Subsec. (h)(3). Pub. L. 115–395,  2(9)(E), which directed substitution of “A provider” for “An electronic communication service or remote computing service”, was executed by making the substitution for “An electronic communications service or remote computing service”, to reflect the probable intent of Congress. Pub. L. 115–395,  2(9)(C), redesignated par. (4) as (3). Former par. (3) redesignated (2). Subsec. (h)(4), (5). Pub. L. 115–395,  2(9)(C), redesignated pars. (4) and (5) as (3) and (4), respectively. Statutory Notes and Related Subsidiaries Guidelines Pub. L. 118–59,  4(b), May 7, 2024, 138 Stat. 1017, provided that: “Not later than 180 days after the date of enactment of this Act [May 7, 2024], the National Center for Missing & Exploited Children may issue guidelines, as appropriate, to providers required or permitted to take actions described in section 2258A(a)(1)(B) of title 18, United States Code, on the relevant identifiers for content that may indicate sex trafficking of children, as described in section 1591 of that title, or enticement, as described in section 2422(b) of that title.” (a) Duty To Report.— (1) In general.— (A) Duty.—In order to reduce the proliferation of online child sexual exploitation and to prevent the online sexual exploitation of children, a provider— (i) shall, as soon as reasonably possible after obtaining actual knowledge of any facts or circumstances described in paragraph (2)(A), take the actions described in subparagraph (B); and (ii) may, after obtaining actual knowledge of any facts or circumstances described in paragraph (2)(B), take the actions described in subparagraph (B). (B) Actions described.—The actions described in this subparagraph are— (i) providing to the CyberTipline of NCMEC, or any successor to the CyberTipline operated by NCMEC, the mailing address, telephone number, facsimile number, electronic mailing address of, and individual point of contact for, such provider; and (ii) making a report of such facts or circumstances to the CyberTipline, or any successor to the CyberTipline operated by NCMEC. (2) Facts or circumstances.— (A) Apparent violations.— The facts or circumstances described in this subparagraph are any facts or circumstances from which there is an apparent violation of section 2251, 2251A, 2252, 2252A, 2252B, or 2260 that involves child pornography, of section 1591 (if the violation involves a minor), or of [1] 2422(b). (B) Imminent violations.— The facts or circumstances described in this subparagraph are any facts or circumstances which indicate a violation of any of the sections described in subparagraph (A) involving child pornography may be planned or imminent. (b) Contents of Report.—In an effort to prevent the future sexual victimization of children, and to the extent the information is within the custody or control of a provider, the facts and circumstances included in each report under subsection (a)(1) may, at the sole discretion of the provider, include the following information: (1) Information about the involved individual.— Information relating to the identity of any individual who appears to have violated or plans to violate a Federal law described in subsection (a)(2), which may, to the extent reasonably practicable, include the electronic mail address, Internet Protocol address, uniform resource locator, payment information (excluding personally identifiable information), or any other identifying information, including self-reported identifying information. (2) Historical reference.— Information relating to when and how a customer or subscriber of a provider uploaded, transmitted, or received content relating to the report or when and how content relating to the report was reported to, or discovered by the provider, including a date and time stamp and time zone. (3) Geographic location information.— Information relating to the geographic location of the involved individual or website, which may include the Internet Protocol address or verified address, or, if not reasonably available, at least one form of geographic identifying information, including area code or zip code, provided by the customer or subscriber, or stored or obtained by the provider. (4) Visual depictions of apparent child pornography.— Any visual depiction of apparent child pornography or other content relating to the incident such report is regarding. (5) Complete communication.—The complete communication containing any visual depiction of apparent child pornography or other content, including— (A) any data or information regarding the transmission of the communication; and (B) any visual depictions, data, or other digital files contained in, or attached to, the communication. (c) Forwarding of Report to Law Enforcement.—Pursuant to its clearinghouse role as a private, nonprofit organization, and at the conclusion of its review in furtherance of its nonprofit mission, NCMEC shall make available each report made under subsection (a)(1) to one or more of the following law enforcement agencies: (1) Any Federal law enforcement agency that is involved in the investigation of child sexual exploitation, kidnapping, or enticement crimes. (2) Any State or local law enforcement agency that is involved in the investigation of child sexual exploitation. (3) A foreign law enforcement agency designated by the Attorney General under subsection (d)(3) or a foreign law enforcement agency that has an established relationship with the Federal Bureau of Investigation, Immigration and Customs Enforcement, or INTERPOL, and is involved in the investigation of child sexual exploitation, kidnapping, or enticement crimes. (d) Attorney General Responsibilities.— (1) In general.— The Attorney General shall enforce this section. (2) Designation of federal agencies.— The Attorney General may designate a Federal law enforcement agency or agencies to which a report shall be forwarded under subsection (c)(1). (3) Designation of foreign agencies.—The Attorney General may— (A) in consultation with the Secretary of State, designate foreign law enforcement agencies to which a report may be forwarded under subsection (c)(3); (B) establish the conditions under which such a report may be forwarded to such agencies; and (C) develop a process for foreign law enforcement agencies to request assistance from Federal law enforcement agencies in obtaining evidence related to a report referred under subsection (c)(3). (4) Reporting designated foreign agencies.— The Attorney General may maintain and make available to the Department of State, NCMEC, providers, the Committee on the Judiciary of the Senate, and the Committee on the Judiciary of the House of Representatives a list of the foreign law enforcement agencies designated under paragraph (3). (5) Notification to providers.— (A) In general.—NCMEC may notify a provider of the information described in subparagraph (B), if— (i) a provider notifies NCMEC that the provider is making a report under this section as the result of a request by a foreign law enforcement agency; and (ii) NCMEC forwards the report described in clause (i) to— (I) the requesting foreign law enforcement agency; or (II) another agency in the same country designated by the Attorney General under paragraph (3) or that has an established relationship with the Federal Bureau of Investigation, U.S. Immigration and Customs Enforcement, or INTERPOL and is involved in the investigation of child sexual exploitation, kidnapping, or enticement crimes. (B) Information described.—The information described in this subparagraph is— (i) the identity of the foreign law enforcement agency to which the report was forwarded; and (ii) the date on which the report was forwarded. (C) Notification of inability to forward report.— If a provider notifies NCMEC that the provider is making a report under this section as the result of a request by a foreign law enforcement agency and NCMEC is unable to forward the report as described in subparagraph (A)(ii), NCMEC shall notify the provider that NCMEC was unable to forward the report. (e) Failure To Report.—A provider that knowingly and willfully fails to make a report required under subsection (a)(1) shall be fined— (1) in the case of an initial knowing and willful failure to make a report, not more than $850,000 in the case of a provider with not less than 100,000,000 monthly active users or $600,000 in the case of a provider with less than 100,000,000 monthly active users; and (2) in the case of any second or subsequent knowing and willful failure to make a report, not more than $1,000,000 in the case of a provider with not less than 100,000,000 monthly active users or $850,000 in the case of a provider with less than 100,000,000 monthly active users. (f) Protection of Privacy.—Nothing in this section shall be construed to require a provider to— (1) monitor any user, subscriber, or customer of that provider; (2) monitor the content of any communication of any person described in paragraph (1); or (3) affirmatively search, screen, or scan for facts or circumstances described in sections (a) and (b). (g) Conditions of Disclosure Information Contained Within Report.— (1) In general.— Except as provided in paragraph (2), a law enforcement agency that receives a report under subsection (c) shall not disclose any information contained in that report. (2) Permitted disclosures by law enforcement.— (A) In general.—A law enforcement agency may disclose information in a report received under subsection (c)— (i) to an attorney for the government for use in the performance of the official duties of that attorney; (ii) to such officers and employees of that law enforcement agency, as may be necessary in the performance of their investigative and recordkeeping functions; (iii) to such other government personnel (including personnel of a State or subdivision of a State) as are determined to be necessary by an attorney for the government to assist the attorney in the performance of the official duties of the attorney in enforcing Federal criminal law; (iv) if the report discloses a violation of State criminal law, to an appropriate official of a State or subdivision of a State for the purpose of enforcing such State law; (v) to a defendant in a criminal case or the attorney for that defendant, subject to the terms and limitations under section 3509(m) or a similar State law, to the extent the information relates to a criminal charge pending against that defendant; (vi) subject to subparagraph (B), to a provider if necessary to facilitate response to legal process issued in connection to a criminal investigation, prosecution, or post-conviction remedy relating to that report; and (vii) as ordered by a court upon a showing of good cause and pursuant to any protective orders or other conditions that the court may impose. (B) Limitation.— Nothing in subparagraph (A)(vi) authorizes a law enforcement agency to provide visual depictions of apparent child pornography to a provider. (3) Permitted disclosures by NCMEC.—NCMEC may disclose by mail, electronic transmission, or other reasonable means, information received in a report under subsection (a) only to— (A) any Federal law enforcement agency designated by the Attorney General under subsection (d)(2) or that is involved in the investigation of child sexual exploitation, kidnapping, or enticement crimes; (B) any State, local, or tribal law enforcement agency involved in the investigation of child sexual exploitation, kidnapping, or enticement crimes; (C) any foreign law enforcement agency designated by the Attorney General under subsection (d)(3) or that has an established relationship with the Federal Bureau of Investigation, Immigration and Customs Enforcement, or INTERPOL, and is involved in the investigation of child sexual exploitation, kidnapping, or enticement crimes; (D) a provider as described in section 2258C; and (E) respond to legal process, as necessary. (4) Permitted disclosure by a provider.— A provider that submits a report under subsection (a)(1) may disclose by mail, electronic transmission, or other reasonable means, information, including visual depictions contained in the report, in a manner consistent with permitted disclosures under paragraphs (3) through (8) of section 2702(b) only to a law enforcement agency described in subparagraph (A), (B), or (C) of paragraph (3), to NCMEC, or as necessary to respond to legal process. (h) Preservation.— (1) In general.— For the purposes of this section, a completed submission by a provider of a report to the CyberTipline under subsection (a)(1) shall be treated as a request to preserve the contents provided in the report for 1 year after the submission to the CyberTipline. (2) Preservation of commingled content.— Pursuant to paragraph (1), a provider shall preserve any visual depictions, data, or other digital files that are reasonably accessible and may provide context or additional information about the reported material or person. (3) Protection of preserved materials.— A provider preserving materials under this section shall maintain the materials in a secure location and take appropriate steps to limit access by agents or employees of the service to the materials to that access necessary to comply with the requirements of this subsection. (4) Authorities and duties not affected.— Nothing in this section shall be construed as replacing, amending, or otherwise interfering with the authorities and duties under section 2703. (5) Extension of preservation.— A provider of a report to the CyberTipline under subsection (a)(1) may voluntarily preserve the contents provided in the report (including any comingled content described in paragraph (2)) for longer than 1 year after the submission to the CyberTipline for the purpose of reducing the proliferation of online child sexual exploitation or preventing the online sexual exploitation of children. (6) Method of preservation.— Not later than 1 year after the date of enactment of this paragraph, a provider of a report to the CyberTipline under subsection (a)(1) shall preserve materials under this subsection in a manner that is consistent with the most recent version of the Cybersecurity Framework developed by the National Institute of Standards and Technology, or any successor thereto. (Added Pub. L. 110–401, title V,  501(a), Oct. 13, 2008, 122 Stat. 4243; amended Pub. L. 115–395,  2, Dec. 21, 2018, 132 Stat. 5287; Pub. L. 118–59,  3, 4(a), May 7, 2024, 138 Stat. 1016.) (a) Duty To Report.— (1) In general.— (A) Duty.—In order to reduce the proliferation of online child sexual exploitation and to prevent the online sexual exploitation of children, a provider— (i) shall, as soon as reasonably possible after obtaining actual knowledge of any facts or circumstances described in paragraph (2)(A), take the actions described in subparagraph (B); and (ii) may, after obtaining actual knowledge of any facts or circumstances described in paragraph (2)(B), take the actions described in subparagraph (B). (B) Actions described.—The actions described in this subparagraph are— (i) providing to the CyberTipline of NCMEC, or any successor to the CyberTipline operated by NCMEC, the mailing address, telephone number, facsimile number, electronic mailing address of, and individual point of contact for, such provider; and (ii) making a report of such facts or circumstances to the CyberTipline, or any successor to the CyberTipline operated by NCMEC. (2) Facts or circumstances.— (A) Apparent violations.— The facts or circumstances described in this subparagraph are any facts or circumstances from which there is an apparent violation of section 2251, 2251A, 2252, 2252A, 2252B, or 2260 that involves child pornography, of section 1591 (if the violation involves a minor), or of [1] 2422(b). (B) Imminent violations.— The facts or circumstances described in this subparagraph are any facts or circumstances which indicate a violation of any of the sections described in subparagraph (A) involving child pornography may be planned or imminent. (b) Contents of Report.—In an effort to prevent the future sexual victimization of children, and to the extent the information is within the custody or control of a provider, the facts and circumstances included in each report under subsection (a)(1) may, at the sole discretion of the provider, include the following information: (1) Information about the involved individual.— Information relating to the identity of any individual who appears to have violated or plans to violate a Federal law described in subsection (a)(2), which may, to the extent reasonably practicable, include the electronic mail address, Internet Protocol address, uniform resource locator, payment information (excluding personally identifiable information), or any other identifying information, including self-reported identifying information. (2) Historical reference.— Information relating to when and how a customer or subscriber of a provider uploaded, transmitted, or received content relating to the report or when and how content relating to the report was reported to, or discovered by the provider, including a date and time stamp and time zone. (3) Geographic location information.— Information relating to the geographic location of the involved individual or website, which may include the Internet Protocol address or verified address, or, if not reasonably available, at least one form of geographic identifying information, including area code or zip code, provided by the customer or subscriber, or stored or obtained by the provider. (4) Visual depictions of apparent child pornography.— Any visual depiction of apparent child pornography or other content relating to the incident such report is regarding. (5) Complete communication.—The complete communication containing any visual depiction of apparent child pornography or other content, including— (A) any data or information regarding the transmission of the communication; and (B) any visual depictions, data, or other digital files contained in, or attached to, the communication. (c) Forwarding of Report to Law Enforcement.—Pursuant to its clearinghouse role as a private, nonprofit organization, and at the conclusion of its review in furtherance of its nonprofit mission, NCMEC shall make available each report made under subsection (a)(1) to one or more of the following law enforcement agencies: (1) Any Federal law enforcement agency that is involved in the investigation of child sexual exploitation, kidnapping, or enticement crimes. (2) Any State or local law enforcement agency that is involved in the investigation of child sexual exploitation. (3) A foreign law enforcement agency designated by the Attorney General under subsection (d)(3) or a foreign law enforcement agency that has an established relationship with the Federal Bureau of Investigation, Immigration and Customs Enforcement, or INTERPOL, and is involved in the investigation of child sexual exploitation, kidnapping, or enticement crimes. (d) Attorney General Responsibilities.— (1) In general.— The Attorney General shall enforce this section. (2) Designation of federal agencies.— The Attorney General may designate a Federal law enforcement agency or agencies to which a report shall be forwarded under subsection (c)(1). (3) Designation of foreign agencies.—The Attorney General may— (A) in consultation with the Secretary of State, designate foreign law enforcement agencies to which a report may be forwarded under subsection (c)(3); (B) establish the conditions under which such a report may be forwarded to such agencies; and (C) develop a process for foreign law enforcement agencies to request assistance from Federal law enforcement agencies in obtaining evidence related to a report referred under subsection (c)(3). (4) Reporting designated foreign agencies.— The Attorney General may maintain and make available to the Department of State, NCMEC, providers, the Committee on the Judiciary of the Senate, and the Committee on the Judiciary of the House of Representatives a list of the foreign law enforcement agencies designated under paragraph (3). (5) Notification to providers.— (A) In general.—NCMEC may notify a provider of the information described in subparagraph (B), if— (i) a provider notifies NCMEC that the provider is making a report under this section as the result of a request by a foreign law enforcement agency; and (ii) NCMEC forwards the report described in clause (i) to— (I) the requesting foreign law enforcement agency; or (II) another agency in the same country designated by the Attorney General under paragraph (3) or that has an established relationship with the Federal Bureau of Investigation, U.S. Immigration and Customs Enforcement, or INTERPOL and is involved in the investigation of child sexual exploitation, kidnapping, or enticement crimes. (B) Information described.—The information described in this subparagraph is— (i) the identity of the foreign law enforcement agency to which the report was forwarded; and (ii) the date on which the report was forwarded. (C) Notification of inability to forward report.— If a provider notifies NCMEC that the provider is making a report under this section as the result of a request by a foreign law enforcement agency and NCMEC is unable to forward the report as described in subparagraph (A)(ii), NCMEC shall notify the provider that NCMEC was unable to forward the report. (e) Failure To Report.—A provider that knowingly and willfully fails to make a report required under subsection (a)(1) shall be fined— (1) in the case of an initial knowing and willful failure to make a report, not more than $850,000 in the case of a provider with not less than 100,000,000 monthly active users or $600,000 in the case of a provider with less than 100,000,000 monthly active users; and (2) in the case of any second or subsequent knowing and willful failure to make a report, not more than $1,000,000 in the case of a provider with not less than 100,000,000 monthly active users or $850,000 in the case of a provider with less than 100,000,000 monthly active users. (f) Protection of Privacy.—Nothing in this section shall be construed to require a provider to— (1) monitor any user, subscriber, or customer of that provider; (2) monitor the content of any communication of any person described in paragraph (1); or (3) affirmatively search, screen, or scan for facts or circumstances described in sections (a) and (b). (g) Conditions of Disclosure Information Contained Within Report.— (1) In general.— Except as provided in paragraph (2), a law enforcement agency that receives a report under subsection (c) shall not disclose any information contained in that report. (2) Permitted disclosures by law enforcement.— (A) In general.—A law enforcement agency may disclose information in a report received under subsection (c)— (i) to an attorney for the government for use in the performance of the official duties of that attorney; (ii) to such officers and employees of that law enforcement agency, as may be necessary in the performance of their investigative and recordkeeping functions; (iii) to such other government personnel (including personnel of a State or subdivision of a State) as are determined to be necessary by an attorney for the government to assist the attorney in the performance of the official duties of the attorney in enforcing Federal criminal law; (iv) if the report discloses a violation of State criminal law, to an appropriate official of a State or subdivision of a State for the purpose of enforcing such State law; (v) to a defendant in a criminal case or the attorney for that defendant, subject to the terms and limitations under section 3509(m) or a similar State law, to the extent the information relates to a criminal charge pending against that defendant; (vi) subject to subparagraph (B), to a provider if necessary to facilitate response to legal process issued in connection to a criminal investigation, prosecution, or post-conviction remedy relating to that report; and (vii) as ordered by a court upon a showing of good cause and pursuant to any protective orders or other conditions that the court may impose. (B) Limitation.— Nothing in subparagraph (A)(vi) authorizes a law enforcement agency to provide visual depictions of apparent child pornography to a provider. (3) Permitted disclosures by NCMEC.—NCMEC may disclose by mail, electronic transmission, or other reasonable means, information received in a report under subsection (a) only to— (A) any Federal law enforcement agency designated by the Attorney General under subsection (d)(2) or that is involved in the investigation of child sexual exploitation, kidnapping, or enticement crimes; (B) any State, local, or tribal law enforcement agency involved in the investigation of child sexual exploitation, kidnapping, or enticement crimes; (C) any foreign law enforcement agency designated by the Attorney General under subsection (d)(3) or that has an established relationship with the Federal Bureau of Investigation, Immigration and Customs Enforcement, or INTERPOL, and is involved in the investigation of child sexual exploitation, kidnapping, or enticement crimes; (D) a provider as described in section 2258C; and (E) respond to legal process, as necessary. (4) Permitted disclosure by a provider.— A provider that submits a report under subsection (a)(1) may disclose by mail, electronic transmission, or other reasonable means, information, including visual depictions contained in the report, in a manner consistent with permitted disclosures under paragraphs (3) through (8) of section 2702(b) only to a law enforcement agency described in subparagraph (A), (B), or (C) of paragraph (3), to NCMEC, or as necessary to respond to legal process. (h) Preservation.— (1) In general.— For the purposes of this section, a completed submission by a provider of a report to the CyberTipline under subsection (a)(1) shall be treated as a request to preserve the contents provided in the report for 1 year after the submission to the CyberTipline. (2) Preservation of commingled content.— Pursuant to paragraph (1), a provider shall preserve any visual depictions, data, or other digital files that are reasonably accessible and may provide context or additional information about the reported material or person. (3) Protection of preserved materials.— A provider preserving materials under this section shall maintain the materials in a secure location and take appropriate steps to limit access by agents or employees of the service to the materials to that access necessary to comply with the requirements of this subsection. (4) Authorities and duties not affected.— Nothing in this section shall be construed as replacing, amending, or otherwise interfering with the authorities and duties under section 2703. (5) Extension of preservation.— A provider of a report to the CyberTipline under subsection (a)(1) may voluntarily preserve the contents provided in the report (including any comingled content described in paragraph (2)) for longer than 1 year after the submission to the CyberTipline for the purpose of reducing the proliferation of online child sexual exploitation or preventing the online sexual exploitation of children. (6) Method of preservation.— Not later than 1 year after the date of enactment of this paragraph, a provider of a report to the CyberTipline under subsection (a)(1) shall preserve materials under this subsection in a manner that is consistent with the most recent version of the Cybersecurity Framework developed by the National Institute of Standards and Technology, or any successor thereto. (Added Pub. L. 110–401, title V,  501(a), Oct. 13, 2008, 122 Stat. 4243; amended Pub. L. 115–395,  2, Dec. 21, 2018, 132 Stat. 5287; Pub. L. 118–59,  3, 4(a), May 7, 2024, 138 Stat. 1016.) (a) Duty To Report.— (1) In general.— (A) Duty.—In order to reduce the proliferation of online child sexual exploitation and to prevent the online sexual exploitation of children, a provider— (i) shall, as soon as reasonably possible after obtaining actual knowledge of any facts or circumstances described in paragraph (2)(A), take the actions described in subparagraph (B); and (ii) may, after obtaining actual knowledge of any facts or circumstances described in paragraph (2)(B), take the actions described in subparagraph (B). (B) Actions described.—The actions described in this subparagraph are— (i) providing to the CyberTipline of NCMEC, or any successor to the CyberTipline operated by NCMEC, the mailing address, telephone number, facsimile number, electronic mailing address of, and individual point of contact for, such provider; and (ii) making a report of such facts or circumstances to the CyberTipline, or any successor to the CyberTipline operated by NCMEC. (2) Facts or circumstances.— (A) Apparent violations.— The facts or circumstances described in this subparagraph are any facts or circumstances from which there is an apparent violation of section 2251, 2251A, 2252, 2252A, 2252B, or 2260 that involves child pornography, of section 1591 (if the violation involves a minor), or of [1] 2422(b). (B) Imminent violations.— The facts or circumstances described in this subparagraph are any facts or circumstances which indicate a violation of any of the sections described in subparagraph (A) involving child pornography may be planned or imminent. (b) Contents of Report.—In an effort to prevent the future sexual victimization of children, and to the extent the information is within the custody or control of a provider, the facts and circumstances included in each report under subsection (a)(1) may, at the sole discretion of the provider, include the following information: (1) Information about the involved individual.— Information relating to the identity of any individual who appears to have violated or plans to violate a Federal law described in subsection (a)(2), which may, to the extent reasonably practicable, include the electronic mail address, Internet Protocol address, uniform resource locator, payment information (excluding personally identifiable information), or any other identifying information, including self-reported identifying information. (2) Historical reference.— Information relating to when and how a customer or subscriber of a provider uploaded, transmitted, or received content relating to the report or when and how content relating to the report was reported to, or discovered by the provider, including a date and time stamp and time zone. (3) Geographic location information.— Information relating to the geographic location of the involved individual or website, which may include the Internet Protocol address or verified address, or, if not reasonably available, at least one form of geographic identifying information, including area code or zip code, provided by the customer or subscriber, or stored or obtained by the provider. (4) Visual depictions of apparent child pornography.— Any visual depiction of apparent child pornography or other content relating to the incident such report is regarding. (5) Complete communication.—The complete communication containing any visual depiction of apparent child pornography or other content, including— (A) any data or information regarding the transmission of the communication; and (B) any visual depictions, data, or other digital files contained in, or attached to, the communication. (c) Forwarding of Report to Law Enforcement.—Pursuant to its clearinghouse role as a private, nonprofit organization, and at the conclusion of its review in furtherance of its nonprofit mission, NCMEC shall make available each report made under subsection (a)(1) to one or more of the following law enforcement agencies: (1) Any Federal law enforcement agency that is involved in the investigation of child sexual exploitation, kidnapping, or enticement crimes. (2) Any State or local law enforcement agency that is involved in the investigation of child sexual exploitation. (3) A foreign law enforcement agency designated by the Attorney General under subsection (d)(3) or a foreign law enforcement agency that has an established relationship with the Federal Bureau of Investigation, Immigration and Customs Enforcement, or INTERPOL, and is involved in the investigation of child sexual exploitation, kidnapping, or enticement crimes. (d) Attorney General Responsibilities.— (1) In general.— The Attorney General shall enforce this section. (2) Designation of federal agencies.— The Attorney General may designate a Federal law enforcement agency or agencies to which a report shall be forwarded under subsection (c)(1). (3) Designation of foreign agencies.—The Attorney General may— (A) in consultation with the Secretary of State, designate foreign law enforcement agencies to which a report may be forwarded under subsection (c)(3); (B) establish the conditions under which such a report may be forwarded to such agencies; and (C) develop a process for foreign law enforcement agencies to request assistance from Federal law enforcement agencies in obtaining evidence related to a report referred under subsection (c)(3). (4) Reporting designated foreign agencies.— The Attorney General may maintain and make available to the Department of State, NCMEC, providers, the Committee on the Judiciary of the Senate, and the Committee on the Judiciary of the House of Representatives a list of the foreign law enforcement agencies designated under paragraph (3). (5) Notification to providers.— (A) In general.—NCMEC may notify a provider of the information described in subparagraph (B), if— (i) a provider notifies NCMEC that the provider is making a report under this section as the result of a request by a foreign law enforcement agency; and (ii) NCMEC forwards the report described in clause (i) to— (I) the requesting foreign law enforcement agency; or (II) another agency in the same country designated by the Attorney General under paragraph (3) or that has an established relationship with the Federal Bureau of Investigation, U.S. Immigration and Customs Enforcement, or INTERPOL and is involved in the investigation of child sexual exploitation, kidnapping, or enticement crimes. (B) Information described.—The information described in this subparagraph is— (i) the identity of the foreign law enforcement agency to which the report was forwarded; and (ii) the date on which the report was forwarded. (C) Notification of inability to forward report.— If a provider notifies NCMEC that the provider is making a report under this section as the result of a request by a foreign law enforcement agency and NCMEC is unable to forward the report as described in subparagraph (A)(ii), NCMEC shall notify the provider that NCMEC was unable to forward the report. (e) Failure To Report.—A provider that knowingly and willfully fails to make a report required under subsection (a)(1) shall be fined— (1) in the case of an initial knowing and willful failure to make a report, not more than $850,000 in the case of a provider with not less than 100,000,000 monthly active users or $600,000 in the case of a provider with less than 100,000,000 monthly active users; and (2) in the case of any second or subsequent knowing and willful failure to make a report, not more than $1,000,000 in the case of a provider with not less than 100,000,000 monthly active users or $850,000 in the case of a provider with less than 100,000,000 monthly active users. (f) Protection of Privacy.—Nothing in this section shall be construed to require a provider to— (1) monitor any user, subscriber, or customer of that provider; (2) monitor the content of any communication of any person described in paragraph (1); or (3) affirmatively search, screen, or scan for facts or circumstances described in sections (a) and (b). (g) Conditions of Disclosure Information Contained Within Report.— (1) In general.— Except as provided in paragraph (2), a law enforcement agency that receives a report under subsection (c) shall not disclose any information contained in that report. (2) Permitted disclosures by law enforcement.— (A) In general.—A law enforcement agency may disclose information in a report received under subsection (c)— (i) to an attorney for the government for use in the performance of the official duties of that attorney; (ii) to such officers and employees of that law enforcement agency, as may be necessary in the performance of their investigative and recordkeeping functions; (iii) to such other government personnel (including personnel of a State or subdivision of a State) as are determined to be necessary by an attorney for the government to assist the attorney in the performance of the official duties of the attorney in enforcing Federal criminal law; (iv) if the report discloses a violation of State criminal law, to an appropriate official of a State or subdivision of a State for the purpose of enforcing such State law; (v) to a defendant in a criminal case or the attorney for that defendant, subject to the terms and limitations under section 3509(m) or a similar State law, to the extent the information relates to a criminal charge pending against that defendant; (vi) subject to subparagraph (B), to a provider if necessary to facilitate response to legal process issued in connection to a criminal investigation, prosecution, or post-conviction remedy relating to that report; and (vii) as ordered by a court upon a showing of good cause and pursuant to any protective orders or other conditions that the court may impose. (B) Limitation.— Nothing in subparagraph (A)(vi) authorizes a law enforcement agency to provide visual depictions of apparent child pornography to a provider. (3) Permitted disclosures by NCMEC.—NCMEC may disclose by mail, electronic transmission, or other reasonable means, information received in a report under subsection (a) only to— (A) any Federal law enforcement agency designated by the Attorney General under subsection (d)(2) or that is involved in the investigation of child sexual exploitation, kidnapping, or enticement crimes; (B) any State, local, or tribal law enforcement agency involved in the investigation of child sexual exploitation, kidnapping, or enticement crimes; (C) any foreign law enforcement agency designated by the Attorney General under subsection (d)(3) or that has an established relationship with the Federal Bureau of Investigation, Immigration and Customs Enforcement, or INTERPOL, and is involved in the investigation of child sexual exploitation, kidnapping, or enticement crimes; (D) a provider as described in section 2258C; and (E) respond to legal process, as necessary. (4) Permitted disclosure by a provider.— A provider that submits a report under subsection (a)(1) may disclose by mail, electronic transmission, or other reasonable means, information, including visual depictions contained in the report, in a manner consistent with permitted disclosures under paragraphs (3) through (8) of section 2702(b) only to a law enforcement agency described in subparagraph (A), (B), or (C) of paragraph (3), to NCMEC, or as necessary to respond to legal process. (h) Preservation.— (1) In general.— For the purposes of this section, a completed submission by a provider of a report to the CyberTipline under subsection (a)(1) shall be treated as a request to preserve the contents provided in the report for 1 year after the submission to the CyberTipline. (2) Preservation of commingled content.— Pursuant to paragraph (1), a provider shall preserve any visual depictions, data, or other digital files that are reasonably accessible and may provide context or additional information about the reported material or person. (3) Protection of preserved materials.— A provider preserving materials under this section shall maintain the materials in a secure location and take appropriate steps to limit access by agents or employees of the service to the materials to that access necessary to comply with the requirements of this subsection. (4) Authorities and duties not affected.— Nothing in this section shall be construed as replacing, amending, or otherwise interfering with the authorities and duties under section 2703. (5) Extension of preservation.— A provider of a report to the CyberTipline under subsection (a)(1) may voluntarily preserve the contents provided in the report (including any comingled content described in paragraph (2)) for longer than 1 year after the submission to the CyberTipline for the purpose of reducing the proliferation of online child sexual exploitation or preventing the online sexual exploitation of children. (6) Method of preservation.— Not later than 1 year after the date of enactment of this paragraph, a provider of a report to the CyberTipline under subsection (a)(1) shall preserve materials under this subsection in a manner that is consistent with the most recent version of the Cybersecurity Framework developed by the National Institute of Standards and Technology, or any successor thereto. (Added Pub. L. 110–401, title V,  501(a), Oct. 13, 2008, 122 Stat. 4243; amended Pub. L. 115–395,  2, Dec. 21, 2018, 132 Stat. 5287; Pub. L. 118–59,  3, 4(a), May 7, 2024, 138 Stat. 1016.) (a) Duty To Report.— (1) In general.— (A) Duty.—In order to reduce the proliferation of online child sexual exploitation and to prevent the online sexual exploitation of children, a provider— (i) shall, as soon as reasonably possible after obtaining actual knowledge of any facts or circumstances described in paragraph (2)(A), take the actions described in subparagraph (B); and (ii) may, after obtaining actual knowledge of any facts or circumstances described in paragraph (2)(B), take the actions described in subparagraph (B). (B) Actions described.—The actions described in this subparagraph are— (i) providing to the CyberTipline of NCMEC, or any successor to the CyberTipline operated by NCMEC, the mailing address, telephone number, facsimile number, electronic mailing address of, and individual point of contact for, such provider; and (ii) making a report of such facts or circumstances to the CyberTipline, or any successor to the CyberTipline operated by NCMEC. (2) Facts or circumstances.— (A) Apparent violations.— The facts or circumstances described in this subparagraph are any facts or circumstances from which there is an apparent violation of section 2251, 2251A, 2252, 2252A, 2252B, or 2260 that involves child pornography, of section 1591 (if the violation involves a minor), or of [1] 2422(b). (B) Imminent violations.— The facts or circumstances described in this subparagraph are any facts or circumstances which indicate a violation of any of the sections described in subparagraph (A) involving child pornography may be planned or imminent. (1) In general.— (A) Duty.—In order to reduce the proliferation of online child sexual exploitation and to prevent the online sexual exploitation of children, a provider— (i) shall, as soon as reasonably possible after obtaining actual knowledge of any facts or circumstances described in paragraph (2)(A), take the actions described in subparagraph (B); and (ii) may, after obtaining actual knowledge of any facts or circumstances described in paragraph (2)(B), take the actions described in subparagraph (B). (B) Actions described.—The actions described in this subparagraph are— (i) providing to the CyberTipline of NCMEC, or any successor to the CyberTipline operated by NCMEC, the mailing address, telephone number, facsimile number, electronic mailing address of, and individual point of contact for, such provider; and (ii) making a report of such facts or circumstances to the CyberTipline, or any successor to the CyberTipline operated by NCMEC. (A) Duty.—In order to reduce the proliferation of online child sexual exploitation and to prevent the online sexual exploitation of children, a provider— (i) shall, as soon as reasonably possible after obtaining actual knowledge of any facts or circumstances described in paragraph (2)(A), take the actions described in subparagraph (B); and (ii) may, after obtaining actual knowledge of any facts or circumstances described in paragraph (2)(B), take the actions described in subparagraph (B). (i) shall, as soon as reasonably possible after obtaining actual knowledge of any facts or circumstances described in paragraph (2)(A), take the actions described in subparagraph (B); and shall, as soon as reasonably possible after obtaining actual knowledge of any facts or circumstances described in paragraph (2)(A), take the actions described in subparagraph (B); and (ii) may, after obtaining actual knowledge of any facts or circumstances described in paragraph (2)(B), take the actions described in subparagraph (B). may, after obtaining actual knowledge of any facts or circumstances described in paragraph (2)(B), take the actions described in subparagraph (B). (B) Actions described.—The actions described in this subparagraph are— (i) providing to the CyberTipline of NCMEC, or any successor to the CyberTipline operated by NCMEC, the mailing address, telephone number, facsimile number, electronic mailing address of, and individual point of contact for, such provider; and (ii) making a report of such facts or circumstances to the CyberTipline, or any successor to the CyberTipline operated by NCMEC. (i) providing to the CyberTipline of NCMEC, or any successor to the CyberTipline operated by NCMEC, the mailing address, telephone number, facsimile number, electronic mailing address of, and individual point of contact for, such provider; and providing to the CyberTipline of NCMEC, or any successor to the CyberTipline operated by NCMEC, the mailing address, telephone number, facsimile number, electronic mailing address of, and individual point of contact for, such provider; and (ii) making a report of such facts or circumstances to the CyberTipline, or any successor to the CyberTipline operated by NCMEC. making a report of such facts or circumstances to the CyberTipline, or any successor to the CyberTipline operated by NCMEC. (2) Facts or circumstances.— (A) Apparent violations.— The facts or circumstances described in this subparagraph are any facts or circumstances from which there is an apparent violation of section 2251, 2251A, 2252, 2252A, 2252B, or 2260 that involves child pornography, of section 1591 (if the violation involves a minor), or of [1] 2422(b). (B) Imminent violations.— The facts or circumstances described in this subparagraph are any facts or circumstances which indicate a violation of any of the sections described in subparagraph (A) involving child pornography may be planned or imminent. (A) Apparent violations.— The facts or circumstances described in this subparagraph are any facts or circumstances from which there is an apparent violation of section 2251, 2251A, 2252, 2252A, 2252B, or 2260 that involves child pornography, of section 1591 (if the violation involves a minor), or of [1] 2422(b). The facts or circumstances described in this subparagraph are any facts or circumstances from which there is an apparent violation of section 2251, 2251A, 2252, 2252A, 2252B, or 2260 that involves child pornography, of section 1591 (if the violation involves a minor), or of [1] 2422(b). (B) Imminent violations.— The facts or circumstances described in this subparagraph are any facts or circumstances which indicate a violation of any of the sections described in subparagraph (A) involving child pornography may be planned or imminent. The facts or circumstances described in this subparagraph are any facts or circumstances which indicate a violation of any of the sections described in subparagraph (A) involving child pornography may be planned or imminent. (b) Contents of Report.—In an effort to prevent the future sexual victimization of children, and to the extent the information is within the custody or control of a provider, the facts and circumstances included in each report under subsection (a)(1) may, at the sole discretion of the provider, include the following information: (1) Information about the involved individual.— Information relating to the identity of any individual who appears to have violated or plans to violate a Federal law described in subsection (a)(2), which may, to the extent reasonably practicable, include the electronic mail address, Internet Protocol address, uniform resource locator, payment information (excluding personally identifiable information), or any other identifying information, including self-reported identifying information. (2) Historical reference.— Information relating to when and how a customer or subscriber of a provider uploaded, transmitted, or received content relating to the report or when and how content relating to the report was reported to, or discovered by the provider, including a date and time stamp and time zone. (3) Geographic location information.— Information relating to the geographic location of the involved individual or website, which may include the Internet Protocol address or verified address, or, if not reasonably available, at least one form of geographic identifying information, including area code or zip code, provided by the customer or subscriber, or stored or obtained by the provider. (4) Visual depictions of apparent child pornography.— Any visual depiction of apparent child pornography or other content relating to the incident such report is regarding. (5) Complete communication.—The complete communication containing any visual depiction of apparent child pornography or other content, including— (A) any data or information regarding the transmission of the communication; and (B) any visual depictions, data, or other digital files contained in, or attached to, the communication. (1) Information about the involved individual.— Information relating to the identity of any individual who appears to have violated or plans to violate a Federal law described in subsection (a)(2), which may, to the extent reasonably practicable, include the electronic mail address, Internet Protocol address, uniform resource locator, payment information (excluding personally identifiable information), or any other identifying information, including self-reported identifying information. Information relating to the identity of any individual who appears to have violated or plans to violate a Federal law described in subsection (a)(2), which may, to the extent reasonably practicable, include the electronic mail address, Internet Protocol address, uniform resource locator, payment information (excluding personally identifiable information), or any other identifying information, including self-reported identifying information. (2) Historical reference.— Information relating to when and how a customer or subscriber of a provider uploaded, transmitted, or received content relating to the report or when and how content relating to the report was reported to, or discovered by the provider, including a date and time stamp and time zone. Information relating to when and how a customer or subscriber of a provider uploaded, transmitted, or received content relating to the report or when and how content relating to the report was reported to, or discovered by the provider, including a date and time stamp and time zone. (3) Geographic location information.— Information relating to the geographic location of the involved individual or website, which may include the Internet Protocol address or verified address, or, if not reasonably available, at least one form of geographic identifying information, including area code or zip code, provided by the customer or subscriber, or stored or obtained by the provider. Information relating to the geographic location of the involved individual or website, which may include the Internet Protocol address or verified address, or, if not reasonably available, at least one form of geographic identifying information, including area code or zip code, provided by the customer or subscriber, or stored or obtained by the provider. (4) Visual depictions of apparent child pornography.— Any visual depiction of apparent child pornography or other content relating to the incident such report is regarding. Any visual depiction of apparent child pornography or other content relating to the incident such report is regarding. (5) Complete communication.—The complete communication containing any visual depiction of apparent child pornography or other content, including— (A) any data or information regarding the transmission of the communication; and (B) any visual depictions, data, or other digital files contained in, or attached to, the communication. (A) any data or information regarding the transmission of the communication; and any data or information regarding the transmission of the communication; and (B) any visual depictions, data, or other digital files contained in, or attached to, the communication. any visual depictions, data, or other digital files contained in, or attached to, the communication. (c) Forwarding of Report to Law Enforcement.—Pursuant to its clearinghouse role as a private, nonprofit organization, and at the conclusion of its review in furtherance of its nonprofit mission, NCMEC shall make available each report made under subsection (a)(1) to one or more of the following law enforcement agencies: (1) Any Federal law enforcement agency that is involved in the investigation of child sexual exploitation, kidnapping, or enticement crimes. (2) Any State or local law enforcement agency that is involved in the investigation of child sexual exploitation. (3) A foreign law enforcement agency designated by the Attorney General under subsection (d)(3) or a foreign law enforcement agency that has an established relationship with the Federal Bureau of Investigation, Immigration and Customs Enforcement, or INTERPOL, and is involved in the investigation of child sexual exploitation, kidnapping, or enticement crimes. (1) Any Federal law enforcement agency that is involved in the investigation of child sexual exploitation, kidnapping, or enticement crimes. Any Federal law enforcement agency that is involved in the investigation of child sexual exploitation, kidnapping, or enticement crimes. (2) Any State or local law enforcement agency that is involved in the investigation of child sexual exploitation. Any State or local law enforcement agency that is involved in the investigation of child sexual exploitation. (3) A foreign law enforcement agency designated by the Attorney General under subsection (d)(3) or a foreign law enforcement agency that has an established relationship with the Federal Bureau of Investigation, Immigration and Customs Enforcement, or INTERPOL, and is involved in the investigation of child sexual exploitation, kidnapping, or enticement crimes. A foreign law enforcement agency designated by the Attorney General under subsection (d)(3) or a foreign law enforcement agency that has an established relationship with the Federal Bureau of Investigation, Immigration and Customs Enforcement, or INTERPOL, and is involved in the investigation of child sexual exploitation, kidnapping, or enticement crimes. (d) Attorney General Responsibilities.— (1) In general.— The Attorney General shall enforce this section. (2) Designation of federal agencies.— The Attorney General may designate a Federal law enforcement agency or agencies to which a report shall be forwarded under subsection (c)(1). (3) Designation of foreign agencies.—The Attorney General may— (A) in consultation with the Secretary of State, designate foreign law enforcement agencies to which a report may be forwarded under subsection (c)(3); (B) establish the conditions under which such a report may be forwarded to such agencies; and (C) develop a process for foreign law enforcement agencies to request assistance from Federal law enforcement agencies in obtaining evidence related to a report referred under subsection (c)(3). (4) Reporting designated foreign agencies.— The Attorney General may maintain and make available to the Department of State, NCMEC, providers, the Committee on the Judiciary of the Senate, and the Committee on the Judiciary of the House of Representatives a list of the foreign law enforcement agencies designated under paragraph (3). (5) Notification to providers.— (A) In general.—NCMEC may notify a provider of the information described in subparagraph (B), if— (i) a provider notifies NCMEC that the provider is making a report under this section as the result of a request by a foreign law enforcement agency; and (ii) NCMEC forwards the report described in clause (i) to— (I) the requesting foreign law enforcement agency; or (II) another agency in the same country designated by the Attorney General under paragraph (3) or that has an established relationship with the Federal Bureau of Investigation, U.S. Immigration and Customs Enforcement, or INTERPOL and is involved in the investigation of child sexual exploitation, kidnapping, or enticement crimes. (B) Information described.—The information described in this subparagraph is— (i) the identity of the foreign law enforcement agency to which the report was forwarded; and (ii) the date on which the report was forwarded. (C) Notification of inability to forward report.— If a provider notifies NCMEC that the provider is making a report under this section as the result of a request by a foreign law enforcement agency and NCMEC is unable to forward the report as described in subparagraph (A)(ii), NCMEC shall notify the provider that NCMEC was unable to forward the report. (1) In general.— The Attorney General shall enforce this section. The Attorney General shall enforce this section. (2) Designation of federal agencies.— The Attorney General may designate a Federal law enforcement agency or agencies to which a report shall be forwarded under subsection (c)(1). The Attorney General may designate a Federal law enforcement agency or agencies to which a report shall be forwarded under subsection (c)(1). (3) Designation of foreign agencies.—The Attorney General may— (A) in consultation with the Secretary of State, designate foreign law enforcement agencies to which a report may be forwarded under subsection (c)(3); (B) establish the conditions under which such a report may be forwarded to such agencies; and (C) develop a process for foreign law enforcement agencies to request assistance from Federal law enforcement agencies in obtaining evidence related to a report referred under subsection (c)(3). (A) in consultation with the Secretary of State, designate foreign law enforcement agencies to which a report may be forwarded under subsection (c)(3); in consultation with the Secretary of State, designate foreign law enforcement agencies to which a report may be forwarded under subsection (c)(3); (B) establish the conditions under which such a report may be forwarded to such agencies; and establish the conditions under which such a report may be forwarded to such agencies; and (C) develop a process for foreign law enforcement agencies to request assistance from Federal law enforcement agencies in obtaining evidence related to a report referred under subsection (c)(3). develop a process for foreign law enforcement agencies to request assistance from Federal law enforcement agencies in obtaining evidence related to a report referred under subsection (c)(3). (4) Reporting designated foreign agencies.— The Attorney General may maintain and make available to the Department of State, NCMEC, providers, the Committee on the Judiciary of the Senate, and the Committee on the Judiciary of the House of Representatives a list of the foreign law enforcement agencies designated under paragraph (3). The Attorney General may maintain and make available to the Department of State, NCMEC, providers, the Committee on the Judiciary of the Senate, and the Committee on the Judiciary of the House of Representatives a list of the foreign law enforcement agencies designated under paragraph (3). (5) Notification to providers.— (A) In general.—NCMEC may notify a provider of the information described in subparagraph (B), if— (i) a provider notifies NCMEC that the provider is making a report under this section as the result of a request by a foreign law enforcement agency; and (ii) NCMEC forwards the report described in clause (i) to— (I) the requesting foreign law enforcement agency; or (II) another agency in the same country designated by the Attorney General under paragraph (3) or that has an established relationship with the Federal Bureau of Investigation, U.S. Immigration and Customs Enforcement, or INTERPOL and is involved in the investigation of child sexual exploitation, kidnapping, or enticement crimes. (B) Information described.—The information described in this subparagraph is— (i) the identity of the foreign law enforcement agency to which the report was forwarded; and (ii) the date on which the report was forwarded. (C) Notification of inability to forward report.— If a provider notifies NCMEC that the provider is making a report under this section as the result of a request by a foreign law enforcement agency and NCMEC is unable to forward the report as described in subparagraph (A)(ii), NCMEC shall notify the provider that NCMEC was unable to forward the report. (A) In general.—NCMEC may notify a provider of the information described in subparagraph (B), if— (i) a provider notifies NCMEC that the provider is making a report under this section as the result of a request by a foreign law enforcement agency; and (ii) NCMEC forwards the report described in clause (i) to— (I) the requesting foreign law enforcement agency; or (II) another agency in the same country designated by the Attorney General under paragraph (3) or that has an established relationship with the Federal Bureau of Investigation, U.S. Immigration and Customs Enforcement, or INTERPOL and is involved in the investigation of child sexual exploitation, kidnapping, or enticement crimes. (i) a provider notifies NCMEC that the provider is making a report under this section as the result of a request by a foreign law enforcement agency; and a provider notifies NCMEC that the provider is making a report under this section as the result of a request by a foreign law enforcement agency; and (ii) NCMEC forwards the report described in clause (i) to— (I) the requesting foreign law enforcement agency; or (II) another agency in the same country designated by the Attorney General under paragraph (3) or that has an established relationship with the Federal Bureau of Investigation, U.S. Immigration and Customs Enforcement, or INTERPOL and is involved in the investigation of child sexual exploitation, kidnapping, or enticement crimes. (I) the requesting foreign law enforcement agency; or the requesting foreign law enforcement agency; or (II) another agency in the same country designated by the Attorney General under paragraph (3) or that has an established relationship with the Federal Bureau of Investigation, U.S. Immigration and Customs Enforcement, or INTERPOL and is involved in the investigation of child sexual exploitation, kidnapping, or enticement crimes. another agency in the same country designated by the Attorney General under paragraph (3) or that has an established relationship with the Federal Bureau of Investigation, U.S. Immigration and Customs Enforcement, or INTERPOL and is involved in the investigation of child sexual exploitation, kidnapping, or enticement crimes. (B) Information described.—The information described in this subparagraph is— (i) the identity of the foreign law enforcement agency to which the report was forwarded; and (ii) the date on which the report was forwarded. (i) the identity of the foreign law enforcement agency to which the report was forwarded; and the identity of the foreign law enforcement agency to which the report was forwarded; and (ii) the date on which the report was forwarded. the date on which the report was forwarded. (C) Notification of inability to forward report.— If a provider notifies NCMEC that the provider is making a report under this section as the result of a request by a foreign law enforcement agency and NCMEC is unable to forward the report as described in subparagraph (A)(ii), NCMEC shall notify the provider that NCMEC was unable to forward the report. If a provider notifies NCMEC that the provider is making a report under this section as the result of a request by a foreign law enforcement agency and NCMEC is unable to forward the report as described in subparagraph (A)(ii), NCMEC shall notify the provider that NCMEC was unable to forward the report. (e) Failure To Report.—A provider that knowingly and willfully fails to make a report required under subsection (a)(1) shall be fined— (1) in the case of an initial knowing and willful failure to make a report, not more than $850,000 in the case of a provider with not less than 100,000,000 monthly active users or $600,000 in the case of a provider with less than 100,000,000 monthly active users; and (2) in the case of any second or subsequent knowing and willful failure to make a report, not more than $1,000,000 in the case of a provider with not less than 100,000,000 monthly active users or $850,000 in the case of a provider with less than 100,000,000 monthly active users. (1) in the case of an initial knowing and willful failure to make a report, not more than $850,000 in the case of a provider with not less than 100,000,000 monthly active users or $600,000 in the case of a provider with less than 100,000,000 monthly active users; and in the case of an initial knowing and willful failure to make a report, not more than $850,000 in the case of a provider with not less than 100,000,000 monthly active users or $600,000 in the case of a provider with less than 100,000,000 monthly active users; and (2) in the case of any second or subsequent knowing and willful failure to make a report, not more than $1,000,000 in the case of a provider with not less than 100,000,000 monthly active users or $850,000 in the case of a provider with less than 100,000,000 monthly active users. in the case of any second or subsequent knowing and willful failure to make a report, not more than $1,000,000 in the case of a provider with not less than 100,000,000 monthly active users or $850,000 in the case of a provider with less than 100,000,000 monthly active users. (f) Protection of Privacy.—Nothing in this section shall be construed to require a provider to— (1) monitor any user, subscriber, or customer of that provider; (2) monitor the content of any communication of any person described in paragraph (1); or (3) affirmatively search, screen, or scan for facts or circumstances described in sections (a) and (b). (1) monitor any user, subscriber, or customer of that provider; monitor any user, subscriber, or customer of that provider; (2) monitor the content of any communication of any person described in paragraph (1); or monitor the content of any communication of any person described in paragraph (1); or (3) affirmatively search, screen, or scan for facts or circumstances described in sections (a) and (b). affirmatively search, screen, or scan for facts or circumstances described in sections (a) and (b). (g) Conditions of Disclosure Information Contained Within Report.— (1) In general.— Except as provided in paragraph (2), a law enforcement agency that receives a report under subsection (c) shall not disclose any information contained in that report. (2) Permitted disclosures by law enforcement.— (A) In general.—A law enforcement agency may disclose information in a report received under subsection (c)— (i) to an attorney for the government for use in the performance of the official duties of that attorney; (ii) to such officers and employees of that law enforcement agency, as may be necessary in the performance of their investigative and recordkeeping functions; (iii) to such other government personnel (including personnel of a State or subdivision of a State) as are determined to be necessary by an attorney for the government to assist the attorney in the performance of the official duties of the attorney in enforcing Federal criminal law; (iv) if the report discloses a violation of State criminal law, to an appropriate official of a State or subdivision of a State for the purpose of enforcing such State law; (v) to a defendant in a criminal case or the attorney for that defendant, subject to the terms and limitations under section 3509(m) or a similar State law, to the extent the information relates to a criminal charge pending against that defendant; (vi) subject to subparagraph (B), to a provider if necessary to facilitate response to legal process issued in connection to a criminal investigation, prosecution, or post-conviction remedy relating to that report; and (vii) as ordered by a court upon a showing of good cause and pursuant to any protective orders or other conditions that the court may impose. (B) Limitation.— Nothing in subparagraph (A)(vi) authorizes a law enforcement agency to provide visual depictions of apparent child pornography to a provider. (3) Permitted disclosures by NCMEC.—NCMEC may disclose by mail, electronic transmission, or other reasonable means, information received in a report under subsection (a) only to— (A) any Federal law enforcement agency designated by the Attorney General under subsection (d)(2) or that is involved in the investigation of child sexual exploitation, kidnapping, or enticement crimes; (B) any State, local, or tribal law enforcement agency involved in the investigation of child sexual exploitation, kidnapping, or enticement crimes; (C) any foreign law enforcement agency designated by the Attorney General under subsection (d)(3) or that has an established relationship with the Federal Bureau of Investigation, Immigration and Customs Enforcement, or INTERPOL, and is involved in the investigation of child sexual exploitation, kidnapping, or enticement crimes; (D) a provider as described in section 2258C; and (E) respond to legal process, as necessary. (4) Permitted disclosure by a provider.— A provider that submits a report under subsection (a)(1) may disclose by mail, electronic transmission, or other reasonable means, information, including visual depictions contained in the report, in a manner consistent with permitted disclosures under paragraphs (3) through (8) of section 2702(b) only to a law enforcement agency described in subparagraph (A), (B), or (C) of paragraph (3), to NCMEC, or as necessary to respond to legal process. (1) In general.— Except as provided in paragraph (2), a law enforcement agency that receives a report under subsection (c) shall not disclose any information contained in that report. Except as provided in paragraph (2), a law enforcement agency that receives a report under subsection (c) shall not disclose any information contained in that report. (2) Permitted disclosures by law enforcement.— (A) In general.—A law enforcement agency may disclose information in a report received under subsection (c)— (i) to an attorney for the government for use in the performance of the official duties of that attorney; (ii) to such officers and employees of that law enforcement agency, as may be necessary in the performance of their investigative and recordkeeping functions; (iii) to such other government personnel (including personnel of a State or subdivision of a State) as are determined to be necessary by an attorney for the government to assist the attorney in the performance of the official duties of the attorney in enforcing Federal criminal law; (iv) if the report discloses a violation of State criminal law, to an appropriate official of a State or subdivision of a State for the purpose of enforcing such State law; (v) to a defendant in a criminal case or the attorney for that defendant, subject to the terms and limitations under section 3509(m) or a similar State law, to the extent the information relates to a criminal charge pending against that defendant; (vi) subject to subparagraph (B), to a provider if necessary to facilitate response to legal process issued in connection to a criminal investigation, prosecution, or post-conviction remedy relating to that report; and (vii) as ordered by a court upon a showing of good cause and pursuant to any protective orders or other conditions that the court may impose. (B) Limitation.— Nothing in subparagraph (A)(vi) authorizes a law enforcement agency to provide visual depictions of apparent child pornography to a provider. (A) In general.—A law enforcement agency may disclose information in a report received under subsection (c)— (i) to an attorney for the government for use in the performance of the official duties of that attorney; (ii) to such officers and employees of that law enforcement agency, as may be necessary in the performance of their investigative and recordkeeping functions; (iii) to such other government personnel (including personnel of a State or subdivision of a State) as are determined to be necessary by an attorney for the government to assist the attorney in the performance of the official duties of the attorney in enforcing Federal criminal law; (iv) if the report discloses a violation of State criminal law, to an appropriate official of a State or subdivision of a State for the purpose of enforcing such State law; (v) to a defendant in a criminal case or the attorney for that defendant, subject to the terms and limitations under section 3509(m) or a similar State law, to the extent the information relates to a criminal charge pending against that defendant; (vi) subject to subparagraph (B), to a provider if necessary to facilitate response to legal process issued in connection to a criminal investigation, prosecution, or post-conviction remedy relating to that report; and (vii) as ordered by a court upon a showing of good cause and pursuant to any protective orders or other conditions that the court may impose. (i) to an attorney for the government for use in the performance of the official duties of that attorney; to an attorney for the government for use in the performance of the official duties of that attorney; (ii) to such officers and employees of that law enforcement agency, as may be necessary in the performance of their investigative and recordkeeping functions; to such officers and employees of that law enforcement agency, as may be necessary in the performance of their investigative and recordkeeping functions; (iii) to such other government personnel (including personnel of a State or subdivision of a State) as are determined to be necessary by an attorney for the government to assist the attorney in the performance of the official duties of the attorney in enforcing Federal criminal law; to such other government personnel (including personnel of a State or subdivision of a State) as are determined to be necessary by an attorney for the government to assist the attorney in the performance of the official duties of the attorney in enforcing Federal criminal law; (iv) if the report discloses a violation of State criminal law, to an appropriate official of a State or subdivision of a State for the purpose of enforcing such State law; if the report discloses a violation of State criminal law, to an appropriate official of a State or subdivision of a State for the purpose of enforcing such State law; (v) to a defendant in a criminal case or the attorney for that defendant, subject to the terms and limitations under section 3509(m) or a similar State law, to the extent the information relates to a criminal charge pending against that defendant; to a defendant in a criminal case or the attorney for that defendant, subject to the terms and limitations under section 3509(m) or a similar State law, to the extent the information relates to a criminal charge pending against that defendant; (vi) subject to subparagraph (B), to a provider if necessary to facilitate response to legal process issued in connection to a criminal investigation, prosecution, or post-conviction remedy relating to that report; and subject to subparagraph (B), to a provider if necessary to facilitate response to legal process issued in connection to a criminal investigation, prosecution, or post-conviction remedy relating to that report; and (vii) as ordered by a court upon a showing of good cause and pursuant to any protective orders or other conditions that the court may impose. as ordered by a court upon a showing of good cause and pursuant to any protective orders or other conditions that the court may impose. (B) Limitation.— Nothing in subparagraph (A)(vi) authorizes a law enforcement agency to provide visual depictions of apparent child pornography to a provider. Nothing in subparagraph (A)(vi) authorizes a law enforcement agency to provide visual depictions of apparent child pornography to a provider. (3) Permitted disclosures by NCMEC.—NCMEC may disclose by mail, electronic transmission, or other reasonable means, information received in a report under subsection (a) only to— (A) any Federal law enforcement agency designated by the Attorney General under subsection (d)(2) or that is involved in the investigation of child sexual exploitation, kidnapping, or enticement crimes; (B) any State, local, or tribal law enforcement agency involved in the investigation of child sexual exploitation, kidnapping, or enticement crimes; (C) any foreign law enforcement agency designated by the Attorney General under subsection (d)(3) or that has an established relationship with the Federal Bureau of Investigation, Immigration and Customs Enforcement, or INTERPOL, and is involved in the investigation of child sexual exploitation, kidnapping, or enticement crimes; (D) a provider as described in section 2258C; and (E) respond to legal process, as necessary. (A) any Federal law enforcement agency designated by the Attorney General under subsection (d)(2) or that is involved in the investigation of child sexual exploitation, kidnapping, or enticement crimes; any Federal law enforcement agency designated by the Attorney General under subsection (d)(2) or that is involved in the investigation of child sexual exploitation, kidnapping, or enticement crimes; (B) any State, local, or tribal law enforcement agency involved in the investigation of child sexual exploitation, kidnapping, or enticement crimes; any State, local, or tribal law enforcement agency involved in the investigation of child sexual exploitation, kidnapping, or enticement crimes; (C) any foreign law enforcement agency designated by the Attorney General under subsection (d)(3) or that has an established relationship with the Federal Bureau of Investigation, Immigration and Customs Enforcement, or INTERPOL, and is involved in the investigation of child sexual exploitation, kidnapping, or enticement crimes; any foreign law enforcement agency designated by the Attorney General under subsection (d)(3) or that has an established relationship with the Federal Bureau of Investigation, Immigration and Customs Enforcement, or INTERPOL, and is involved in the investigation of child sexual exploitation, kidnapping, or enticement crimes; (D) a provider as described in section 2258C; and a provider as described in section 2258C; and (E) respond to legal process, as necessary. respond to legal process, as necessary. (4) Permitted disclosure by a provider.— A provider that submits a report under subsection (a)(1) may disclose by mail, electronic transmission, or other reasonable means, information, including visual depictions contained in the report, in a manner consistent with permitted disclosures under paragraphs (3) through (8) of section 2702(b) only to a law enforcement agency described in subparagraph (A), (B), or (C) of paragraph (3), to NCMEC, or as necessary to respond to legal process. A provider that submits a report under subsection (a)(1) may disclose by mail, electronic transmission, or other reasonable means, information, including visual depictions contained in the report, in a manner consistent with permitted disclosures under paragraphs (3) through (8) of section 2702(b) only to a law enforcement agency described in subparagraph (A), (B), or (C) of paragraph (3), to NCMEC, or as necessary to respond to legal process. (h) Preservation.— (1) In general.— For the purposes of this section, a completed submission by a provider of a report to the CyberTipline under subsection (a)(1) shall be treated as a request to preserve the contents provided in the report for 1 year after the submission to the CyberTipline. (2) Preservation of commingled content.— Pursuant to paragraph (1), a provider shall preserve any visual depictions, data, or other digital files that are reasonably accessible and may provide context or additional information about the reported material or person. (3) Protection of preserved materials.— A provider preserving materials under this section shall maintain the materials in a secure location and take appropriate steps to limit access by agents or employees of the service to the materials to that access necessary to comply with the requirements of this subsection. (4) Authorities and duties not affected.— Nothing in this section shall be construed as replacing, amending, or otherwise interfering with the authorities and duties under section 2703. (5) Extension of preservation.— A provider of a report to the CyberTipline under subsection (a)(1) may voluntarily preserve the contents provided in the report (including any comingled content described in paragraph (2)) for longer than 1 year after the submission to the CyberTipline for the purpose of reducing the proliferation of online child sexual exploitation or preventing the online sexual exploitation of children. (6) Method of preservation.— Not later than 1 year after the date of enactment of this paragraph, a provider of a report to the CyberTipline under subsection (a)(1) shall preserve materials under this subsection in a manner that is consistent with the most recent version of the Cybersecurity Framework developed by the National Institute of Standards and Technology, or any successor thereto. (1) In general.— For the purposes of this section, a completed submission by a provider of a report to the CyberTipline under subsection (a)(1) shall be treated as a request to preserve the contents provided in the report for 1 year after the submission to the CyberTipline. For the purposes of this section, a completed submission by a provider of a report to the CyberTipline under subsection (a)(1) shall be treated as a request to preserve the contents provided in the report for 1 year after the submission to the CyberTipline. (2) Preservation of commingled content.— Pursuant to paragraph (1), a provider shall preserve any visual depictions, data, or other digital files that are reasonably accessible and may provide context or additional information about the reported material or person. Pursuant to paragraph (1), a provider shall preserve any visual depictions, data, or other digital files that are reasonably accessible and may provide context or additional information about the reported material or person. (3) Protection of preserved materials.— A provider preserving materials under this section shall maintain the materials in a secure location and take appropriate steps to limit access by agents or employees of the service to the materials to that access necessary to comply with the requirements of this subsection. A provider preserving materials under this section shall maintain the materials in a secure location and take appropriate steps to limit access by agents or employees of the service to the materials to that access necessary to comply with the requirements of this subsection. (4) Authorities and duties not affected.— Nothing in this section shall be construed as replacing, amending, or otherwise interfering with the authorities and duties under section 2703. Nothing in this section shall be construed as replacing, amending, or otherwise interfering with the authorities and duties under section 2703. (5) Extension of preservation.— A provider of a report to the CyberTipline under subsection (a)(1) may voluntarily preserve the contents provided in the report (including any comingled content described in paragraph (2)) for longer than 1 year after the submission to the CyberTipline for the purpose of reducing the proliferation of online child sexual exploitation or preventing the online sexual exploitation of children. A provider of a report to the CyberTipline under subsection (a)(1) may voluntarily preserve the contents provided in the report (including any comingled content described in paragraph (2)) for longer than 1 year after the submission to the CyberTipline for the purpose of reducing the proliferation of online child sexual exploitation or preventing the online sexual exploitation of children. (6) Method of preservation.— Not later than 1 year after the date of enactment of this paragraph, a provider of a report to the CyberTipline under subsection (a)(1) shall preserve materials under this subsection in a manner that is consistent with the most recent version of the Cybersecurity Framework developed by the National Institute of Standards and Technology, or any successor thereto. Not later than 1 year after the date of enactment of this paragraph, a provider of a report to the CyberTipline under subsection (a)(1) shall preserve materials under this subsection in a manner that is consistent with the most recent version of the Cybersecurity Framework developed by the National Institute of Standards and Technology, or any successor thereto. (Added Pub. L. 110–401, title V,  501(a), Oct. 13, 2008, 122 Stat. 4243; amended Pub. L. 115–395,  2, Dec. 21, 2018, 132 Stat. 5287; Pub. L. 118–59,  3, 4(a), May 7, 2024, 138 Stat. 1016.) [1] So in original. Probably should be followed by “section”. Editorial Notes References in Text The date of enactment of this paragraph, referred to in subsec. (h)(6), is the date of enactment of Pub. L. 118–59, which was approved May 7, 2024. Amendments 2024—Subsec. (a)(2)(A). Pub. L. 118–59,  4(a)(1), inserted “, of section 1591 (if the violation involves a minor), or of 2422(b)” after “child pornography”. Subsec. (e)(1). Pub. L. 118–59,  4(a)(2)(A), substituted “$850,000 in the case of a provider with not less than 100,000,000 monthly active users or $600,000 in the case of a provider with less than 100,000,000 monthly active users” for “$150,000”. Subsec. (e)(2). Pub. L. 118–59,  4(a)(2)(B), substituted “$1,000,000 in the case of a provider with not less than 100,000,000 monthly active users or $850,000 in the case of a provider with less than 100,000,000 monthly active users” for “$300,000”. Subsec. (h)(1). Pub. L. 118–59,  3(1), substituted “1 year” for “90 days”. Subsec. (h)(5), (6). Pub. L. 118–59,  3(2), added pars. (5) and (6). 2018—Pub. L. 115–395,  2(1), substituted “providers” for “electronic communication service providers and remote computing service providers” in section catchline. Subsec. (a)(1). Pub. L. 115–395,  2(2)(A), amended par. (1) generally. Prior to amendment, par. (1) related to general reporting duty of electronic communication service providers. Subsec. (a)(2). Pub. L. 115–395,  2(2)(B), amended par. (2) generally. Prior to amendment, par. (2) described facts or circumstances of apparent violations requiring report. Subsec. (b). Pub. L. 115–395,  2(3)(A), in introductory provisions, substituted “In an effort to prevent the future sexual victimization of children, and to the extent the information is within the custody or control of a provider, the facts and circumstances included in each report under subsection (a)(1) may, at the sole discretion of the provider, include” for “To the extent the information is within the custody or control of an electronic communication service provider or a remote computing service provider, the facts and circumstances included in each report under subsection (a)(1) may include”. Subsec. (b)(1). Pub. L. 115–395,  2(3)(B), inserted “or plans to violate” after “who appears to have violated” and “payment information (excluding personally identifiable information),” after “uniform resource locator,”. Subsec. (b)(2). Pub. L. 115–395,  2(3)(C), substituted “a provider uploaded, transmitted, or received content relating to the report or when and how content relating to the report was reported to, or discovered by the provider” for “an electronic communication service or a remote computing service uploaded, transmitted, or received apparent child pornography or when and how apparent child pornography was reported to, or discovered by the electronic communication service provider or remote computing service provider”. Subsec. (b)(3). Pub. L. 115–395,  2(3)(D), amended par. (3) generally. Prior to amendment, text read as follows: “(A) In general.—Information relating to the geographic location of the involved individual or website, which may include the Internet Protocol address or verified billing address, or, if not reasonably available, at least 1 form of geographic identifying information, including area code or zip code. “(B) Inclusion.—The information described in subparagraph (A) may also include any geographic information provided to the electronic communication service or remote computing service by the customer or subscriber.” Subsec. (b)(4). Pub. L. 115–395,  2(3)(E), in heading, substituted “Visual depictions” for “Images” and, in text, substituted “visual depiction” for “image” and inserted “or other content” after “apparent child pornography”. Subsec. (b)(5). Pub. L. 115–395,  2(3)(F), substituted “visual depiction” for “image” and inserted “or other content” after “apparent child pornography” in introductory provisions and substituted “visual depictions” for “images” in subpar. (B). Subsec. (c). Pub. L. 115–395,  2(4), amended subsec. (c) generally. Prior to amendment, subsec. (c) related to forwarding of reports to domestic and foreign law enforcement agencies. Subsec. (d)(2). Pub. L. 115–395,  2(5)(A), substituted “may designate a” for “shall designate promptly the”. Subsec. (d)(3). Pub. L. 115–395,  2(5)(B), substituted “may” for “shall promptly” in introductory provisions and “designate” for “designate the” in subpar. (A). Subsec. (d)(4). Pub. L. 115–395,  2(5)(C), substituted “may” for “shall”, “NCMEC” for “the National Center for Missing and Exploited Children”, and “providers” for “electronic communication service providers, remote computing service providers”. Subsec. (d)(5). Pub. L. 115–395,  2(5)(E), (F), redesignated par. (6) as (5) and amended it generally. Prior to amendment, par. related to contents of Center’s notification to providers of report forwarded at request of foreign law enforcement agency. Pub. L. 115–395,  2(5)(D), struck out par. (5). Text read as follows: “It is the sense of Congress that— “(A) combating the international manufacturing, possession, and trade in online child pornography requires cooperation with competent, qualified, and appropriately trained foreign law enforcement agencies; and “(B) the Attorney General, in cooperation with the Secretary of State, should make a substantial effort to expand the list of foreign agencies designated under paragraph (3).” Subsec. (d)(6). Pub. L. 115–395,  2(5)(E), redesignated par. (6) as (5). Subsec. (e). Pub. L. 115–395,  2(6), substituted “A provider” for “An electronic communication service provider or remote computing service provider”. Subsec. (f). Pub. L. 115–395,  2(7)(A), substituted “a provider” for “an electronic communication service provider or a remote computing service provider” in introductory provisions. Subsec. (f)(3). Pub. L. 115–395,  2(7)(B), substituted “search, screen, or scan for” for “seek”. Subsec. (g)(2)(A)(vi). Pub. L. 115–395,  2(8)(A)(i), which directed substitution of “a provider” for “an electronic communication service provider or remote computing service provider”, was executed by making the substitution for “an electronic communication service provider or remote computing provider”, to reflect the probable intent of Congress. Subsec. (g)(2)(B). Pub. L. 115–395,  2(8)(A)(ii), amended subpar. (B) generally. Prior to amendment, text read as follows: “(i) Limitations on further disclosure.—The electronic communication service provider or remote computing service provider shall be prohibited from disclosing the contents of a report provided under subparagraph (A)(vi) to any person, except as necessary to respond to the legal process. “(ii) Effect.—Nothing in subparagraph (A)(vi) authorizes a law enforcement agency to provide child pornography images to an electronic communications service provider or a remote computing service.” Subsec. (g)(3). Pub. L. 115–395,  2(8)(B)(i), (ii), in heading, substituted “NCMEC” for “the national center for missing and exploited children” and, in introductory provisions, substituted “NCMEC may disclose by mail, electronic transmission, or other reasonable means, information received in a report under subsection (a) only to” for “The National Center for Missing and Exploited Children may disclose information received in a report under subsection (a) only”. Subsec. (g)(3)(A). Pub. L. 115–395,  2(8)(B)(iii), substituted “any Federal law enforcement agency” for “to any Federal law enforcement agency” and inserted “or that is involved in the investigation of child sexual exploitation, kidnapping, or enticement crimes” before semicolon at end. Subsec. (g)(3)(B). Pub. L. 115–395,  2(8)(B)(iv), substituted “any State” for “to any State” and “child sexual exploitation” for “child pornography, child exploitation”. Subsec. (g)(3)(C). Pub. L. 115–395,  2(8)(B)(v), substituted “any foreign law enforcement agency” for “to any foreign law enforcement agency” and “or that has an established relationship with the Federal Bureau of Investigation, Immigration and Customs Enforcement, or INTERPOL, and is involved in the investigation of child sexual exploitation, kidnapping, or enticement crimes;” for “; and”. Subsec. (g)(3)(D). Pub. L. 115–395,  2(8)(B)(vi), substituted “a provider” for “an electronic communication service provider or remote computing service provider” and “; and” for period at end. Subsec. (g)(3)(E). Pub. L. 115–395,  2(8)(B)(vii), added subpar. (E). Subsec. (g)(4). Pub. L. 115–395,  2(8)(C), added par. (4). Subsec. (h)(1). Pub. L. 115–395,  2(9)(A), substituted “a completed submission by a provider of a report to the CyberTipline under subsection (a)(1) shall be treated as a request to preserve the contents provided in the report for 90 days after the submission to the CyberTipline” for “the notification to an electronic communication service provider or a remote computing service provider by the CyberTipline of receipt of a report under subsection (a)(1) shall be treated as a request to preserve, as if such request was made pursuant to section 2703(f)”. Subsec. (h)(2). Pub. L. 115–395,  2(9)(D), in heading, substituted “content” for “images” and, in text, substituted “a provider” for “an electronic communication service provider or a remote computing service”, “visual depictions” for “images”, and “reasonably accessible and may provide context or additional information about the reported material or person” for “commingled or interspersed among the images of apparent child pornography within a particular communication or user-created folder or directory”. Final substitution, which directed striking out text containing “user created”, was executed instead to text which contained “user-created”, to reflect the probable intent of Congress. Pub. L. 115–395,  2(9)(B), (C), redesignated par. (3) as (2) and struck out former par. (2). Prior to amendment, text of par. (2) read as follows: “Pursuant to paragraph (1), an electronic communication service provider or a remote computing service shall preserve the contents of the report provided pursuant to subsection (b) for 90 days after such notification by the CyberTipline.” Subsec. (h)(3). Pub. L. 115–395,  2(9)(E), which directed substitution of “A provider” for “An electronic communication service or remote computing service”, was executed by making the substitution for “An electronic communications service or remote computing service”, to reflect the probable intent of Congress. Pub. L. 115–395,  2(9)(C), redesignated par. (4) as (3). Former par. (3) redesignated (2). Subsec. (h)(4), (5). Pub. L. 115–395,  2(9)(C), redesignated pars. (4) and (5) as (3) and (4), respectively. Statutory Notes and Related Subsidiaries Guidelines Pub. L. 118–59,  4(b), May 7, 2024, 138 Stat. 1017, provided that: “Not later than 180 days after the date of enactment of this Act [May 7, 2024], the National Center for Missing & Exploited Children may issue guidelines, as appropriate, to providers required or permitted to take actions described in section 2258A(a)(1)(B) of title 18, United States Code, on the relevant identifiers for content that may indicate sex trafficking of children, as described in section 1591 of that title, or enticement, as described in section 2422(b) of that title.” [1] So in original. Probably should be followed by “section”. Editorial Notes References in Text The date of enactment of this paragraph, referred to in subsec. (h)(6), is the date of enactment of Pub. L. 118–59, which was approved May 7, 2024. Amendments 2024—Subsec. (a)(2)(A). Pub. L. 118–59,  4(a)(1), inserted “, of section 1591 (if the violation involves a minor), or of 2422(b)” after “child pornography”. Subsec. (e)(1). Pub. L. 118–59,  4(a)(2)(A), substituted “$850,000 in the case of a provider with not less than 100,000,000 monthly active users or $600,000 in the case of a provider with less than 100,000,000 monthly active users” for “$150,000”. Subsec. (e)(2). Pub. L. 118–59,  4(a)(2)(B), substituted “$1,000,000 in the case of a provider with not less than 100,000,000 monthly active users or $850,000 in the case of a provider with less than 100,000,000 monthly active users” for “$300,000”. Subsec. (h)(1). Pub. L. 118–59,  3(1), substituted “1 year” for “90 days”. Subsec. (h)(5), (6). Pub. L. 118–59,  3(2), added pars. (5) and (6). 2018—Pub. L. 115–395,  2(1), substituted “providers” for “electronic communication service providers and remote computing service providers” in section catchline. Subsec. (a)(1). Pub. L. 115–395,  2(2)(A), amended par. (1) generally. Prior to amendment, par. (1) related to general reporting duty of electronic communication service providers. Subsec. (a)(2). Pub. L. 115–395,  2(2)(B), amended par. (2) generally. Prior to amendment, par. (2) described facts or circumstances of apparent violations requiring report. Subsec. (b). Pub. L. 115–395,  2(3)(A), in introductory provisions, substituted “In an effort to prevent the future sexual victimization of children, and to the extent the information is within the custody or control of a provider, the facts and circumstances included in each report under subsection (a)(1) may, at the sole discretion of the provider, include” for “To the extent the information is within the custody or control of an electronic communication service provider or a remote computing service provider, the facts and circumstances included in each report under subsection (a)(1) may include”. Subsec. (b)(1). Pub. L. 115–395,  2(3)(B), inserted “or plans to violate” after “who appears to have violated” and “payment information (excluding personally identifiable information),” after “uniform resource locator,”. Subsec. (b)(2). Pub. L. 115–395,  2(3)(C), substituted “a provider uploaded, transmitted, or received content relating to the report or when and how content relating to the report was reported to, or discovered by the provider” for “an electronic communication service or a remote computing service uploaded, transmitted, or received apparent child pornography or when and how apparent child pornography was reported to, or discovered by the electronic communication service provider or remote computing service provider”. Subsec. (b)(3). Pub. L. 115–395,  2(3)(D), amended par. (3) generally. Prior to amendment, text read as follows: “(A) In general.—Information relating to the geographic location of the involved individual or website, which may include the Internet Protocol address or verified billing address, or, if not reasonably available, at least 1 form of geographic identifying information, including area code or zip code. “(B) Inclusion.—The information described in subparagraph (A) may also include any geographic information provided to the electronic communication service or remote computing service by the customer or subscriber.” Subsec. (b)(4). Pub. L. 115–395,  2(3)(E), in heading, substituted “Visual depictions” for “Images” and, in text, substituted “visual depiction” for “image” and inserted “or other content” after “apparent child pornography”. Subsec. (b)(5). Pub. L. 115–395,  2(3)(F), substituted “visual depiction” for “image” and inserted “or other content” after “apparent child pornography” in introductory provisions and substituted “visual depictions” for “images” in subpar. (B). Subsec. (c). Pub. L. 115–395,  2(4), amended subsec. (c) generally. Prior to amendment, subsec. (c) related to forwarding of reports to domestic and foreign law enforcement agencies. Subsec. (d)(2). Pub. L. 115–395,  2(5)(A), substituted “may designate a” for “shall designate promptly the”. Subsec. (d)(3). Pub. L. 115–395,  2(5)(B), substituted “may” for “shall promptly” in introductory provisions and “designate” for “designate the” in subpar. (A). Subsec. (d)(4). Pub. L. 115–395,  2(5)(C), substituted “may” for “shall”, “NCMEC” for “the National Center for Missing and Exploited Children”, and “providers” for “electronic communication service providers, remote computing service providers”. Subsec. (d)(5). Pub. L. 115–395,  2(5)(E), (F), redesignated par. (6) as (5) and amended it generally. Prior to amendment, par. related to contents of Center’s notification to providers of report forwarded at request of foreign law enforcement agency. Pub. L. 115–395,  2(5)(D), struck out par. (5). Text read as follows: “It is the sense of Congress that— “(A) combating the international manufacturing, possession, and trade in online child pornography requires cooperation with competent, qualified, and appropriately trained foreign law enforcement agencies; and “(B) the Attorney General, in cooperation with the Secretary of State, should make a substantial effort to expand the list of foreign agencies designated under paragraph (3).” Subsec. (d)(6). Pub. L. 115–395,  2(5)(E), redesignated par. (6) as (5). Subsec. (e). Pub. L. 115–395,  2(6), substituted “A provider” for “An electronic communication service provider or remote computing service provider”. Subsec. (f). Pub. L. 115–395,  2(7)(A), substituted “a provider” for “an electronic communication service provider or a remote computing service provider” in introductory provisions. Subsec. (f)(3). Pub. L. 115–395,  2(7)(B), substituted “search, screen, or scan for” for “seek”. Subsec. (g)(2)(A)(vi). Pub. L. 115–395,  2(8)(A)(i), which directed substitution of “a provider” for “an electronic communication service provider or remote computing service provider”, was executed by making the substitution for “an electronic communication service provider or remote computing provider”, to reflect the probable intent of Congress. Subsec. (g)(2)(B). Pub. L. 115–395,  2(8)(A)(ii), amended subpar. (B) generally. Prior to amendment, text read as follows: “(i) Limitations on further disclosure.—The electronic communication service provider or remote computing service provider shall be prohibited from disclosing the contents of a report provided under subparagraph (A)(vi) to any person, except as necessary to respond to the legal process. “(ii) Effect.—Nothing in subparagraph (A)(vi) authorizes a law enforcement agency to provide child pornography images to an electronic communications service provider or a remote computing service.” Subsec. (g)(3). Pub. L. 115–395,  2(8)(B)(i), (ii), in heading, substituted “NCMEC” for “the national center for missing and exploited children” and, in introductory provisions, substituted “NCMEC may disclose by mail, electronic transmission, or other reasonable means, information received in a report under subsection (a) only to” for “The National Center for Missing and Exploited Children may disclose information received in a report under subsection (a) only”. Subsec. (g)(3)(A). Pub. L. 115–395,  2(8)(B)(iii), substituted “any Federal law enforcement agency” for “to any Federal law enforcement agency” and inserted “or that is involved in the investigation of child sexual exploitation, kidnapping, or enticement crimes” before semicolon at end. Subsec. (g)(3)(B). Pub. L. 115–395,  2(8)(B)(iv), substituted “any State” for “to any State” and “child sexual exploitation” for “child pornography, child exploitation”. Subsec. (g)(3)(C). Pub. L. 115–395,  2(8)(B)(v), substituted “any foreign law enforcement agency” for “to any foreign law enforcement agency” and “or that has an established relationship with the Federal Bureau of Investigation, Immigration and Customs Enforcement, or INTERPOL, and is involved in the investigation of child sexual exploitation, kidnapping, or enticement crimes;” for “; and”. Subsec. (g)(3)(D). Pub. L. 115–395,  2(8)(B)(vi), substituted “a provider” for “an electronic communication service provider or remote computing service provider” and “; and” for period at end. Subsec. (g)(3)(E). Pub. L. 115–395,  2(8)(B)(vii), added subpar. (E). Subsec. (g)(4). Pub. L. 115–395,  2(8)(C), added par. (4). Subsec. (h)(1). Pub. L. 115–395,  2(9)(A), substituted “a completed submission by a provider of a report to the CyberTipline under subsection (a)(1) shall be treated as a request to preserve the contents provided in the report for 90 days after the submission to the CyberTipline” for “the notification to an electronic communication service provider or a remote computing service provider by the CyberTipline of receipt of a report under subsection (a)(1) shall be treated as a request to preserve, as if such request was made pursuant to section 2703(f)”. Subsec. (h)(2). Pub. L. 115–395,  2(9)(D), in heading, substituted “content” for “images” and, in text, substituted “a provider” for “an electronic communication service provider or a remote computing service”, “visual depictions” for “images”, and “reasonably accessible and may provide context or additional information about the reported material or person” for “commingled or interspersed among the images of apparent child pornography within a particular communication or user-created folder or directory”. Final substitution, which directed striking out text containing “user created”, was executed instead to text which contained “user-created”, to reflect the probable intent of Congress. Pub. L. 115–395,  2(9)(B), (C), redesignated par. (3) as (2) and struck out former par. (2). Prior to amendment, text of par. (2) read as follows: “Pursuant to paragraph (1), an electronic communication service provider or a remote computing service shall preserve the contents of the report provided pursuant to subsection (b) for 90 days after such notification by the CyberTipline.” Subsec. (h)(3). Pub. L. 115–395,  2(9)(E), which directed substitution of “A provider” for “An electronic communication service or remote computing service”, was executed by making the substitution for “An electronic communications service or remote computing service”, to reflect the probable intent of Congress. Pub. L. 115–395,  2(9)(C), redesignated par. (4) as (3). Former par. (3) redesignated (2). Subsec. (h)(4), (5). Pub. L. 115–395,  2(9)(C), redesignated pars. (4) and (5) as (3) and (4), respectively. Statutory Notes and Related Subsidiaries Guidelines Pub. L. 118–59,  4(b), May 7, 2024, 138 Stat. 1017, provided that: “Not later than 180 days after the date of enactment of this Act [May 7, 2024], the National Center for Missing & Exploited Children may issue guidelines, as appropriate, to providers required or permitted to take actions described in section 2258A(a)(1)(B) of title 18, United States Code, on the relevant identifiers for content that may indicate sex trafficking of children, as described in section 1591 of that title, or enticement, as described in section 2422(b) of that title.” References in Text The date of enactment of this paragraph, referred to in subsec. (h)(6), is the date of enactment of Pub. L. 118–59, which was approved May 7, 2024. The date of enactment of this paragraph, referred to in subsec. (h)(6), is the date of enactment of Pub. L. 118–59, which was approved May 7, 2024. Amendments 2024—Subsec. (a)(2)(A). Pub. L. 118–59,  4(a)(1), inserted “, of section 1591 (if the violation involves a minor), or of 2422(b)” after “child pornography”. Subsec. (e)(1). Pub. L. 118–59,  4(a)(2)(A), substituted “$850,000 in the case of a provider with not less than 100,000,000 monthly active users or $600,000 in the case of a provider with less than 100,000,000 monthly active users” for “$150,000”. Subsec. (e)(2). Pub. L. 118–59,  4(a)(2)(B), substituted “$1,000,000 in the case of a provider with not less than 100,000,000 monthly active users or $850,000 in the case of a provider with less than 100,000,000 monthly active users” for “$300,000”. Subsec. (h)(1). Pub. L. 118–59,  3(1), substituted “1 year” for “90 days”. Subsec. (h)(5), (6). Pub. L. 118–59,  3(2), added pars. (5) and (6). 2018—Pub. L. 115–395,  2(1), substituted “providers” for “electronic communication service providers and remote computing service providers” in section catchline. Subsec. (a)(1). Pub. L. 115–395,  2(2)(A), amended par. (1) generally. Prior to amendment, par. (1) related to general reporting duty of electronic communication service providers. Subsec. (a)(2). Pub. L. 115–395,  2(2)(B), amended par. (2) generally. Prior to amendment, par. (2) described facts or circumstances of apparent violations requiring report. Subsec. (b). Pub. L. 115–395,  2(3)(A), in introductory provisions, substituted “In an effort to prevent the future sexual victimization of children, and to the extent the information is within the custody or control of a provider, the facts and circumstances included in each report under subsection (a)(1) may, at the sole discretion of the provider, include” for “To the extent the information is within the custody or control of an electronic communication service provider or a remote computing service provider, the facts and circumstances included in each report under subsection (a)(1) may include”. Subsec. (b)(1). Pub. L. 115–395,  2(3)(B), inserted “or plans to violate” after “who appears to have violated” and “payment information (excluding personally identifiable information),” after “uniform resource locator,”. Subsec. (b)(2). Pub. L. 115–395,  2(3)(C), substituted “a provider uploaded, transmitted, or received content relating to the report or when and how content relating to the report was reported to, or discovered by the provider” for “an electronic communication service or a remote computing service uploaded, transmitted, or received apparent child pornography or when and how apparent child pornography was reported to, or discovered by the electronic communication service provider or remote computing service provider”. Subsec. (b)(3). Pub. L. 115–395,  2(3)(D), amended par. (3) generally. Prior to amendment, text read as follows: “(A) In general.—Information relating to the geographic location of the involved individual or website, which may include the Internet Protocol address or verified billing address, or, if not reasonably available, at least 1 form of geographic identifying information, including area code or zip code. “(B) Inclusion.—The information described in subparagraph (A) may also include any geographic information provided to the electronic communication service or remote computing service by the customer or subscriber.” Subsec. (b)(4). Pub. L. 115–395,  2(3)(E), in heading, substituted “Visual depictions” for “Images” and, in text, substituted “visual depiction” for “image” and inserted “or other content” after “apparent child pornography”. Subsec. (b)(5). Pub. L. 115–395,  2(3)(F), substituted “visual depiction” for “image” and inserted “or other content” after “apparent child pornography” in introductory provisions and substituted “visual depictions” for “images” in subpar. (B). Subsec. (c). Pub. L. 115–395,  2(4), amended subsec. (c) generally. Prior to amendment, subsec. (c) related to forwarding of reports to domestic and foreign law enforcement agencies. Subsec. (d)(2). Pub. L. 115–395,  2(5)(A), substituted “may designate a” for “shall designate promptly the”. Subsec. (d)(3). Pub. L. 115–395,  2(5)(B), substituted “may” for “shall promptly” in introductory provisions and “designate” for “designate the” in subpar. (A). Subsec. (d)(4). Pub. L. 115–395,  2(5)(C), substituted “may” for “shall”, “NCMEC” for “the National Center for Missing and Exploited Children”, and “providers” for “electronic communication service providers, remote computing service providers”. Subsec. (d)(5). Pub. L. 115–395,  2(5)(E), (F), redesignated par. (6) as (5) and amended it generally. Prior to amendment, par. related to contents of Center’s notification to providers of report forwarded at request of foreign law enforcement agency. Pub. L. 115–395,  2(5)(D), struck out par. (5). Text read as follows: “It is the sense of Congress that— “(A) combating the international manufacturing, possession, and trade in online child pornography requires cooperation with competent, qualified, and appropriately trained foreign law enforcement agencies; and “(B) the Attorney General, in cooperation with the Secretary of State, should make a substantial effort to expand the list of foreign agencies designated under paragraph (3).” Subsec. (d)(6). Pub. L. 115–395,  2(5)(E), redesignated par. (6) as (5). Subsec. (e). Pub. L. 115–395,  2(6), substituted “A provider” for “An electronic communication service provider or remote computing service provider”. Subsec. (f). Pub. L. 115–395,  2(7)(A), substituted “a provider” for “an electronic communication service provider or a remote computing service provider” in introductory provisions. Subsec. (f)(3). Pub. L. 115–395,  2(7)(B), substituted “search, screen, or scan for” for “seek”. Subsec. (g)(2)(A)(vi). Pub. L. 115–395,  2(8)(A)(i), which directed substitution of “a provider” for “an electronic communication service provider or remote computing service provider”, was executed by making the substitution for “an electronic communication service provider or remote computing provider”, to reflect the probable intent of Congress. Subsec. (g)(2)(B). Pub. L. 115–395,  2(8)(A)(ii), amended subpar. (B) generally. Prior to amendment, text read as follows: “(i) Limitations on further disclosure.—The electronic communication service provider or remote computing service provider shall be prohibited from disclosing the contents of a report provided under subparagraph (A)(vi) to any person, except as necessary to respond to the legal process. “(ii) Effect.—Nothing in subparagraph (A)(vi) authorizes a law enforcement agency to provide child pornography images to an electronic communications service provider or a remote computing service.” Subsec. (g)(3). Pub. L. 115–395,  2(8)(B)(i), (ii), in heading, substituted “NCMEC” for “the national center for missing and exploited children” and, in introductory provisions, substituted “NCMEC may disclose by mail, electronic transmission, or other reasonable means, information received in a report under subsection (a) only to” for “The National Center for Missing and Exploited Children may disclose information received in a report under subsection (a) only”. Subsec. (g)(3)(A). Pub. L. 115–395,  2(8)(B)(iii), substituted “any Federal law enforcement agency” for “to any Federal law enforcement agency” and inserted “or that is involved in the investigation of child sexual exploitation, kidnapping, or enticement crimes” before semicolon at end. Subsec. (g)(3)(B). Pub. L. 115–395,  2(8)(B)(iv), substituted “any State” for “to any State” and “child sexual exploitation” for “child pornography, child exploitation”. Subsec. (g)(3)(C). Pub. L. 115–395,  2(8)(B)(v), substituted “any foreign law enforcement agency” for “to any foreign law enforcement agency” and “or that has an established relationship with the Federal Bureau of Investigation, Immigration and Customs Enforcement, or INTERPOL, and is involved in the investigation of child sexual exploitation, kidnapping, or enticement crimes;” for “; and”. Subsec. (g)(3)(D). Pub. L. 115–395,  2(8)(B)(vi), substituted “a provider” for “an electronic communication service provider or remote computing service provider” and “; and” for period at end. Subsec. (g)(3)(E). Pub. L. 115–395,  2(8)(B)(vii), added subpar. (E). Subsec. (g)(4). Pub. L. 115–395,  2(8)(C), added par. (4). Subsec. (h)(1). Pub. L. 115–395,  2(9)(A), substituted “a completed submission by a provider of a report to the CyberTipline under subsection (a)(1) shall be treated as a request to preserve the contents provided in the report for 90 days after the submission to the CyberTipline” for “the notification to an electronic communication service provider or a remote computing service provider by the CyberTipline of receipt of a report under subsection (a)(1) shall be treated as a request to preserve, as if such request was made pursuant to section 2703(f)”. Subsec. (h)(2). Pub. L. 115–395,  2(9)(D), in heading, substituted “content” for “images” and, in text, substituted “a provider” for “an electronic communication service provider or a remote computing service”, “visual depictions” for “images”, and “reasonably accessible and may provide context or additional information about the reported material or person” for “commingled or interspersed among the images of apparent child pornography within a particular communication or user-created folder or directory”. Final substitution, which directed striking out text containing “user created”, was executed instead to text which contained “user-created”, to reflect the probable intent of Congress. Pub. L. 115–395,  2(9)(B), (C), redesignated par. (3) as (2) and struck out former par. (2). Prior to amendment, text of par. (2) read as follows: “Pursuant to paragraph (1), an electronic communication service provider or a remote computing service shall preserve the contents of the report provided pursuant to subsection (b) for 90 days after such notification by the CyberTipline.” Subsec. (h)(3). Pub. L. 115–395,  2(9)(E), which directed substitution of “A provider” for “An electronic communication service or remote computing service”, was executed by making the substitution for “An electronic communications service or remote computing service”, to reflect the probable intent of Congress. Pub. L. 115–395,  2(9)(C), redesignated par. (4) as (3). Former par. (3) redesignated (2). Subsec. (h)(4), (5). Pub. L. 115–395,  2(9)(C), redesignated pars. (4) and (5) as (3) and (4), respectively. 2024—Subsec. (a)(2)(A). Pub. L. 118–59,  4(a)(1), inserted “, of section 1591 (if the violation involves a minor), or of 2422(b)” after “child pornography”. Subsec. (e)(1). Pub. L. 118–59,  4(a)(2)(A), substituted “$850,000 in the case of a provider with not less than 100,000,000 monthly active users or $600,000 in the case of a provider with less than 100,000,000 monthly active users” for “$150,000”. Subsec. (e)(2). Pub. L. 118–59,  4(a)(2)(B), substituted “$1,000,000 in the case of a provider with not less than 100,000,000 monthly active users or $850,000 in the case of a provider with less than 100,000,000 monthly active users” for “$300,000”. Subsec. (h)(1). Pub. L. 118–59,  3(1), substituted “1 year” for “90 days”. Subsec. (h)(5), (6). Pub. L. 118–59,  3(2), added pars. (5) and (6). 2018—Pub. L. 115–395,  2(1), substituted “providers” for “electronic communication service providers and remote computing service providers” in section catchline. Subsec. (a)(1). Pub. L. 115–395,  2(2)(A), amended par. (1) generally. Prior to amendment, par. (1) related to general reporting duty of electronic communication service providers. Subsec. (a)(2). Pub. L. 115–395,  2(2)(B), amended par. (2) generally. Prior to amendment, par. (2) described facts or circumstances of apparent violations requiring report. Subsec. (b). Pub. L. 115–395,  2(3)(A), in introductory provisions, substituted “In an effort to prevent the future sexual victimization of children, and to the extent the information is within the custody or control of a provider, the facts and circumstances included in each report under subsection (a)(1) may, at the sole discretion of the provider, include” for “To the extent the information is within the custody or control of an electronic communication service provider or a remote computing service provider, the facts and circumstances included in each report under subsection (a)(1) may include”. Subsec. (b)(1). Pub. L. 115–395,  2(3)(B), inserted “or plans to violate” after “who appears to have violated” and “payment information (excluding personally identifiable information),” after “uniform resource locator,”. Subsec. (b)(2). Pub. L. 115–395,  2(3)(C), substituted “a provider uploaded, transmitted, or received content relating to the report or when and how content relating to the report was reported to, or discovered by the provider” for “an electronic communication service or a remote computing service uploaded, transmitted, or received apparent child pornography or when and how apparent child pornography was reported to, or discovered by the electronic communication service provider or remote computing service provider”. Subsec. (b)(3). Pub. L. 115–395,  2(3)(D), amended par. (3) generally. Prior to amendment, text read as follows: “(A) In general.—Information relating to the geographic location of the involved individual or website, which may include the Internet Protocol address or verified billing address, or, if not reasonably available, at least 1 form of geographic identifying information, including area code or zip code. “(B) Inclusion.—The information described in subparagraph (A) may also include any geographic information provided to the electronic communication service or remote computing service by the customer or subscriber.” Subsec. (b)(4). Pub. L. 115–395,  2(3)(E), in heading, substituted “Visual depictions” for “Images” and, in text, substituted “visual depiction” for “image” and inserted “or other content” after “apparent child pornography”. Subsec. (b)(5). Pub. L. 115–395,  2(3)(F), substituted “visual depiction” for “image” and inserted “or other content” after “apparent child pornography” in introductory provisions and substituted “visual depictions” for “images” in subpar. (B). Subsec. (c). Pub. L. 115–395,  2(4), amended subsec. (c) generally. Prior to amendment, subsec. (c) related to forwarding of reports to domestic and foreign law enforcement agencies. Subsec. (d)(2). Pub. L. 115–395,  2(5)(A), substituted “may designate a” for “shall designate promptly the”. Subsec. (d)(3). Pub. L. 115–395,  2(5)(B), substituted “may” for “shall promptly” in introductory provisions and “designate” for “designate the” in subpar. (A). Subsec. (d)(4). Pub. L. 115–395,  2(5)(C), substituted “may” for “shall”, “NCMEC” for “the National Center for Missing and Exploited Children”, and “providers” for “electronic communication service providers, remote computing service providers”. Subsec. (d)(5). Pub. L. 115–395,  2(5)(E), (F), redesignated par. (6) as (5) and amended it generally. Prior to amendment, par. related to contents of Center’s notification to providers of report forwarded at request of foreign law enforcement agency. Pub. L. 115–395,  2(5)(D), struck out par. (5). Text read as follows: “It is the sense of Congress that— “(A) combating the international manufacturing, possession, and trade in online child pornography requires cooperation with competent, qualified, and appropriately trained foreign law enforcement agencies; and “(B) the Attorney General, in cooperation with the Secretary of State, should make a substantial effort to expand the list of foreign agencies designated under paragraph (3).” Subsec. (d)(6). Pub. L. 115–395,  2(5)(E), redesignated par. (6) as (5). Subsec. (e). Pub. L. 115–395,  2(6), substituted “A provider” for “An electronic communication service provider or remote computing service provider”. Subsec. (f). Pub. L. 115–395,  2(7)(A), substituted “a provider” for “an electronic communication service provider or a remote computing service provider” in introductory provisions. Subsec. (f)(3). Pub. L. 115–395,  2(7)(B), substituted “search, screen, or scan for” for “seek”. Subsec. (g)(2)(A)(vi). Pub. L. 115–395,  2(8)(A)(i), which directed substitution of “a provider” for “an electronic communication service provider or remote computing service provider”, was executed by making the substitution for “an electronic communication service provider or remote computing provider”, to reflect the probable intent of Congress. Subsec. (g)(2)(B). Pub. L. 115–395,  2(8)(A)(ii), amended subpar. (B) generally. Prior to amendment, text read as follows: “(i) Limitations on further disclosure.—The electronic communication service provider or remote computing service provider shall be prohibited from disclosing the contents of a report provided under subparagraph (A)(vi) to any person, except as necessary to respond to the legal process. “(ii) Effect.—Nothing in subparagraph (A)(vi) authorizes a law enforcement agency to provide child pornography images to an electronic communications service provider or a remote computing service.” Subsec. (g)(3). Pub. L. 115–395,  2(8)(B)(i), (ii), in heading, substituted “NCMEC” for “the national center for missing and exploited children” and, in introductory provisions, substituted “NCMEC may disclose by mail, electronic transmission, or other reasonable means, information received in a report under subsection (a) only to” for “The National Center for Missing and Exploited Children may disclose information received in a report under subsection (a) only”. Subsec. (g)(3)(A). Pub. L. 115–395,  2(8)(B)(iii), substituted “any Federal law enforcement agency” for “to any Federal law enforcement agency” and inserted “or that is involved in the investigation of child sexual exploitation, kidnapping, or enticement crimes” before semicolon at end. Subsec. (g)(3)(B). Pub. L. 115–395,  2(8)(B)(iv), substituted “any State” for “to any State” and “child sexual exploitation” for “child pornography, child exploitation”. Subsec. (g)(3)(C). Pub. L. 115–395,  2(8)(B)(v), substituted “any foreign law enforcement agency” for “to any foreign law enforcement agency” and “or that has an established relationship with the Federal Bureau of Investigation, Immigration and Customs Enforcement, or INTERPOL, and is involved in the investigation of child sexual exploitation, kidnapping, or enticement crimes;” for “; and”. Subsec. (g)(3)(D). Pub. L. 115–395,  2(8)(B)(vi), substituted “a provider” for “an electronic communication service provider or remote computing service provider” and “; and” for period at end. Subsec. (g)(3)(E). Pub. L. 115–395,  2(8)(B)(vii), added subpar. (E). Subsec. (g)(4). Pub. L. 115–395,  2(8)(C), added par. (4). Subsec. (h)(1). Pub. L. 115–395,  2(9)(A), substituted “a completed submission by a provider of a report to the CyberTipline under subsection (a)(1) shall be treated as a request to preserve the contents provided in the report for 90 days after the submission to the CyberTipline” for “the notification to an electronic communication service provider or a remote computing service provider by the CyberTipline of receipt of a report under subsection (a)(1) shall be treated as a request to preserve, as if such request was made pursuant to section 2703(f)”. Subsec. (h)(2). Pub. L. 115–395,  2(9)(D), in heading, substituted “content” for “images” and, in text, substituted “a provider” for “an electronic communication service provider or a remote computing service”, “visual depictions” for “images”, and “reasonably accessible and may provide context or additional information about the reported material or person” for “commingled or interspersed among the images of apparent child pornography within a particular communication or user-created folder or directory”. Final substitution, which directed striking out text containing “user created”, was executed instead to text which contained “user-created”, to reflect the probable intent of Congress. Pub. L. 115–395,  2(9)(B), (C), redesignated par. (3) as (2) and struck out former par. (2). Prior to amendment, text of par. (2) read as follows: “Pursuant to paragraph (1), an electronic communication service provider or a remote computing service shall preserve the contents of the report provided pursuant to subsection (b) for 90 days after such notification by the CyberTipline.” Subsec. (h)(3). Pub. L. 115–395,  2(9)(E), which directed substitution of “A provider” for “An electronic communication service or remote computing service”, was executed by making the substitution for “An electronic communications service or remote computing service”, to reflect the probable intent of Congress. Pub. L. 115–395,  2(9)(C), redesignated par. (4) as (3). Former par. (3) redesignated (2). Subsec. (h)(4), (5). Pub. L. 115–395,  2(9)(C), redesignated pars. (4) and (5) as (3) and (4), respectively. Statutory Notes and Related Subsidiaries Guidelines Pub. L. 118–59,  4(b), May 7, 2024, 138 Stat. 1017, provided that: “Not later than 180 days after the date of enactment of this Act [May 7, 2024], the National Center for Missing & Exploited Children may issue guidelines, as appropriate, to providers required or permitted to take actions described in section 2258A(a)(1)(B) of title 18, United States Code, on the relevant identifiers for content that may indicate sex trafficking of children, as described in section 1591 of that title, or enticement, as described in section 2422(b) of that title.” Pub. L. 118–59,  4(b), May 7, 2024, 138 Stat. 1017, provided that: “Not later than 180 days after the date of enactment of this Act [May 7, 2024], the National Center for Missing & Exploited Children may issue guidelines, as appropriate, to providers required or permitted to take actions described in section 2258A(a)(1)(B) of title 18, United States Code, on the relevant identifiers for content that may indicate sex trafficking of children, as described in section 1591 of that title, or enticement, as described in section 2422(b) of that title.” "
        }
      ],
      "content_type": "legal_statute",
      "word_count": 41715,
      "char_count": 279276
    }
  ]
}